{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RRL_qK7KHnUC"
   },
   "source": [
    "# Ch02. 텍스트 전처리 (Text Preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KXb_e-xqHvCJ"
   },
   "source": [
    "# v03. 어간 추출(Stemming) and 표제어 추출(Lemmatization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TUdkgqQdH1DB"
   },
   "source": [
    "- 정규화 기법 중 코퍼스에 있는 단어의 개수를 줄일 수 있는 기법\n",
    "  - 표제어 추출(lemmatization)\n",
    "  - 어간 추출(stemming)\n",
    "- 이 둘의 결과가 어떻게 다른 지 확인  \n",
    "  \n",
    "\n",
    "- 두 작업이 갖고 있는 의미\n",
    "  - 눈으로 봤을 때는 서로 다른 단어들이지만, 하나의 단어로 일반화시켜서 문서 내의 단어 수를 줄이겠다.  \n",
    "\n",
    "\n",
    "- 이러한 방법들은 단어의 빈도수를 기반으로 문제를 풀고자 하는 BoW(Bag of Words) 표현을 사용하는 자연어 처리 문제에서 주로 사용됨\n",
    "- 자연어 처리에서 전처리, 더 정확히는 정규화의 지향점은 언제나 갖고 있는 코퍼스로부터 복잡성을 줄이는 일이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KSplmIDNqRmi"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HRsA2i_EqSVI"
   },
   "source": [
    "## 3.1 표제어 추출 (Lemmatization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G2kXA6VoqWLv"
   },
   "source": [
    "### 3.1.1 표제어 (Lemma)\n",
    "\n",
    "- 한글로는 '표제어' 또는 '기본 사전형 단어' 정도의 의미를 갖는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szQPLf37qh2n"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EIwfBKRqqij3"
   },
   "source": [
    "### 3.1.2 표제어 추출\n",
    "\n",
    "- 단어들로부터 표제어를 찾아가는 과정\n",
    "- 단어들이 다른 형태를 가지더라도, 그 뿌리 단어를 찾아가서 단어의 개수를 줄일 수 있는 지 판단"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NTF3fh6GqstC"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aFkJJ1NPqtae"
   },
   "source": [
    "### 3.1.3 표제어 추출 방법\n",
    "\n",
    "- 먼저 단어의 형태학적 파싱을 진행\n",
    "- 형태학 (morphology)\n",
    "  - 형태소로부터 단어들을 만들어가는 학문  \n",
    "  (형태소 : '의미를 가진 가장 작은 단위')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rE3Fy8eTq7Ru"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SYIagVYKq8Qu"
   },
   "source": [
    "### 3.1.4 형태소의 두 가지 종류\n",
    "\n",
    "1. **어간(stem)**\n",
    "  - 단어의 의미를  담고 있는 단어의 핵심 부분\n",
    "2. **접사(affix)**\n",
    "  - 단어에 추가적인 의미를 주는 부분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P2YY9HoFrLel"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mrG2mHxSrMT1"
   },
   "source": [
    "### 3.1.5 형태학적 파싱\n",
    "\n",
    "- 위 두 가지의 형태소의 구성 요소를 분리하는 작업을 말한다.\n",
    "- ex) cats\n",
    "  - cat (어간)\n",
    "  - -s (접사)  \n",
    "\n",
    "\n",
    "- 꼭 두 가지로 분리하지 않는 경우도 있다.\n",
    "- ex) fox\n",
    "  - 형태학적 파싱을 한다고 하더라도 더 이상 분리할 수 없다.\n",
    "  - fox는 독립적인 형태소이기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X93WLmaXrjyj"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sLm-vL2Zrkoc"
   },
   "source": [
    "### 3.1.6 NLTK의 `WordNetLemmatizer`\n",
    "\n",
    "- NLTK에서는 표제어 추출을 위한 도구인 `WordNetLemmatizer`를 지원한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "ZiPBbHwYskr8",
    "outputId": "b7f8fa8d-85d5-4297-b34f-98fcd67810cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  import nltk\n",
    "  nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Be9Wfz_yrvRk",
    "outputId": "f369b667-70f6-43d3-beca-2e745bfb4091"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "n = WordNetLemmatizer()\n",
    "\n",
    "words=['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', \n",
    "       'fly', 'dies', 'watched', 'has', 'starting']\n",
    "\n",
    "print([n.lemmatize(w) for w in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I2UBxEKXryed"
   },
   "source": [
    "- 표제어 추출은 어간 추출과는 달리 단어의 형태가 적절히 보존되는 양상을 보이는 특징이 있다.\n",
    "- 하지만 그럼에도 위 결과에는 `dy`나 `ha`와 같이 의미를 알 수 없는 적절하지 못한 단어를 출력하고 있다.\n",
    "- 이는 표제어 추출기(lemmatizer)가 본래 단어의 **품사 정보**를 알아야만 정확한 결과를 얻을 수 있기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rlhFfydYupNE"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xEk3xehWtGUZ"
   },
   "source": [
    "### 3.1.7 `WordNetLemmatizer`에 단어의 품사 지정\n",
    "\n",
    "- `WordNetLemmatizer`는 입력으로 단어가 동사 품사라는 사실을 알려줄 수 있다.\n",
    "- 즉, dies와 watched, has가 문장에서 동사로 쓰였다는 것을 알려준다면 표제어 추출기는 품사의 정보를 보존하면서 정확한 Lemma를 출력하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5Ny60Q6_ub_3",
    "outputId": "cec6f70b-7a93-4b40-cdf9-1d7211355ccb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'die'"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.lemmatize('dies', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rbYJM0cCuekv",
    "outputId": "eecf37b4-69f0-4404-d1b2-c5f226a411f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'watch'"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.lemmatize('watched', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "7UHjp17guhSb",
    "outputId": "4442a66c-6573-4d4d-c7ab-2bbcfe3a395d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have'"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.lemmatize('has', 'v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8AxwXmxeujgW"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ubX3QY73un43"
   },
   "source": [
    "### 3.1.8 표제어 추출의 품사 정보 보존\n",
    "\n",
    "- 표제어 추출은 문맥을 고려하며, 수행했을 때의 결과는 해당 단어의 품사 정보를 보존한다.  \n",
    "(POS 태그를 보존한다고 말할 수 있다.  \n",
    "  \n",
    "\n",
    "- 반면, 어간 추출을 수행한 결과는 품사 정보가 보존되지 않는다.  \n",
    "(POS 태그를 고려하지 않는다.)\n",
    "- 더 정확히는, 어간 추출을 한 결과는 사전에 존재하지 않는 단어일 경우가 많다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rqtzPeSbvGho"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r-KAMvS9vJZu"
   },
   "source": [
    "## 3.2 어간 추출 (Stemming)\n",
    "\n",
    "- 어간(Stem)을 추출하는 작업\n",
    "- 형태학적 분석을 단순화한 버전\n",
    "- 정해진 규칙만 보고 단어의 어미를 자르는 어림짐작의 작업\n",
    "- 이 작업은 섬세한 작업이 아니기 때문에 어간 추출 후에 나오는 결과 단어는 사전에 존재하지 않는 단어일 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZslWxkPmvLt-"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B6FXI2VBvhdB"
   },
   "source": [
    "### 3.2.1 포터 알고리즘(Porter Algorithm) 실습\n",
    "\n",
    "- 어간 추출 알고리즘 중 하나인 포터 알고리즘(Porter Algorithm)에 아래의 Text를 입력으로 넣는다.\n",
    "\n",
    "**Input**\n",
    "\n",
    "> This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "-5yTOkPSwDLY",
    "outputId": "45c93e05-1740-4af0-c524-8117aa2a763f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  import nltk\n",
    "  nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "sV1kboN0vvqh",
    "outputId": "8b0110a1-d45b-4e23-b7e0-f392835c8f97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', 'Bones', \"'s\", 'chest', ',', 'but', 'an', 'accurate', 'copy', ',', 'complete', 'in', 'all', 'things', '--', 'names', 'and', 'heights', 'and', 'soundings', '--', 'with', 'the', 'single', 'exception', 'of', 'the', 'red', 'crosses', 'and', 'the', 'written', 'notes', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "s = PorterStemmer()\n",
    "\n",
    "text = \"This was not the map we found in Billy Bones's chest, \\\n",
    "but an accurate copy, complete in all things--names and heights and \\\n",
    "soundings--with the single exception of the red crosses and the written notes.\"\n",
    "\n",
    "words = word_tokenize(text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "xKJ3ak7kwA-9",
    "outputId": "e3564270-e8a2-4ef9-8f49-18febfc98a63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'billi', 'bone', \"'s\", 'chest', ',', 'but', 'an', 'accur', 'copi', ',', 'complet', 'in', 'all', 'thing', '--', 'name', 'and', 'height', 'and', 'sound', '--', 'with', 'the', 'singl', 'except', 'of', 'the', 'red', 'cross', 'and', 'the', 'written', 'note', '.']\n"
     ]
    }
   ],
   "source": [
    "print([s.stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w4NMR_FqwQ2M"
   },
   "source": [
    "- 위의 알고리즘의 결과에는 사전에 없는 단어들도 포함되어 있다.\n",
    "- 위의 어간 추출은 단순 규칙에 기반하여 이루어지기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "084eYL-TwtvU"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56wg_dg0wZ-7"
   },
   "source": [
    "### 3.2.2 포터 알고리즘의 어간 추출 규칙\n",
    "\n",
    "- ALIZE $\\rightarrow$ AL\n",
    "- ANCE $\\rightarrow$ 제거\n",
    "- ICAL $\\rightarrow$ IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "16qJBrDTwjNz",
    "outputId": "a807ff12-82a3-465e-9546-e30a77aaee41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['formal', 'allow', 'electric']\n"
     ]
    }
   ],
   "source": [
    "words=['formalize', 'allowance', 'electricical']\n",
    "print([s.stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P2OrpAQEwoDz"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qo_ZxqxZwyba"
   },
   "source": [
    "### 3.2.3 추출 속도\n",
    "\n",
    "- 어간 추출 속도는 표제어 추출보다 일반적으로 빠르다.\n",
    "- 포터 어간 추출기는 정밀하게 설계되어 정확도가 높으므로 영어 자연어 처리에서 어간 추출을 하고자 한다면 가장 준수한 선택이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k_HYMFsPF2ZU"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W_OaGgV5F3Iz"
   },
   "source": [
    "### 3.2.4 포터 알고리즘 vs 랭커스터 스태머(Lancaster Stemmer) 알고리즘\n",
    "\n",
    "- NLTK에서는 포터 알고리즘 외에도 랭커스터 스태머(Lancaster Stemmer) 알고리즘을 지원한다.\n",
    "- 각각의 알고리즘으로 각각 어간 추출을 진행했을 때, 이 둘의 결과를 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9QN9rXRcGGsb",
    "outputId": "03f63524-a2d8-4b9f-fbc0-2a595e214237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['polici', 'do', 'organ', 'have', 'go', 'love', 'live', 'fli', 'die', 'watch', 'ha', 'start']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "s = PorterStemmer()\n",
    "\n",
    "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', \n",
    "         'fly', 'dies', 'watched', 'has', 'starting']\n",
    "\n",
    "print([s.stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "aflA3QgIGSmT",
    "outputId": "b57fa313-7f59-4e1e-82d5-1faffac7c00a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['policy', 'doing', 'org', 'hav', 'going', 'lov', 'liv', 'fly', 'die', 'watch', 'has', 'start']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "l = LancasterStemmer()\n",
    "\n",
    "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', \n",
    "         'fly', 'dies', 'watched', 'has', 'starting']\n",
    "\n",
    "print([l.stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lb5CAR1JGef0"
   },
   "source": [
    "- 동일한 단어들의 나열에 대해서 두 스태머는 전혀 다른 결과를 보여준다.  \n",
    "(두 스태머 알고리즘은 서로 다른 알고리즘을 사용하기 때문)\n",
    "- 그렇기 때문에 이미 알려진 알고리즘을 사용할 때는, 사용하고자 하는 코퍼스에 스태머를 적용해보고 어떤 스태머가 해당 코퍼스에 적합한 지를 판단한 후에 사용해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8E5xWI77HUF3"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yjCLv4lmHUuY"
   },
   "source": [
    "### 3.2.5 규칙 기반 알고리즘이 일반화를 수행하지 못하는 경우\n",
    "\n",
    "- 어간 추출을 하고나서 일반화가 지나치게 되거나, 또는 덜 되거나 하는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FZvLXoIUHgLr"
   },
   "source": [
    "**포터 알고리즘에서 organization을 어간 추출했을 때의 결과**\n",
    "\n",
    "> organization $\\rightarrow$ organ\n",
    "\n",
    "- organization과 organ은 완전히 다른 단어임에도 organization에 대해서 어간 추출 결과 organ이라는 단어가 나왔다.\n",
    "- organ에 대해서 어간 추출을 한다고 하더라도 결과는 역시 organ이 된다.\n",
    "- 따라서 두 단어에 대해서 어간 추출을 한다면 동일한 어간을 갖게 된다.\n",
    "- 이는 어간 추출의 목적에는 맞지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ncGvQ98DH7k-"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r_BB9vwdH8ba"
   },
   "source": [
    "### 3.2.6 같은 단어에 대한 표제어 추출과 어간 추출의 차이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hsqhLRCbIBZO"
   },
   "source": [
    "**Stemming**\n",
    "\n",
    "> am $\\rightarrow$ am  \n",
    "the going $\\rightarrow$ the go  \n",
    "having $\\rightarrow$ hav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7FNzHKkwIN42"
   },
   "source": [
    "**Lemmatization**\n",
    "\n",
    "> am $\\rightarrow$ be  \n",
    "the going $\\rightarrow$ the going  \n",
    "having $\\rightarrow$ have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eFqdGBd1IV8n"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9cbcXpO1IXef"
   },
   "source": [
    "## 3.3 한국어에서의 어간 추출\n",
    "\n",
    "- 한국어의 어간에 대해서 설명\n",
    "- 한국어는 아래의 표와 같이 5언 9품사의 구조를 가지고 있다.\n",
    "\n",
    "| 언       | 품사               |\n",
    "| -------- | ------------------ |\n",
    "| 체언     | 명사, 대명사, 수사 |\n",
    "| 수식언   | 관형사, 부사       |\n",
    "| 관계언   | 조사               |\n",
    "| 독립언   | 감탄사             |\n",
    "| **용언** | **동사, 형용사**   |\n",
    "\n",
    "- 이 중 용언에 해당되는 '동사'와 '형용사'는 어간(stem)과 어미(ending)의 결합으로 구성된다.\n",
    "- 앞으로 용언이라고 언급하는 부분은 전부 동사와 형용사를 포함하여 언급하는 개념이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3H6S4oGKIhHN"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pWrVjoB2JxQr"
   },
   "source": [
    "### 3.3.1 활용 (conjugation)\n",
    "\n",
    "- 활용(conjugation)은 한국어에서만 가지는 특징이 아니라, 인도유럽어(indo-european language)에서도 주로 볼 수 있는 언어적 특징 중 하나를 말하는 통칭적인 개념이다.\n",
    "- 여기서는 한국어에 한정하여 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Su-KuImKAF-"
   },
   "source": [
    "- 활용이란 \"용언의 어간(stem)이 어미(ending)를 가지는 일\"을 말한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EZ-4eZPbKFSS"
   },
   "source": [
    "**어간(stem)**\n",
    "\n",
    "- 용언(동사, 형용사)을 활용할 때, 원칙적으로 모양이 변하지 않는 부분\n",
    "- 활용에서 어미에 선행하는 부분\n",
    "- 때론 어간의 모양도 바뀔 수 있음  \n",
    "(예: 긋다, 긋고, 그어서, 그어라)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tI_1EW21KXGB"
   },
   "source": [
    "**어미(ending)**\n",
    "\n",
    "- 용언의 어간 뒤에 붙어서 활용하면서 변하는 부분\n",
    "- 여러 문법적 기능을 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XiJSlgHTKebe"
   },
   "source": [
    "**활용의 구분**\n",
    "\n",
    "- 활용(conjugation)은 어간이 어미를 취할 때, 어간의 모습이 일정하다면 규칙 활용, 어간이나 어미의 모습이 변하는 불규칙 활용으로 나뉜다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u4C8plvsKoSh"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f4MkzSl_Kpwz"
   },
   "source": [
    "### 3.3.2 규칙 활용\n",
    "\n",
    "- 규칙 활용은 어간이 어미를 취할 때, 어간의 모습이 일정하다.\n",
    "- 아래 예제는 어간과 어미가 합쳐질 때, 어간의 형태가 바뀌지 않음을 보여준다.\n",
    "\n",
    "```\n",
    "잡/어간 + 다/어미 (잡다)\n",
    "```\n",
    "\n",
    "- 이 경우에는 어간이 어미가 붙기전의 모습과 어미가 붙은 후의 모습이 같으므로, 규칙 기반으로 어미를 단순히 분리해주면 어간이 추출된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZZZ-k9uyK2GY"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GEMRcNeoK-3o"
   },
   "source": [
    "### 3.3.3 불규칙 활용\n",
    "\n",
    "- 불규칙 활용은 어간이 어미를 취할 때 어간의 모습이 바뀌거나 취하는 어미가 특수한 어미일 경우를 말한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r4y_V2JKLH-4"
   },
   "source": [
    "**어간의 형식이 달라지는 경우**\n",
    "\n",
    "```\n",
    " ‘듣-, 돕-, 곱-, 잇-, 오르-, 노랗-’ → ‘듣/들-, 돕/도우-, 곱/고우-, 잇/이-, 올/올-, 노랗/노라-\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9s_YJ39LQ5y"
   },
   "source": [
    "**일반적인 어미가 아닌 특수한 어미를 취하는 경우**\n",
    "\n",
    "```\n",
    "‘오르+ 아/어 → 올라'\n",
    "'하+아/어 → 하여'\n",
    "'이르+아/어 → 이르러'\n",
    "'푸르+아/어 → 푸르러'\n",
    "```\n",
    "\n",
    "- 이 경우에는 어간이 어미가 붙는 과정에서 어간의 모습이 바뀌었으므로 단순한 분리만으로 어간 추출이 되지 않고 좀 더 복잡한 규칙을 필요로 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZbUT3Xr2Law_"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Op2XZdkcLzRX"
   },
   "source": [
    "### 3.3.4 다양한 불규칙 활용의 예\n",
    "\n",
    "- [링크](https://namu.wiki/w/한국어/불규칙%20활용)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ch02_v03_Stemming-and-Lemmatization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
