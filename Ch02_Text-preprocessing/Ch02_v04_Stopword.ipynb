{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NkRWisVsMisS"
   },
   "source": [
    "# Ch02. 텍스트 전처리 (Text Preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1SYzqigNMqsW"
   },
   "source": [
    "# v04. 불용어 (Stopword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p8mzwvd9Mswe"
   },
   "source": [
    "- 갖고 있는 데이터에서 유의미한 단어 토큰만을 선별하기 위해서는 **큰 의미가 없는 단어** 토큰을 제거하는 작업이 필요하다.\n",
    "- 큰 의미가 없는 단어\n",
    "  - 자주 등장하지만 분석을 하는 것에 있어서는 큰 도움이 되지 않는 단어들\n",
    "  - ex) I, my, me, over, 조사, 접미사 같은 단어들  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FyRz989BPLgb"
   },
   "source": [
    "- 이러한 단어들을 **불용어(stopword)**라고 한다.\n",
    "- NLTK에서는 위와 같으 100여개 이상의 영어 단어들을 불용어로 패키지 내에서 미리 정의하고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qkdcONQ-POVR"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NtshOigrPShp"
   },
   "source": [
    "## 4.1 NLTK에서 불용어 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "yZ9PHbniPheO",
    "outputId": "a35ed9a6-efaf-485e-e3b1-54e9cb631a77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "dL4Xjj42PVKM",
    "outputId": "c4eb0108-e7cf-4b83-9724-105b4b9d53f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords.words('english')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2KeHuiOEPaoY"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DLZcwm9iPlrI"
   },
   "source": [
    "## 4.2 NLTK를 통해서 불용어 제거하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "E7ZBGQkQP4oR",
    "outputId": "7516efc7-a0b2-4924-fde2-d7a973027c03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "A6ujibX4Pnvk",
    "outputId": "5883b85e-fcad-49e2-81c8-22c30a3232ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Family', 'is', 'not', 'an', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n",
      "['Family', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "example = \"Family is not an important thing. It's everything.\"\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_tokens = word_tokenize(example)\n",
    "\n",
    "result = []\n",
    "for w in word_tokens:\n",
    "  if w not in stop_words:\n",
    "    result.append(w)\n",
    "\n",
    "print(word_tokens)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nI-xYatWPszw"
   },
   "source": [
    "- 'is', 'not', 'an'과 같은 단어들이 문장에서 제거됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EhQ2gF9hQMPi"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IXFbD93bQNJH"
   },
   "source": [
    "## 4.3 한국어에서 불용어 제거하기\n",
    "\n",
    "- 토큰화 후에 **조사, 접속사** 등을 제거하는 방법을 통해 불용어를 제거할 수 있다.\n",
    "- 하지만 불용어를 제거하려고 하다보면 조사나 접속사와 같은 단어들뿐만 아니라 **명사, 형용사**와 같은 단어들 중에서 불용어로서 제거하고 싶은 단어들이 생기기도 한다.\n",
    "- 결국에는 사용자가 직접 불용어 사전을 만들게 되는 경우가 많다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Or1Xs2UYQQ_e"
   },
   "source": [
    "### 4.3.1 한국어 불용어 제거 실습\n",
    "\n",
    "- 직접 불용어를 정의\n",
    "- 주어진 문장으로부터 직접 정의한 불용어 사전을 참고로 불용어를 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "JOMzvuXRQPEj",
    "outputId": "080c2b72-8e2a-46fa-aa6e-450420b829b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['고기를', '아무렇게나', '구우려고', '하면', '안', '돼', '.', '고기라고', '다', '같은', '게', '아니거든', '.', '예컨대', '삼겹살을', '구울', '때는', '중요한', '게', '있지', '.']\n",
      "['고기를', '구우려고', '안', '돼', '.', '고기라고', '다', '같은', '게', '.', '삼겹살을', '구울', '때는', '중요한', '게', '있지', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "example = \"고기를 아무렇게나 구우려고 하면 안 돼. 고기라고 다 같은 게 아니거든. \\\n",
    "예컨대 삼겹살을 구울 때는 중요한 게 있지.\"\n",
    "\n",
    "stop_words = \"아무거나 아무렇게나 어찌하든지 같다 비슷하다 예컨대 이럴정도로 하면 아니거든\"\n",
    "# 위의 불용어는 명사가 아닌 단어 중에서 저자가 임의로 선정한 것으로 실제 의미있는 선정 기준이 아님\n",
    "\n",
    "stop_words = stop_words.split(' ')\n",
    "word_tokens = word_tokenize(example)\n",
    "\n",
    "result = []\n",
    "for w in word_tokens:\n",
    "  if w not in stop_words:\n",
    "    result.append(w)\n",
    "\n",
    "# 위의 4줄은 아래의 한 줄로 대체 가능\n",
    "# result = [word for word in word_tokens if word not in stop_words]\n",
    "\n",
    "print(word_tokens)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mftL3gPdRWkg"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tRK0uZXhRl-o"
   },
   "source": [
    "### 4.3.2 보편적으로 선택할 수 있는 한국어 불용어 리스트\n",
    "\n",
    "- [링크 1](https://www.ranks.nl/stopwords/korean)\n",
    "- [링크 2](https://bab2min.tistory.com/544)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RW8RTs0CRxXq"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mKi-E_x2RaPs"
   },
   "source": [
    "### 4.3.3 더 좋은 한국어 불용어 제거 방법\n",
    "\n",
    "- 코드 내에서 직접 정의하지 않고 txt 파일이나 csv 파일로 수많은 불용어를 정리해놓고, 이를 불러와서 사용하는 방법"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ch02_v04_Stopword.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
