{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IGd4FpmMm83-"
   },
   "source": [
    "# Ch03. 언어 모델 (Language Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zDvITNu-n4J8"
   },
   "source": [
    "# v05. 펄플렉서티(Perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HdUNv9Jcn-9M"
   },
   "source": [
    "**외부 평가(extrinsic evaluation)**\n",
    "\n",
    "- 두 개의 모델 A, B가 있을 때 이 모델의 성능은 어떻게 비교할 수 있을까?\n",
    "  - 두 개의 모델을 오타 교정, 기계 번역 등의 평가에 투입해볼 수 있음\n",
    "  - 그리고 두 모델이 해당 업무의 성능을 누가 더 잘했는 지를 비교하면 된다.  \n",
    "\n",
    "\n",
    "- 그런데 두 모델의 성능을 비교하고자, 일일히 모델들에 대해서 실제 작업을 시켜보고 정확도를 비교하는 작업은 공수가 너무 많이 드는 작업이다.\n",
    "- 만약 비교해야 하는 모델이 두 개가 아니라 그 이상의 수라면 시간은 비교해야 하는 모델의 수만큼 배로 늘어날 수 있다.  \n",
    "  \n",
    "\n",
    "- 이러한 평가를 외부 평가(extrinsic evaluation)라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-h_twZ6cuxii"
   },
   "source": [
    "<br>\n",
    "\n",
    "**펄플렉서티(perplexity)**\n",
    "\n",
    "- 이러한 외부 평가보다는 어쩌면 조금은 부정확할 수는 있어도 테스트 데이터에 대해서 빠르게 식으로 계산되는 더 간단한 평가 방법이 있다.\n",
    "- 바로 모델 내에서 자신의 성능을 수치화하여 결과를 내놓는 **내부 평가(Intrinsic evaluation)**에 해당되는 **펄플렉서티(perplexity)**이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W4FMuSnpvlaD"
   },
   "source": [
    "## 5.1 언어 모델의 평가 방법(Evaluation metric): PPL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E7qowSP9vGBu"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 5.1.1 PPL의 의미\n",
    "\n",
    "- 펄플렉서티(perplexity)는 언어 모델을 평가하기 위한 내부 평가 지표이다.\n",
    "- 줄여서 PPL이라고 한다.  \n",
    "  \n",
    "\n",
    "- 영어에서 'perplexed'는 '헷갈리는'과 유사한 의미를 갖는다.\n",
    "- 그러므로 PPL은 '헷갈리는 정도'로 이해하면 된다.  \n",
    "  \n",
    "\n",
    "- PPL은 수치가 '낮을수록' 언어 모델의 성능이 좋다는 것을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YjoLCaeBvfuN"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 5.1.2 PPL의 계산\n",
    "\n",
    "- PPL은 **단어의 수로 정규화(normalization)된 테스트 데이터에 대한 확률의 역수**이다.\n",
    "- PPL을 최소화한다 $\\rightarrow$ 문장의 확률을 최대화한다.  \n",
    "  \n",
    "\n",
    "- 문장 $W$의 길이가 $N$이라고 했을 때의 PPL은 다음과 같다.\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "PPL(W) = {P(w_1, w_2, w_3, \\cdots, w_N)}^{-{1 \\over N}} = N \\sqrt{{1 \\over {P(w_1, w_2, w_3, \\cdots, w_N)}}}\n",
    "$\n",
    "\n",
    "- 문장의 확률에 연쇄 법칙(chain rule)을 적용하면 아래와 같다.\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "PPL(W) = N \\sqrt{{1 \\over {P(w_1, w_2, w_3, \\cdots, w_N)}}} = N \\sqrt{{1 \\over { \\prod_{i=1}^N P(w_i \\; | \\; w_1, w_2, w_3, \\cdots, w_{i-1})}}}\n",
    "$\n",
    "\n",
    "- 여기에 n-gram을 적용해볼 수도 있다.\n",
    "- 예를 들어 bigram 언어 모델의 경우에는 식이 아래와 같다.\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "PPL(W) = N \\sqrt{{1 \\over { \\prod_{i=1}^N P(w_i \\; | \\; w_{i-1})}}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vyBQACUIxBX0"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 5.2 분기 계수 (Branching factor)\n",
    "\n",
    "- PPL은 선택할 수 있는 가능한 경우의 수를 의미하는 **분기계수(branching factor)**이다.\n",
    "- PPL은 이 언어 모델이 특정 시점에서 평균적으로 몇 개의 선택지를 가지고 고민하고 있는 지를 의미한다.  \n",
    "  \n",
    "\n",
    "- ex) 언어 모델에 어떤 테스트 데이터를 주고 측정했더니 PPL이 10이 나왔다고 가정\n",
    "  - 그렇다면 해당 언어 모델은 테스트 데이터에 대해서 다음 단어를 예측하는 모든 시점(time-step)마다 평균적으로 10개의 단어를 가지고 어떤 것이 정답인지 고민하고 있다고 볼 수 있다.\n",
    "\n",
    "\n",
    "- 같은 테스트 데이터에 대해서 두 언어 모델의 PPL을 각각 계산한 후에 PPL의 값을 비교하면, 두 언어 모델 중 어떤 것이 성능이 좋은 지도 판단이 가능하다.\n",
    "- 당연히 PPL이 더 낮은 모델의 성능이 더 좋다고 볼 수 있다.\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "PPL(W) = {P(w_1, w_2, w_3, \\cdots, w_N)}^{-{1 \\over N}} = {\\left({1 \\over 10}^N\\right)}^{-{1 \\over N}} = {1 \\over 10}^{-1} = 10\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TcaVF-7eyUiw"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 5.2.1 주의사항\n",
    "\n",
    "- 단, 평가 방법에 있어서 주의할 점은 PPL의 값이 낮다는 것은 테스트 데이터 상에서 높은 정확도를 보인다는 것을 의미한다.\n",
    "- 이는 사람이 직접 느끼기에 좋은 언어 모델이라는 것을 반드시 의미하진 않는다.  \n",
    "  \n",
    "  \n",
    "- 또한 언어 모델의 PPL은 테스트 데이터에 의존하므로 두 개 이상의 언어 모델을 비교할 때는 정량적으로 양이 많고, 또한 도메인에 알맞은 동일한 테스트 데이터를 사용해야 신뢰도가 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GEBiOjocyr0R"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 5.3 기존 언어 모델 Vs. 인공 신경망을 이용한 언어 모델\n",
    "\n",
    "- PPL의 실제 사용 사례를 확인  \n",
    "  \n",
    "\n",
    "- 페이스북 AI 연구팀은 우리가 앞서 배운 n-gram 언어 모델과 이후 배우게 될 딥 러닝을 이용한 언어 모델에 대해서 PPL로 성능 테스트를 한 표를 공개했다.  \n",
    "<img src=\"https://wikidocs.net/images/page/21697/ppl.PNG\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oTAtp239zIi2"
   },
   "source": [
    "**통계적 언어 모델**\n",
    "\n",
    "- Interpolated Kneser-Ney 5-gram\n",
    "  - n-gram을 이용한 언어 모델\n",
    "  - PPL이 67.6으로 측정됨\n",
    "  - 5-gram 사용\n",
    "  - Interpolated Kneser-Ney : 일반화 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wCVcfZt4zYeZ"
   },
   "source": [
    "**인공 신경망을 이용한 언어 모델**\n",
    "\n",
    "- 그 외의 다른 모델들\n",
    "- 인공 신경망을 이용한 언어 모델들은 대부분 n-gram을 이용한 언어 모델보다 더 좋은 성능 평가를 받았음을 확인할 수 있다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ch03_v05_Perplexity.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
