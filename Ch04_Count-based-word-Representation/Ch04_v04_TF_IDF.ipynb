{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TOaj731RBHR5"
   },
   "source": [
    "# Ch04. 카운트 기반의 단어 표현(Count based word Representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1vivwHCqBOGo"
   },
   "source": [
    "# v04. TF-IDF (Term Frequency-Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sLFWVwzLBSvf"
   },
   "source": [
    "- DTM 내에 있는 각 단어에 대한 중요도를 계산할 수 있는 TF-IDF 가중치에 대해서 확인\n",
    "- TF-IDF를 사용하면, 기존의 DTM을 사용하는 것보다 더 많은 정보를 고려하여 문서들을 비교할 수 있다.\n",
    "- 하지만 TF-IDF가 DTM보다 항상 성능이 뛰어나진 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p-TdI1r0BkX-"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 4.1 TF-IDF (단어 빈도-역 문서 빈도, Term Frequency-Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XDEpn5TyBqlW"
   },
   "source": [
    "- TF-IDF는 **단어의 빈도**와 **역 문서 빈도(문서의 빈도에 특정 식을 취함)**를 사용하여 DTM 내의 각 단어들마다 중요한 정도를 가중치로 주는 방법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jmuA4w5aB3ek"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 4.1.1 사용 방법\n",
    "\n",
    "- DTM을 만듬\n",
    "- TF-IDF 가중치를 부여"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NBODkNzIB9GI"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 4.1.2 TF-IDF 주요 용도\n",
    "\n",
    "- 문서의 유사도를 구하는 작업\n",
    "- 검색 시스템에서 검색 결과의 중요도를 정하는 작업\n",
    "- 문서 내에서 특정 단어의 중요도를 구하는 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MSjB2_CeCRdE"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 4.1.3 TF-IDF 수식 표현\n",
    "\n",
    "- TF-IDF는 TF와 IDF를 곱한 값을 의미  \n",
    "  \n",
    "\n",
    "- d : 문서\n",
    "- t : 단어\n",
    "- n : 문서의 총 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HGohMgC9DN8J"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 4.1.3.1 tf(d,t)\n",
    "\n",
    "- 특정 문서 d에서의 특정 단어 t의 등장 횟수  \n",
    "  \n",
    "\n",
    "- TF는 앞에서 배운 DTM의 예제에서 각 단어들이 가진 값들이다.\n",
    "- DTM이 각 문서에서의 각 단어의 등장 빈도를 나타내는 값이었기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f7JPkmkDDpSw"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 4.1.3.2 df(t)\n",
    "\n",
    "- 특정 단어 t가 등장한 문서의 수  \n",
    "  \n",
    "\n",
    "- 특정 단어가 각 문서, 또는 문서들에서 몇 번 등장했는 지는 관심가지지 않는다.\n",
    "- 오직 특정 단어 t가 등장한 **문서의 수**에만 관심을 가진다.\n",
    "- 심지어 특정 단어가 하나의 문서에서 100번 등장했고, 또 다른 문서에서 200번 등장했다고 하더라도 해당 단어의 df는 2가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VTAPfBZa0AfZ"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 4.1.3.3 idf(d, t)\n",
    "\n",
    "- df(t)에 반비례하는 수\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "idf(d, t) = log \\left( {n \\over {1 + df(t)}} \\right)\n",
    "$\n",
    "\n",
    "- IDF는 DF의 역수를 취하고 싶은 것이 맞다.\n",
    "- 하지만 log를 사용하지 않았을 때, IDF를 DF의 역수(${n \\over df(t)}$ 라는 식)로 사용한다면, 총 문서의 수 n이 커질수록, IDF의 값은 기하급수적으로 커지게 된다.\n",
    "- 그렇기 때문에 log를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QA2ZzZH21DXS"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 4.1.3.4 log의 필요성 확인\n",
    "\n",
    "- n = 1,000,000일 때의 예"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N8ylsX_00lbo"
   },
   "source": [
    "\n",
    "**1) log를 사용한 경우의 idf**\n",
    "\n",
    "- log의 밑은 10을 사용한다고 가정했을 때 결과는 아래와 같다.\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "idf(d,t) = log(n/df(t))  \n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "n = 1,000,000\n",
    "$\n",
    "\n",
    "| 단어 t | df(t) | idf(d,t) |\n",
    "| :------ | :--------- | :--------------- |\n",
    "| word1   | 1          | 6                |\n",
    "| word2   | 100        | 4                |\n",
    "| word3   | 1,000      | 3                |\n",
    "| word4   | 10,000     | 2                |\n",
    "| word5   | 100,000    | 1                |\n",
    "| word6   | 1,000,000  | 0                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c1PlGJgW1Kis"
   },
   "source": [
    "**2) log를 사용하지 않은 경우의 idf**\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "idf(d,t) = n/df(t)\n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "n = 1,000,000\n",
    "$\n",
    "\n",
    "| 단어 t | df(t)     | idf(d,t)  |\n",
    "| :----- | :-------- | :-------- |\n",
    "| word1  | 1         | 1,000,000 |\n",
    "| word2  | 100       | 10,000    |\n",
    "| word3  | 1,000     | 1,000     |\n",
    "| word4  | 10,000    | 100       |\n",
    "| word5  | 100,000   | 10        |\n",
    "| word6  | 1,000,000 | 1         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zPHtwx6d1NTG"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 4.1.3.5 log 안의 식에서 분모에 1을 더해주는 이유\n",
    "\n",
    "- 특정 단어가 전체 문서에서 등장하지 않을 경우에 분모가 0이 되는 상황을 방지하기 위함이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mWFkjO812eYo"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 4.1.4 TF-IDF의 단어 중요도\n",
    "\n",
    "- TF-IDF는 모든 문서에서 자주 등장하는 단어는 중요도가 낮다고 판단한다.\n",
    "  - TF-IDF 값이 낮으면 중요도가 낮은 것이다.\n",
    "  - ex) a, the 와 같은 불용어 등  \n",
    "\n",
    "\n",
    "- 특정 문서에서만 자주 등장하는 단어는 중요도가 높다고 판단한다.\n",
    "  - TF-IDF 값이 크면 중요도가 큰 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ojXjYUFr5CHA"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 4.1.5 DTM을 통한 TF-IDF 계산\n",
    "\n",
    "\n",
    "| -     | 과일이 | 길고 | 노란 | 먹고 | 바나나 | 사과 | 싶은 | 저는 | 좋아요 |\n",
    "| :---- | :----- | :--- | :--- | :--- | :----- | :--- | :--- | :--- | :----- |\n",
    "| 문서1 | 0      | 0    | 0    | 1    | 0      | 1    | 1    | 0    | 0      |\n",
    "| 문서2 | 0      | 0    | 0    | 1    | 1      | 0    | 1    | 0    | 0      |\n",
    "| 문서3 | 0      | 1    | 1    | 0    | 2      | 0    | 0    | 0    | 0      |\n",
    "| 문서4 | 1      | 0    | 0    | 0    | 0      | 0    | 0    | 1    | 1      |\n",
    "\n",
    "- TF-IDF = TF x IDF  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PfWazBF65KrG"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 4.1.5.1 TF 계산\n",
    "\n",
    "- 앞서 사용한 DTM을 그대로 사용\n",
    "- 그것이 각 문서에서의 각 단어의 TF가 된다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W-9p77S23Ohz"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 4.1.5.2 IDF 계산\n",
    "\n",
    "- 로그는 자연 로그를 사용한다. (자연로그 : 로그의 밑을 자연 상수 e(e=2.718281...)를 사용하는 로그)\n",
    "- IDF 계산을 위해 사용하는 로그의 밑은 TF-IDF를 사용하는 사용자가 임의로 정할 수 있다.\n",
    "- 여기서 로그는 마치 기존의 값에 곱하여 값의 크기를 조절하는 상수의 역할을 한다.\n",
    "- 그런데 보통 각종 프로그래밍 언어나 프로그램에서 패키지로 지원하는 TF-IDF의 로그는 대부분 자연 로그를 사용한다.\n",
    "- 자연 로그는 보통 log라고 표현하지 않고, ln이라고 표현한다.  \n",
    "\n",
    "| 단어   | IDF(역 문서 빈도)      |\n",
    "| :----- | :--------------------- |\n",
    "| 과일이 | ln(4/(1+1)) = 0.693147 |\n",
    "| 길고   | ln(4/(1+1)) = 0.693147 |\n",
    "| 노란   | ln(4/(1+1)) = 0.693147 |\n",
    "| 먹고   | ln(4/(2+1)) = 0.287682 |\n",
    "| 바나나 | ln(4/(2+1)) = 0.287682 |\n",
    "| 사과   | ln(4/(1+1)) = 0.693147 |\n",
    "| 싶은   | ln(4/(2+1)) = 0.287682 |\n",
    "| 저는   | ln(4/(1+1)) = 0.693147 |\n",
    "| 좋아요 | ln(4/(1+1)) = 0.693147 |\n",
    "\n",
    "- 문서의 총 수 = 4 $\\rightarrow$ ln 안에서 분자는 4로 동일하다.\n",
    "- 분모의 경우에는 각 단어가 등장한 문서의 수(DF)를 의미한다.  \n",
    "  \n",
    "\n",
    "**각 단어에 대해서 IDF 값을 비교**\n",
    "\n",
    "- 문서 1개에만 등장한 단어와 문서 2개에만 등장한 단어는 값의 차이를 보인다.\n",
    "  - 문서 1개에 등장한 단어의 IDF = 0.693147\n",
    "  - 문서 2개에 등장한 단어의 IDF = 0.287682\n",
    "- 이는 IDF가 여러 문서에서 등장한 단어의 가중치를 낮추는 역할을 하기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JV_FB8ec5Qg8"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 4.1.5.3 TF-IDF 계산\n",
    "\n",
    "- 앞서 사용한 DTM에서 단어별로 위의 IDF값을 그대로 곱해주면 TF-IDF가 나오게 된다.\n",
    "\n",
    "| -     | 과일이   | 길고     | 노란     | 먹고     | 바나나   | 사과     | 싶은     | 저는     | 좋아요   |\n",
    "| :---- | :------- | :------- | :------- | :------- | :------- | :------- | :------- | :------- | :------- |\n",
    "| 문서1 | 0        | 0        | 0        | 0.287682 | 0        | 0.693147 | 0.287682 | 0        | 0        |\n",
    "| 문서2 | 0        | 0        | 0        | 0.287682 | 0.287682 | 0        | 0.287682 | 0        | 0        |\n",
    "| 문서3 | 0        | 0.693147 | 0.693147 | 0        | 0.575364 | 0        | 0        | 0        | 0        |\n",
    "| 문서4 | 0.693147 | 0        | 0        | 0        | 0        | 0        | 0        | 0.693147 | 0.693147 |\n",
    "\n",
    "- 문서 3에서의 바나나만 TF값이 2이므로 IDF에 2를 곱해줌\n",
    "- 나머진 TF 값이 1이므로 그대로 IDF 값을 가져오면 된다.  \n",
    "  \n",
    "\n",
    "- 문서 2에서의 바나나의 TF-IDF 가중치(0.287682)와 문서 3에서의 바나나의 TF-IDF 가중치(0.575364)가 다른 것을 볼 수 있다.\n",
    "  - **(수식적인 관점)** : TF가 각각 1과 2로 달랐기 때문\n",
    "  - **(TF-IDF에서의 관점)** : TF-IDF는 특정 문서에서 자주 등장하는 단어는 그 문서 내에서 중요한 단어로 판단했기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4WKk740J5tiT"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 4.2 사이킷런을 이용한 DTM과 TF-IDF 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZGASFwnpFer3"
   },
   "source": [
    "### 4.2.1 `CountVectorizer` 이용 DTM 생성\n",
    "\n",
    "- DTM 또한 BoW 행렬이기 때문에, 앞서 BoW 챕터에서 배운 `CountVectorizer`를 사용하면 간단히 DTM을 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MiiC1nRrE9q-"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "m-Zb8EW3FBY2",
    "outputId": "6162b3f4-f0be-4072-ee33-b8a229a7fbaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 1 0 1 1]\n",
      " [0 0 1 0 0 0 0 1 0]\n",
      " [1 0 0 0 1 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'you know I want your love',\n",
    "    'I like you',\n",
    "    'what should I do ',    \n",
    "]\n",
    "\n",
    "vector = CountVectorizer()\n",
    "\n",
    "# 코퍼스로부터 각 단어의 빈도수 기록\n",
    "print(vector.fit_transform(corpus).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4T7MfcDjFUeB",
    "outputId": "bc630281-8e25-4add-dcb2-14df4cc625ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "# 각 단어의 인덱스가 어떻게 부여됐는 지 확인\n",
    "print(vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0u0crgJ_Fa0F"
   },
   "source": [
    "- 첫 번째 열 : 0의 인덱스를 가진 \"do\"\n",
    "  - \"do\"는 세 번째 문서에만 등장했기 때문에, 세 번째 행에서만 1의 값을 갖는다.  \n",
    "\n",
    "\n",
    "- 두 번째 열 : 1의 인덱스를 가진 \"know\"\n",
    "  - \"know\"는 첫 번째 문서에서만 등장했기 때문에 첫 번째 행에서만 1의 값을 갖는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ydESSEsGBji"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 4.2.2 `TfidfVectorizer`\n",
    "\n",
    "- 사이킷런은 TF-IDF를 자동 계산해주는 `TfidfVectorizer`를 제공한다.\n",
    "- 사이킷런의 TF-IDF는 위에서 배웠던 보편적인 TF-IDF 식에서 좀 더 조정된 다른 식을 사용한다.\n",
    "  - IDF 계산 시 분자에다가도 1을 더해줌\n",
    "  - TF-IDF에 L2 정규화라는 방법으로 값을 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "5BGlKLbUG1ob",
    "outputId": "981ce91b-42d2-48a4-bf48-e3d61551b00c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46735098 0.         0.46735098 0.         0.46735098\n",
      "  0.         0.35543247 0.46735098]\n",
      " [0.         0.         0.79596054 0.         0.         0.\n",
      "  0.         0.60534851 0.        ]\n",
      " [0.57735027 0.         0.         0.         0.57735027 0.\n",
      "  0.57735027 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'you know I want your love',\n",
    "    'I like you',\n",
    "    'what should I do ',    \n",
    "]\n",
    "\n",
    "tfidfv = TfidfVectorizer().fit(corpus)\n",
    "print(tfidfv.transform(corpus).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "e1oA-tLVHOrd",
    "outputId": "08f8a5f1-2c7a-49e6-a2c1-6a8737aa4e1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "print(tfidfv.vocabulary_)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ch04_v04_TF-IDF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
