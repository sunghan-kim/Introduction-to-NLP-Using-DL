{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rpkGWV3fGLYK"
   },
   "source": [
    "# Ch06. 토픽 모델링 (Topic Modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZlWDiqTZGU1M"
   },
   "source": [
    "# v01. 잠재 의미 분석 (Latent Semantic Analysis, LSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d-47UqXVGZfs"
   },
   "source": [
    "**LSA**\n",
    "\n",
    "- 토픽 모델링을 위해 최적화된 알고리즘은 아니다.\n",
    "- 그렇지만 토픽 모델링이라는 분야에 아이디어를 제공한 알고리즘이라고 볼 수 있다.\n",
    "- 그러므로 토픽 모델링 알고리즘인 **LDA**에 앞서 학습한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CZ06tAeUGxSa"
   },
   "source": [
    "**LDA**\n",
    "\n",
    "- LDA는 LSA의 단점을 개선하여 탄생한 알고리즘\n",
    "- 토픽 모델링에 보다 적합한 알고리즘이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5nyxauw_G6L7"
   },
   "source": [
    "**DTM과 TF-IDF의 단점**\n",
    "\n",
    "- BoW에 기반한 DTM이나 TF-IDF는 기본적으로 단어의 빈도 수를 이용한 수치화 방법이기 때문에 **단어의 의미를 고려하지 못한다**는 단점이 있다.  \n",
    "(이를 토픽 모델링 관점에서는 **단어의 토픽을 고려하지 못한다**고도 한다.)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dx3U6UR-KAtl"
   },
   "source": [
    "**단점 보완 방법**\n",
    "\n",
    "- DTM의 잠재된(Latent) 의미를 이끌어내는 방법으로 잠재 의미 분석(Latent Semantic Analysis, LSA)이라는 방법이 있다.  \n",
    "- 잠재 의미 분석(Latent Semantic Indexing, LSI)이라고도 불린다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bfnJ0nSBKjvk"
   },
   "source": [
    "**특이값 분해(Singular Value Decomposition, SVD)**\n",
    "\n",
    "- LSA 방법을 이해하기 위해서는 선형대수학의 **특이값 분해(Singular Value Decomposition, SVD)**를 이해할 필요가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L1d1EDB1KwM8"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.1 특이값 분해 (Singular Value Decomposition, SVD)\n",
    "\n",
    "- 특이값 분해는 **실수 벡터 공간**에 한정하여 내용을 설명한다.  \n",
    "  \n",
    "\n",
    "- SVD란 $A$가 $m \\times n$ 행렬일 때, 다음과 같이 3개의 행렬의 곱으로 분해(decomposition)하는 것을 말한다.\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "a = U \\, \\sum V^T\n",
    "$\n",
    "\n",
    "- 여기서 각 3개의 행렬은 다음과 같은 조건을 만족한다.\n",
    "  - $U$\n",
    "    - $m \\times m$ 직교 행렬\n",
    "    - $A\\,A^T = U \\, \\left( \\sum \\, \\sum^T \\right) \\, U^T$\n",
    "  - $V$\n",
    "    - $n \\times n$ 직교 행렬\n",
    "    - $A^T\\,A = V \\, \\left( \\sum^T \\, \\sum \\right) \\, V^T$\n",
    "  - $\\sum$\n",
    "    - $m \\times n$ 직사각 대각행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j6QJfOesM4t8"
   },
   "source": [
    "**직교행렬(orthogonal matrix)**\n",
    "\n",
    "- 자신과 자신의 전치 행렬(transposed matrix)의 곱 또는 이를 반대로 곱한 결과가 **단위행렬(identity matrix)**이 되는 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZVcDZEHRNDCj"
   },
   "source": [
    "**대각행렬(diagonal matrix)**\n",
    "\n",
    "- 주대각선을 제외한 곳의 원소가 모두 0인 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3pXIfsFTNJ2j"
   },
   "source": [
    "**특이값(singular value)**\n",
    "\n",
    "- 이 때 SVD로 나온 대각 행렬의 대각 원소의 값을 행렬 $A$의 **특이값(singular value)**라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wer5QYt8NWgT"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.1 전치 행렬 (Transposed Matrix)\n",
    "\n",
    "- 원래의 행렬에서 행과 열을 바꾼 행렬\n",
    "- 즉, 주 대각선을 축으로 반사 대칭을 하여 얻는 행렬\n",
    "- 기호 : 기존 행렬 표현의 우측 위에 $T$를 붙인다. (ex) 기존 행렬 : $M$ $\\rightarrow$ 전치 행렬 : $M^T$)\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "M = \n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4 \\\\\n",
    "5 & 6\n",
    "\\end{bmatrix}\n",
    "\\qquad\n",
    "M^T = \n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6\n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h6lRROhpOWCe"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.2 단위 행렬 (Identity Matrix)\n",
    "\n",
    "- 주대각선의 원소가 모두 1이며, 나머지 원소는 모두 0인 정사각 행렬\n",
    "- 기호 : $I$\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "I = \n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "\\qquad\n",
    "I = \n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SmAlDp7UO0HM"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.3 역행렬 (Inverse Matrix)\n",
    "\n",
    "- 행렬 $A$와 어떤 행렬을 곱했을 때, 결과로서 단위 행렬이 나오면 이 때의 어떤 행렬을 행렬 $A$의 역행렬이라고 한다.\n",
    "- 기호 : $A^{-1}$\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "A \\times A^{-1} = I\n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6 \\\\\n",
    "7 & 8 & 9 \n",
    "\\end{bmatrix}\n",
    "\\times\n",
    "\\begin{bmatrix}\n",
    "  &   &   \\\\\n",
    "  & ? &   \\\\\n",
    "  &   &   \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KMmUFhw8Phoa"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.4 직교 행렬 (Orthogonal Matrix)\n",
    "\n",
    "- 실수 $n \\times n$ 행렬 $A$에 대해서 다음 2가지 조건을 동시에 만족하면 행렬 $A$를 직교 행렬이라고 한다.\n",
    "  - $A \\times A^T = I$\n",
    "  - $A^T \\times A = I$\n",
    "- 역행렬 정의에 따라 직교 행렬은 $A^{-1} = A^T$를 만족한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-a2pcfswTlCk"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.5 대각 행렬 (Diagonal Matrix)\n",
    "\n",
    "- 주대각선을 제외한 곳의 원소가 모두 0인 행렬\n",
    "- 주대각선의 원소를 $a$로 표기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uc3s3kYUTtgm"
   },
   "source": [
    "**1) 정사각 대각 행렬**\n",
    "\n",
    "- 대각 행렬 $\\sum$가 $3 \\times 3$ 행렬인 경우\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "\\sum = \n",
    "\\begin{bmatrix}\n",
    "a & 0 & 0 \\\\\n",
    "0 & a & 0 \\\\\n",
    "0 & 0 & a \n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__ZM77wzT4Xq"
   },
   "source": [
    "**2) 직사각 대각 행렬 ($m > n$)**\n",
    "\n",
    "- 행의 크기가 열의 크기보다 큰 경우\n",
    "- 즉, $m \\times n$ 행렬일 때, $m > n$인 경우\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "\\sum = \n",
    "\\begin{bmatrix}\n",
    "a & 0 & 0 \\\\\n",
    "0 & a & 0 \\\\\n",
    "0 & 0 & a \\\\\n",
    "0 & 0 & 0 \n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3c2eY7wuUhrk"
   },
   "source": [
    "**3) 직사각 대각 행렬 ($m < n$)**\n",
    "\n",
    "- 행의 크기가 열의 크기보다 작은 경우\n",
    "- 즉, $m \\times n$ 행렬일 때, $m < n$인 경우\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "\\sum = \n",
    "\\begin{bmatrix}\n",
    "a & 0 & 0 & 0 \\\\\n",
    "0 & a & 0 & 0 \\\\\n",
    "0 & 0 & a & 0 \n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Dog9OWZVGar"
   },
   "source": [
    "**4) SVD를 통해 나온 대각 행렬 $\\sum$의 추가적인 성질**\n",
    "\n",
    "- 대각 행렬 $\\sum$의 주대각 원소를 행렬 $A$의 **특이값(singular value)**라고 한다.\n",
    "- 이 특이값을 $\\sigma_1, \\sigma_2, \\cdots, \\sigma_r$라고 표현한다고 했을 때 특이값 $\\sigma_1, \\sigma_2, \\cdots, \\sigma_r$은 **내림차순으로 정렬**되어 있다는 특징을 가진다.  \n",
    "  \n",
    "\n",
    "- 아래의 그림은 특이값 12.4, 9.5, 1.3이 내림차순으로 정렬되어져 있는 모습니다.\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "\\sum = \n",
    "\\begin{bmatrix}\n",
    "12.4 & 0   & 0 \\\\\n",
    "0    & 9.5 & 0 \\\\\n",
    "0    & 0   & 1.3 \n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LjrtkZGUV1O3"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.2 절단된 SVD (Truncated SVD)\n",
    "\n",
    "- 위에서 설명한 SVD를 풀 SVD(full SVD)라고 한다.\n",
    "- 하지만 LSA의 경우 풀 SVD에서 나온 3개의 행렬에서 일부 벡터들을 삭제시킨 절단된 SVD(truncated SVD)를 사용하게 된다.  \n",
    "<img src=\"https://wikidocs.net/images/page/24949/svd%EC%99%80truncatedsvd.PNG\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfjXqoBsXGWn"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.2.1 $t$의 의미\n",
    "\n",
    "- 절단된 SVD는 대각 행렬 $\\sum$의 대각 원소의 값 중에서 상위값 $t$개만 남게 된다.\n",
    "- 절단된 SVD를 수행하면 값의 손실이 일어나므로 기존의 행렬 $A$를 복구할 수 없다.\n",
    "- 또한, $U$행렬과 $V$행렬의 $t$열까지만 남는다.\n",
    "- 여기서 $t$는 우리가 찾고자 하는 **토픽의 수를 반영한 하이퍼파라미터값**이다.\n",
    "  - 하이퍼파라미터 : 사용자가 직접 값을 선택하며 성능에 영향을 주는 매개변수\n",
    "- $t$를 선택하는 것은 쉽지 않은 일이다.\n",
    "  - $t$를 크게 잡는 경우 : 기존의 행렬 $A$로부터 다양한 의미를 가져갈 수 있다.\n",
    "  - $t$를 작게 잡는 경우 : 노이즈를 제거할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4vTydtJKXJrX"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.2.2 데이터의 차원 줄이기의 효과\n",
    "\n",
    "- 이렇게 일부 벡터들을 삭제하는 것을 데이터의 차원을 줄인다고 말하기도 한다.\n",
    "- 데이터의 차원을 줄이게 되면 당연히 풀 SVD를 했을 때보다 직관적으로 **계산 비용이 낮아지는 효과**를 얻을 수 있다.  \n",
    "  \n",
    "\n",
    "- 계산 비용이 낮아지는 것 외에도 **상대적으로 중요하지 않은 정보를 삭제하는 효과**를 갖는다.\n",
    "  - 영상 처리 분야에서는 노이즈를 제거한다는 의미를 가짐\n",
    "  - 자연어 처리 분야에서는 설명력이 낮은 정보를 삭제하고 설명력이 높은 정보를 남긴다는 의미를 가짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_I2DUTSbXYgy"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.3 잠재 의미 분석 (Latent Semantic Analysis, LSA)\n",
    "\n",
    "### 1.3.1 LSA의 아이디어\n",
    "\n",
    "- 기존의 DTM이나 DTM에 단어의 중요도에 따라 가중치를 주었던 TF-IDF 행렬은 단어의 의미를 전혀 고려하지 못한다는 단점을 갖고 있다.\n",
    "- LSA는 기본적으로 DTM이나 TF-IDF 행렬에 절단된 SVD(truncated SVD)를 사용하여 차원을 축소시키고, 단어들의 잠재적인 의미를 끌어낸다는 아이디어를 갖고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_zSwRuibYL2o"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.2 DTM 생성\n",
    "\n",
    "| -     | 과일이 | 길고 | 노란 | 먹고 | 바나나 | 사과 | 싶은 | 저는 | 좋아요 |\n",
    "| :---- | :----- | :--- | :--- | :--- | :----- | :--- | :--- | :--- | :----- |\n",
    "| 문서1 | 0      | 0    | 0    | 1    | 0      | 1    | 1    | 0    | 0      |\n",
    "| 문서2 | 0      | 0    | 0    | 1    | 1      | 0    | 1    | 0    | 0      |\n",
    "| 문서3 | 0      | 1    | 1    | 0    | 2      | 0    | 0    | 0    | 0      |\n",
    "| 문서4 | 1      | 0    | 0    | 0    | 0      | 0    | 0    | 1    | 1      |\n",
    "\n",
    "- 위와 같은 DTM을 실제로 파이썬을 통해서 만들면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wlbk2nrkYWMa"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "mLF6ig2KYYrD",
    "outputId": "82af0750-d56c-4159-e1c3-1ca5b8069822"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[0,0,0,1,0,1,1,0,0],\n",
    "              [0,0,0,1,1,0,1,0,0],\n",
    "              [0,1,1,0,2,0,0,0,0],\n",
    "              [1,0,0,0,0,0,0,1,1]])\n",
    "\n",
    "np.shape(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xv-bLb00YhiB"
   },
   "source": [
    "- 4 x 9의 크기를 가지는 DTM이 생성됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-Cips9UYpBc"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.3 풀 SVD(full SVD) 수행\n",
    "\n",
    "- 여기서는 대각 행렬의 변수명을 $\\sum$가 아니라 `S`를 사용한다.\n",
    "- $V$의 전치 행렬을 `VT`라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mpz7bKrMY20q"
   },
   "outputs": [],
   "source": [
    "U, s, VT = np.linalg.svd(A, full_matrices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZfXEjh0QZI7w"
   },
   "source": [
    "<br>\n",
    "\n",
    "**1) 직교 행렬 `U`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "8s6OwpayY72p",
    "outputId": "6e8763f3-2727-4524-cdc3-6b58f26f1358"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.24  0.75  0.   -0.62]\n",
      " [-0.51  0.44 -0.    0.74]\n",
      " [-0.83 -0.49 -0.   -0.27]\n",
      " [-0.   -0.    1.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(U.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "v7AXfmISY96R",
    "outputId": "ca2eb6f9-15cc-4540-972f-bb71053ce2b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qcAGOeuGZBCo"
   },
   "source": [
    "- 4 x 4의 크기를 가지는 직교 행렬 `U`가 생성됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHZqB5f3ZNeB"
   },
   "source": [
    "<br>\n",
    "\n",
    "**2) 대각 행렬 `S`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ML7GOZLRZRTp",
    "outputId": "64549313-7d8d-41f2-81be-71f8bdf01c8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.69 2.05 1.73 0.77]\n"
     ]
    }
   ],
   "source": [
    "print(s.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "snGc9_2haU6u",
    "outputId": "f73d8c8e-12aa-4ce6-c477-b77461bf1048"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nJNWnZA3aWuG"
   },
   "source": [
    "- Numpy의 `linalg.svd()`는 특이값 분해의 결과로 대각 행렬이 아니라 특이값의 리스트를 반환한다.\n",
    "- 그러므로 앞서 본 수식의 형식으로 보려면 이를 다시 대각 행렬로 바꾸어 주어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MLDw1uk2akBF"
   },
   "source": [
    "- 우선 특이값을 `s`에 저장하고 대각 행렬 크기의 행렬을 생성한 후에 그 행렬에 특이값을 삽입한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "y4yvqcXqapdl",
    "outputId": "82899102-9000-4cd0-fd1d-ebf1aec98e43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.69 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   2.05 0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   1.73 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.77 0.   0.   0.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "S = np.zeros((4, 9)) # 대각 행렬의 크기인 4 x 9의 임의의 행렬 생성\n",
    "S[:4, :4] = np.diag(s) # 특이값을 대각행렬에 삽입\n",
    "print(S.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gy1w3f2Aa5Iw",
    "outputId": "e53372a4-e4ad-4c20-dec6-2bbf1d65ce8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_B_Qfkpba7k1"
   },
   "source": [
    "- 4 x 9의 크기를 가지는 대각 행렬 `S`가 생성됨\n",
    "- 2.69 > 2.05 > 1.73 > 0.77 순으로 값이 내림차순을 보이는 것을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BIzsz1zAbFs8"
   },
   "source": [
    "<br>\n",
    "\n",
    "**3) 직교 행렬 `VT`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "-YrWrQWSbKmM",
    "outputId": "e83a4bc3-406b-4028-bfaa-b9bcf5ee88f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.   -0.31 -0.31 -0.28 -0.8  -0.09 -0.28 -0.   -0.  ]\n",
      " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]\n",
      " [ 0.58 -0.    0.    0.   -0.    0.   -0.    0.58  0.58]\n",
      " [ 0.   -0.35 -0.35  0.16  0.25 -0.8   0.16 -0.   -0.  ]\n",
      " [-0.   -0.78 -0.01 -0.2   0.4   0.4  -0.2   0.    0.  ]\n",
      " [-0.29  0.31 -0.78 -0.24  0.23  0.23  0.01  0.14  0.14]\n",
      " [-0.29 -0.1   0.26 -0.59 -0.08 -0.08  0.66  0.14  0.14]\n",
      " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19  0.75 -0.25]\n",
      " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19 -0.25  0.75]]\n"
     ]
    }
   ],
   "source": [
    "print(VT.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ELQ_5YWZbOck",
    "outputId": "c32e3e71-0526-462d-ad12-5d071eb4d555"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(VT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H3URvEbFbPz8"
   },
   "source": [
    "- 9 x 9의 크기를 가지는 직교 행렬 `VT`(`V`의 전치 행렬)가 생성됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b1ybdXZlbYpb"
   },
   "source": [
    "<br>\n",
    "\n",
    "**4) 수행 결과 확인**\n",
    "\n",
    "- `U` x `S` x `VT`를 하면 기존의 행렬 $A$가 나와야 한다.\n",
    "- Numpy의 `allclose()`는 2개의 행렬이 동일하면 `True`를 리턴한다.\n",
    "- 이를 사용하여 정말로 기존의 행렬 $A$와 동일한 지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4PGJCQaJb3ZC",
    "outputId": "d4406fa8-6ccb-4d28-d645-5602651201ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(A, np.dot(np.dot(U, S), VT).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FBrEPi4lb_ds"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.4 절단된 SVD(truncated SVD) 수행\n",
    "\n",
    "- `t=2`로 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6DFzIZqcT5K"
   },
   "source": [
    "<br>\n",
    "\n",
    "**1) 대각 행렬 `S` 절단**\n",
    "\n",
    "- 대각 행렬 `S` 내의 특이값 중에서 상위 2개만 남기고 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "WdmvJKD-f5rD",
    "outputId": "c8e6efbf-e75f-4e41-bf11-ed6229f7ac30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.69 0.  ]\n",
      " [0.   2.05]]\n"
     ]
    }
   ],
   "source": [
    "S = S[:2, :2]\n",
    "print(S.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NQhy4CiogAfg"
   },
   "source": [
    "<br>\n",
    "\n",
    "**2) 직교 행렬 `U` 절단**\n",
    "\n",
    "- 직교 행렬 `U`에 대해서도 2개의 **열**만 남기고 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "SIbDdDdtgJxe",
    "outputId": "f3a1408a-61ad-405a-9b23-abd865b8ef39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.24  0.75]\n",
      " [-0.51  0.44]\n",
      " [-0.83 -0.49]\n",
      " [-0.   -0.  ]]\n"
     ]
    }
   ],
   "source": [
    "U = U[:, :2]\n",
    "print(U.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wdSr8RQVgNp7"
   },
   "source": [
    "<br>\n",
    "\n",
    "**3) 직교 행렬 `VT` 절단**\n",
    "\n",
    "- 행렬 $V$의 전치 행렬인 `VT`에 대해서 2개의 **행**만 남기고 제거\n",
    "- 이는 $V$ 관점에서는 2개의 **열**만 남기고 제거한 것이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "-BrcbpfOgZvy",
    "outputId": "f81e5007-e6b7-4307-b080-fc1b33be0c86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.   -0.31 -0.31 -0.28 -0.8  -0.09 -0.28 -0.   -0.  ]\n",
      " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]]\n"
     ]
    }
   ],
   "source": [
    "VT = VT[:2, :]\n",
    "print(VT.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ntUxlPj8gfLz"
   },
   "source": [
    "<br>\n",
    "\n",
    "**4) 수행 결과 확인**\n",
    "\n",
    "- 축소된 행렬 `U`, `S`, `VT`에 대해서 다시 U x S x VT 연산을 하면 기존의 $A$와는 다른 결과가 나오게 된다.\n",
    "- 값이 손실되었기 때문에 이 세 개의 행렬로는 이제 기존의 $A$ 행렬을 복구할 수 없다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d_CSDqmDgxxl"
   },
   "source": [
    "- U x S x VT 연산을 해서 나오는 값은 `A_prime`이라고 하고 기존의 행렬 `A`와 값을 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "rmc3eytug-zx",
    "outputId": "aff4c775-e310-498c-dc04-d00d3ffa4eed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 1 1 0 0]\n",
      " [0 0 0 1 1 0 1 0 0]\n",
      " [0 1 1 0 2 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "2xt5YcYCg29-",
    "outputId": "30fe6b94-268d-4714-8f6e-f1d3d624dd9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   -0.17 -0.17  1.08  0.12  0.62  1.08 -0.   -0.  ]\n",
      " [ 0.    0.2   0.2   0.91  0.86  0.45  0.91  0.    0.  ]\n",
      " [ 0.    0.93  0.93  0.03  2.05 -0.17  0.03  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "A_prime = np.dot(np.dot(U, S), VT)\n",
    "print(A_prime.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9-TAyf4pg9DL"
   },
   "source": [
    "- 대체적으로 기존에 0인 값들은 0에 가까운 값이 나오고, 1인 값들은 1에 가까운 값이 나온다.\n",
    "- 또한 값이 제대로 복구되지 않은 구간도 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B7zh__aAhNfp"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.5 차원이 축소된 행렬들 크기의 의미\n",
    "\n",
    "- 이렇게 차원이 축소된 U, S, VT의 크기가 어떤 의미를 가지고 있는 지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HDCPLHl9haYF"
   },
   "source": [
    "<br>\n",
    "\n",
    "**1) 축소된 `U`**\n",
    "\n",
    "- 축소된 `U`는 4 x 2 크기를 가진다.\n",
    "- 이는 **문서의 개수 x 토픽의 수 $t$**의 크기이다.\n",
    "- 단어의 개수인 9는 유지되지 않는데 문서의 개수인 4의 크기가 유지된다  \n",
    "$\\rightarrow$ 4개의 문서 각각을 2개의 값으로 표현하고 있다.\n",
    "- 즉, `U`의 **각 행**은 **잠재 의미를 표현하기 위한 수치화된 각각의 <font color=\"red\">문서</font>의 벡터**라고 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uf-Bqtc6h45Q"
   },
   "source": [
    "<br>\n",
    "\n",
    "**2) 축소된 `VT`**\n",
    "\n",
    "- 축소된 `VT`는 2 x 9의 크기를 가진다.\n",
    "- 이는 **토픽의 수 $t$ x 단어의 개수**의 크기이다.\n",
    "- `VT`의 **각 열**은 **잠재 의미를 표현하기 위해 수치화된 각각의 <font color=\"red\">단어</font> 벡터**라고 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XtL7ZDmliQgQ"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.6 문서 벡터와 단어 벡터의 활용\n",
    "\n",
    "- 이 문서 벡터들과 단어 벡터들을 통해 다른 문서의 유사도, 다른 단어의 유사도, 단어(쿼리)로부터 문서의 유사도를 구하는 것이 가능해진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9v28uHJyio9u"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.4 실습을 통한 이해\n",
    "\n",
    "- 사이킷런에서는 Twenty Newsgroups이라고 불리는 20개의 다른 주제를 가진 뉴스 데이터를 제공한다.\n",
    "- LSA가 토픽 모델링에 최적화된 알고리즘은 아니지만, 토픽 모델링이라는 분야의 시초가 되는 알고리즘이다.\n",
    "- 여기서는 LSA를 사용하여 문서의 수를 원하는 토픽의 수로 압축한 뒤에 각 토픽당 가장 중요한 단어 5개를 출력하는 실습으로 토픽 모델링을 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zVpMUl29jB7d"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.4.1 뉴스 데이터에 대한 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "KNaKPzZJjEhR",
    "outputId": "aaece351-2f29-4886-aece-211d0a60815e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "dataset = fetch_20newsgroups(shuffle=True,\n",
    "                             random_state=1,\n",
    "                             remove=('headers', 'fotters', 'quotes'))\n",
    "\n",
    "documents = dataset.data\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RaKGgES5jTGO"
   },
   "source": [
    "- 훈련에 사용할 뉴스는 총 11,314개이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xsy5ZJyWjZn8"
   },
   "source": [
    "- 첫 번째 훈련용 뉴스 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "Lk_B9rrejch4",
    "outputId": "89b49540-f7e7-48fd-a678-2ec566a165cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\\nof steam!\\n\\n\\n\\n\\n\\n\\n\\nJim,\\n\\nSorry I can\\'t pity you, Jim.  And I\\'m sorry that you have these feelings of\\ndenial about the faith you need to get by.  Oh well, just pretend that it will\\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\\nalt.atheist.hard, you won\\'t be bummin\\' so much?\\n\\n\\n\\n\\n\\n\\nBye-Bye, Big Jim.  Don\\'t forget your Flintstone\\'s Chewables!  :) \\n--\\nBake Timmons, III\\n\\n-- \"...there\\'s nothing higher, stronger, more wholesome and more useful in life\\nthan some good memory...\" -- Alyosha in Brothers Karamazov (Dostoevsky)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dNwk11MEjd2-"
   },
   "source": [
    "- 뉴스 데이터에는 특수문자가 포함된 다수의 영어 문장으로 구성되어 있다.\n",
    "- 이런 형식의 뉴스가 11,314개 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AAh8Y3N-jzdT"
   },
   "source": [
    "- 사이킷런이 제공하는 뉴스 데이터에서 `target_name`에는 본래 이 뉴스 데이터가 어떤 20개의 카테고리를 갖고 있었는 지가 저장되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "RrhgRNOWj8G7",
    "outputId": "9992252c-1065-4ab6-9d0f-ee7230d93d2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rk4xccQJj-Gs"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.4.2 텍스트 전처리\n",
    "\n",
    "- 텍스트 데이터에 대해서 가능한한 정제 과정을 거쳐야만 한다.\n",
    "- 기본적인 아이디어 : 알파벳을 제외한 구두점, 숫자, 특수 문자를 제거하는 것\n",
    "- 이는 정규 표현식을 통해서 해결할 수 있다.\n",
    "- 또한 짧은 단어는 유용한 정보를 담고 있지 않다고 가정하고, 길이가 짧은 단어도 제거한다.\n",
    "- 마지막으로 모든 알파벳을 소문자로 바꿔서 단어의 개수를 줄이는 작업을 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "MeRLyTSTkYCy",
    "outputId": "94408815-5f3f-46c8-8174-9528640e9ad9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well i'm not sure about the story nad it did s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n   Although I realize that principle is not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n    Notwithstanding all the legitimate fuss ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, I will have to change the scoring on my ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document\n",
       "0  Well i'm not sure about the story nad it did s...\n",
       "1  \\n\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to ...\n",
       "2  \\n   Although I realize that principle is not ...\n",
       "3  \\n    Notwithstanding all the legitimate fuss ...\n",
       "4  Well, I will have to change the scoring on my ..."
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = pd.DataFrame({'document':documents})\n",
    "\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "Q1tFb1HYlTG2",
    "outputId": "0212cb17-d437-46bc-c97a-d5680a0b12b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\\nof steam!\\n\\n\\n\\n\\n\\n\\n\\nJim,\\n\\nSorry I can\\'t pity you, Jim.  And I\\'m sorry that you have these feelings of\\ndenial about the faith you need to get by.  Oh well, just pretend that it will\\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\\nalt.atheist.hard, you won\\'t be bummin\\' so much?\\n\\n\\n\\n\\n\\n\\nBye-Bye, Big Jim.  Don\\'t forget your Flintstone\\'s Chewables!  :) \\n--\\nBake Timmons, III\\n\\n-- \"...there\\'s nothing higher, stronger, more wholesome and more useful in life\\nthan some good memory...\" -- Alyosha in Brothers Karamazov (Dostoevsky)\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['document'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "urwOVhgilE61",
    "outputId": "9a1e81dd-c705-4507-aeec-eb0771adcb7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'        Yeah  do you expect people to read the FAQ  etc  and actually accept hard atheism   No  you need a little leap of faith  Jimmy   Your logic runs out of steam         Jim   Sorry I can t pity you  Jim   And I m sorry that you have these feelings of denial about the faith you need to get by   Oh well  just pretend that it will all end happily ever after anyway   Maybe if you start a new newsgroup  alt atheist hard  you won t be bummin  so much        Bye Bye  Big Jim   Don t forget your Flintstone s Chewables          Bake Timmons  III         there s nothing higher  stronger  more wholesome and more useful in life than some good memory        Alyosha in Brothers Karamazov  Dostoevsky  '"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특수문자 제거\n",
    "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")\n",
    "\n",
    "news_df['clean_doc'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "boUgT4M7ld5m",
    "outputId": "775a1ff4-d2c6-4384-f9ec-fcf01f560abc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yeah expect people read actually accept hard atheism need little leap faith Jimmy Your logic runs steam Sorry pity sorry that have these feelings denial about faith need well just pretend that will happily ever after anyway Maybe start newsgroup atheist hard bummin much forget your Flintstone Chewables Bake Timmons there nothing higher stronger more wholesome more useful life than some good memory Alyosha Brothers Karamazov Dostoevsky'"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 길이가 3이하인 단어 제거 (길이가 짧은 단어 제거)\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "\n",
    "news_df['clean_doc'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "oRYGoMYimArI",
    "outputId": "aed10717-7c7d-4cf7-b472-5565eeab5dc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yeah expect people read actually accept hard atheism need little leap faith jimmy your logic runs steam sorry pity sorry that have these feelings denial about faith need well just pretend that will happily ever after anyway maybe start newsgroup atheist hard bummin much forget your flintstone chewables bake timmons there nothing higher stronger more wholesome more useful life than some good memory alyosha brothers karamazov dostoevsky'"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 단어에 대한 소문자 변환\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())\n",
    "\n",
    "news_df['clean_doc'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VVMHRlG9mPX8"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 이제 뉴스 데이터에서 불용어를 제거한다.\n",
    "- 불용어를 제거하기 위해서 토큰화를 우선 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "nOtVrUKep6PP",
    "outputId": "b69db608-aef1-47ec-b355-cbd2f4d4ebb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "FEVVHYaqpygq",
    "outputId": "d37f0c11-fc83-40df-c93c-02e8c5933d59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [well, sure, about, story, seem, biased, what,...\n",
       "1        [yeah, expect, people, read, actually, accept,...\n",
       "2        [although, realize, that, principle, your, str...\n",
       "3        [notwithstanding, legitimate, fuss, about, thi...\n",
       "4        [well, will, have, change, scoring, playoff, p...\n",
       "                               ...                        \n",
       "11309    [danny, rubenstein, israeli, journalist, will,...\n",
       "11310    [description, content, just, about, ronroth, p...\n",
       "11311    [agree, home, runs, clemens, always, memorable...\n",
       "11312    [used, deskjet, with, orange, micros, grappler...\n",
       "11313    [argument, with, murphy, scared, hell, when, c...\n",
       "Name: clean_doc, Length: 11314, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# 토큰화\n",
    "tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split()) \n",
    "tokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "YmugFpdAqNEN",
    "outputId": "8f8d8b9d-26f6-48e5-bf0e-79e01e18428d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [well, sure, story, seem, biased, disagree, st...\n",
       "1        [yeah, expect, people, read, actually, accept,...\n",
       "2        [although, realize, principle, strongest, poin...\n",
       "3        [notwithstanding, legitimate, fuss, proposal, ...\n",
       "4        [well, change, scoring, playoff, pool, unfortu...\n",
       "                               ...                        \n",
       "11309    [danny, rubenstein, israeli, journalist, speak...\n",
       "11310    [description, content, ronroth, posts, date, l...\n",
       "11311    [agree, home, runs, clemens, always, memorable...\n",
       "11312    [used, deskjet, orange, micros, grappler, syst...\n",
       "11313    [argument, murphy, scared, hell, came, last, y...\n",
       "Name: clean_doc, Length: 11314, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불용어 제거\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "tokenized_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aIDcper6p0c5"
   },
   "source": [
    "- 불용어에 속하는 your, about, just, that, will, after 단어들이 사라졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IFiz_UzVqeV5"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.4.3 TF-IDF 행렬 만들기\n",
    "\n",
    "- 불용어 제거를 위해 토큰화 작업을 수행하였지만, `TfidfVectorizer`는 기본적으로 토큰화가 되어 있지 않은 텍스트 데이터를 입력으로 사용한다.\n",
    "- 그렇기 때문에 `TfidfVectorizer`를 사용해 TF-IDF 행렬을 만들기 위해서 다시 토큰화 작업을 역으로 취소하는 작업을 수행한다.\n",
    "- 이를 **역토큰화(Detokenization)**라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8OjZkFYzq2Q-"
   },
   "outputs": [],
   "source": [
    "# 역토큰화\n",
    "detokneized_doc = []\n",
    "\n",
    "for i in range(len(news_df)):\n",
    "    t = ' '.join(tokenized_doc[i])\n",
    "    detokneized_doc.append(t)\n",
    "\n",
    "news_df['clean_doc'] = detokneized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "AVFtpjGTrG3B",
    "outputId": "80737256-6087-48bb-a249-e6e5a413fa5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yeah expect people read actually accept hard atheism need little leap faith jimmy logic runs steam sorry pity sorry feelings denial faith need well pretend happily ever anyway maybe start newsgroup atheist hard bummin much forget flintstone chewables bake timmons nothing higher stronger wholesome useful life good memory alyosha brothers karamazov dostoevsky'"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['clean_doc'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iF_zKLzdrJOm"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 사이킷런의 `TfidfVectorizer`를 통해 단어 1,000개에 대한 TF-IDF 행렬을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "pSU5idQarQ1l",
    "outputId": "48861bf3-be49-47c4-f2ab-d7bd9a2ec783"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 1000)"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english',\n",
    "                             max_features=1000,\n",
    "                             max_df=0.5,\n",
    "                             smooth_idf=True)\n",
    "\n",
    "X = vectorizer.fit_transform(news_df['clean_doc'])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QU1N2nqrjkt"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.4.4 토픽 모델링 (Topic Modeling)\n",
    "\n",
    "- TF-IDF 행렬을 다수의 행렬로 분해\n",
    "- 여기서는 사이킷런의 절단된 SVD(truncated SVD)를 사용한다.\n",
    "- 절단된 SVD를 사용하면 차원을 축소할 수 있다.\n",
    "- 원래 기존 뉴스 데이터가 20개의 뉴스 카테고리를 갖고 있었기 때문에 20개의 토픽을 가졌다고 가정하고 토픽 모델링을 시도한다.\n",
    "- 토픽의 숫자는 `n_components`의 파라미터로 지정이 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "w9eaDfQCr5LM",
    "outputId": "4251f56e-c774-4287-db7b-91b00676e26e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd_model = TruncatedSVD(n_components=20,\n",
    "                         algorithm='randomized',\n",
    "                         n_iter=100,\n",
    "                         random_state=122)\n",
    "\n",
    "svd_model.fit(X)\n",
    "len(svd_model.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qnEvEcAvsIuV"
   },
   "source": [
    "- `svd_model.components_` : LSA에서 `VT`에 해당된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "M1pXDSyUsPJk",
    "outputId": "98a4f252-0ab4-43a0-c666-bd5107113942"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1000)"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(svd_model.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HpAFmJt8sRy8"
   },
   "source": [
    "- 정확하게 \"토픽의 수 t x 단어의 수\"의 크기를 가지는 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xh5wWvqOsXq7"
   },
   "outputs": [],
   "source": [
    "terms = vectorizer.get_feature_names() # 단어 집합. 1,000개의 단어가 저장됨\n",
    "\n",
    "def get_topics(components, feature_names, n=5):\n",
    "    for idx, topic in enumerate(components):\n",
    "        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(5)) for i in topic.argsort()[:-n - 1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "6y9vp4uqsyIr",
    "outputId": "dd1ea4e5-6e44-4846-bd45-7771f3443a45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: [('like', 0.20505), ('know', 0.18838), ('people', 0.18376), ('think', 0.16767), ('good', 0.14274)]\n",
      "Topic 2: [('thanks', 0.3379), ('windows', 0.27465), ('mail', 0.17725), ('card', 0.17113), ('drive', 0.15578)]\n",
      "Topic 3: [('game', 0.38223), ('team', 0.32242), ('year', 0.27387), ('games', 0.24544), ('season', 0.18665)]\n",
      "Topic 4: [('drive', 0.51326), ('scsi', 0.20344), ('disk', 0.15638), ('hard', 0.15618), ('card', 0.15153)]\n",
      "Topic 5: [('thanks', 0.37204), ('drive', 0.3638), ('know', 0.25132), ('scsi', 0.13857), ('advance', 0.12312)]\n",
      "Topic 6: [('windows', 0.34853), ('know', 0.23487), ('like', 0.1898), ('think', 0.17901), ('file', 0.12958)]\n",
      "Topic 7: [('like', 0.55178), ('bike', 0.1782), ('know', 0.17522), ('chip', 0.11768), ('sounds', 0.079)]\n",
      "Topic 8: [('know', 0.24374), ('thanks', 0.22401), ('government', 0.21558), ('people', 0.18357), ('israel', 0.12575)]\n",
      "Topic 9: [('card', 0.51616), ('video', 0.2482), ('monitor', 0.15725), ('sale', 0.15), ('drivers', 0.13072)]\n",
      "Topic 10: [('like', 0.47037), ('armenian', 0.1927), ('people', 0.18913), ('windows', 0.17753), ('turkish', 0.17508)]\n",
      "Topic 11: [('think', 0.46471), ('like', 0.22862), ('internet', 0.18748), ('university', 0.1842), ('people', 0.18006)]\n",
      "Topic 12: [('know', 0.33508), ('space', 0.28752), ('card', 0.2564), ('university', 0.23586), ('nasa', 0.1955)]\n",
      "Topic 13: [('think', 0.47083), ('space', 0.18333), ('bike', 0.15004), ('good', 0.13955), ('year', 0.13732)]\n",
      "Topic 14: [('think', 0.35417), ('space', 0.32648), ('thanks', 0.20217), ('nasa', 0.19711), ('card', 0.11665)]\n",
      "Topic 15: [('know', 0.43391), ('people', 0.2722), ('space', 0.22016), ('file', 0.15128), ('windows', 0.13644)]\n",
      "Topic 16: [('israel', 0.50303), ('israeli', 0.24153), ('know', 0.23028), ('think', 0.18061), ('jews', 0.16094)]\n",
      "Topic 17: [('mail', 0.4988), ('time', 0.41576), ('know', 0.14842), ('think', 0.11952), ('address', 0.11369)]\n",
      "Topic 18: [('good', 0.39667), ('armenian', 0.17696), ('turkish', 0.16658), ('time', 0.16644), ('armenians', 0.14796)]\n",
      "Topic 19: [('think', 0.26404), ('know', 0.24732), ('work', 0.22683), ('email', 0.19504), ('armenian', 0.17921)]\n",
      "Topic 20: [('bike', 0.32458), ('windows', 0.23663), ('right', 0.21794), ('jesus', 0.1686), ('file', 0.15969)]\n"
     ]
    }
   ],
   "source": [
    "get_topics(svd_model.components_, terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zGpw_z78tzvx"
   },
   "source": [
    "- 각 20개의 행의 각 1,000개의 열 중 가장 값이 큰 5개의 값을 찾아서 단어로 출력한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0AsGJtNUv5Ex"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.5 LSA의 장단점 (Pros and Cons of LSA)\n",
    "\n",
    "### 1.5.1 장점\n",
    "\n",
    "- LSA는 쉽고 빠르게 구현이 가능하다.\n",
    "- 단어의 잠재적인 의미를 이끌어낼 수 있어 문서의 유사도 계산 등에서 좋은 성능을 보여준다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xEAfzGAhwXaE"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.5.2 단점\n",
    "\n",
    "- SVD의 특성상 이미 계산된 LSA에 새로운 데이터를 추가하여 계산하려고하면 보통 처음부터 다시 계산해야 한다.\n",
    "- 즉, 새로운 정보에 대해 업데이트가 어렵다.\n",
    "- 이는 최근 LSA 대신 Word2Vec 등 단어의 의미를 벡터화할 수 있는 또 다른 방법론인 인공 신경망 기반의 방법론이 각광받는 이유이기도 하다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ch06_v01_Latent-Semantic-Analysis-LSA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
