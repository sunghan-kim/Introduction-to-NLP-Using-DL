{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rSiJ9YvwlGC9"
   },
   "source": [
    "# Ch08. 딥 러닝(Deep Learning) 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCbeTAS_lG9-"
   },
   "source": [
    "# v03. 딥 러닝의 학습 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FIpHLhQllOWK"
   },
   "source": [
    "- 손실 함수와 옵티마이저의 개념을 이해\n",
    "- 딥 러닝에서 어떻게 학습을 하는 지 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oQ8ckVy6lVfC"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 3.1 순전파 (Forward Propagation)\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/36033/%EC%88%9C%EC%A0%84%ED%8C%8C.PNG)\n",
    "\n",
    "- 활성화 함수, 은닉층의 수, 각 은닉층의 뉴런 수 등 딥 러닝 모델을 설계\n",
    "- 그런 다음 입력값은 입력층, 은닉층을 지나면서 각 층에서의 가중치와 함께 연산되며 출력층으로 향함\n",
    "- 그리고 출력층에서 모든 연산을 마친 예측값이 나오게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tRHcIhYNmVYE"
   },
   "source": [
    "- 이와 같이 입력층에서 출력층 방향으로 예측값의 연산이 진행되는 과정을 **순전파**라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UbWhHA8OmaW0"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 3.2 손실 함수 (Loss function)\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/36033/%EC%86%90%EC%8B%A4%ED%95%A8%EC%88%98.PNG)\n",
    "\n",
    "- 손실 함수는 실제값과 예측값의 차이를 수치화해주는 함수이다.\n",
    "- 이 두 값의 차이, 즉 **오차**가 클수록 손실 함수의 값은 크고 오차가 작을 수록 손실 함수의 값은 작아진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5sO-SRenm3v7"
   },
   "source": [
    "- 회귀 문제에서의 손실 함수 $\\rightarrow$ 평균 제곱 오차(MSE)\n",
    "- 분류 문제에서의 손실 함수 $\\rightarrow$ 크로스 엔트로피(Cross-Entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UH3HMniBm4mb"
   },
   "source": [
    "- 손실 함수의 값을 최소화하는 두 개의 매개변수인 가중치 W와 편향 b를 찾아가는 것이 딥 러닝의 학습 과정이므로 손실 함수의 선정은 매우 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oLgMhlVinA_z"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.2.1 평균 제곱 오차 (Mean Squared Error, MSE)\n",
    "\n",
    "- 오차 제곱 평균을 의미한다.\n",
    "- **연속형 변수**를 예측할 때 사용된다.\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "{- \\frac{1}{N} \\sum \\left( y - \\hat{y} \\right)^2 }\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ts_l7QeynYE9"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.2.2 크로스 엔트로피(Cross-Entropy)\n",
    "\n",
    "- $y$ : 실제값 (0 or 1)\n",
    "- $\\hat{y}$ : 예측값 (확률)\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "{ - \\sum y \\; log \\; \\hat{y} }\n",
    "$\n",
    "\n",
    "- 낮은 확률로 예측해서 맞추거나, 높은 확률로 예측해서 틀리는 경우 loss가 더 크다.\n",
    "- 이진 분류(Binary Classification)의 경우 $\\rightarrow$ `binary_crossentropy` 사용\n",
    "- 다중 클래스 분류(Multi-Class Classification)의 경우 $\\rightarrow$ `categorical_crossentropy` 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e7QBQXYZn4-f"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 3.3 옵티마이저(Optimizer)\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/36033/%EC%97%AD%EC%A0%84%ED%8C%8C_%EA%B3%BC%EC%A0%95.PNG)\n",
    "\n",
    "- 손실 함수의 값을 줄여나가면서 학습하는 방법은 어떤 옵티마이저를 사용하느냐에 따라 달라진다.\n",
    "- 여기서 **배치(Batch)**라는 개념에 대한 이해가 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k6bjyDozoLIB"
   },
   "source": [
    "**참고) 배치(Batch)**\n",
    "\n",
    "- 가중치 등의 매개 변수의 값을 조정하기 위해 사용하는 데이터의 양\n",
    "- 전체 데이터를 가지고 매개 변수의 값을 조정할 수도 있고, 정해준 양(배치의 크기)의 데이터만 가지고도 매개 변수의 값을 조정할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K-zaQE6moZMg"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.3.1 배치 경사 하강법 (Batch Gradient Descent)\n",
    "\n",
    "- 가장 기본적인 경사 하강법\n",
    "- 옵티마이저 중 하나로서 오차(loss)를 구할 때 **전체 데이터**를 고려한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E4G-0YLHoreA"
   },
   "source": [
    "- 배치 경사 하강법은 한 번의 에포크에 모든 매개 변수 업데이트를 단 한 번 수행한다.  \n",
    "(1 에포크 : 머신 러닝에서 1번의 훈련 횟수를 지칭하는 말)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KttYuDIYppd3"
   },
   "source": [
    "**배치 경사 하강법의 장점**\n",
    "\n",
    "- 글로벌 미니멈을 찾을 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cd--LBLtpovh"
   },
   "source": [
    "**배치 경사 하강법의 단점**\n",
    "\n",
    "- 전체 데이터를 고려해서 학습 $\\rightarrow$ 에포크당 시간이 오래걸림, 메모리를 크게 요구함\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vj01vKjrpF3d"
   },
   "source": [
    "**케라스에서의 배치 경사 하강법 사용**\n",
    "\n",
    "```python\n",
    "model.fit(X_train, y_train, batch_size=len(trainX))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zer6HAhVpNvY"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.3.2 확률적 경사 하강법 (Stochastic Gradient Descent, SGD)\n",
    "\n",
    "- 매개 변수 값을 조정 시 전체 데이터가 아니라 **랜덤으로 선택한 하나의 데이터에 대해서만 계산**하는 방법\n",
    "- 더 적은 데이터를 사용하므로 더 빠르게 계산할 수 있다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/24987/%EA%B2%BD%EC%82%AC%ED%95%98%EA%B0%95%EB%B2%95SGD.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mtjuw_vPpyom"
   },
   "source": [
    "**SGD의 장점**\n",
    "\n",
    "- 속도 만큼은 배치 경사 하강법보다 빠르다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B1My3DLEp1-u"
   },
   "source": [
    "**SGD의 단점**\n",
    "\n",
    "- 매개 변수의 변경폭이 불안정하다.\n",
    "- 떄로는 배치 경사 하강법보다 정확도가 낮을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s2Ugqqavp7km"
   },
   "source": [
    "**케라스에서의 SGD 사용**\n",
    "\n",
    "```python\n",
    "model.fit(X_train, y_train, batch_size=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TD_w-WnPqGOx"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.3.3 미니 배치 경사 하강법 (Mini-Batch Gradient Descent)\n",
    "\n",
    "- 전체 데이터도 아니고, 1개의 데이터도 아닌 **정해진 양에 대해서만 계산**하여 매개 변수의 값을 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGUPRwGRqjxs"
   },
   "source": [
    "**미니 배치 경사 하강법의 장점**\n",
    "\n",
    "- 전체 데이터를 계산하는 것 보다 빠르다.\n",
    "- SGD보다 안정적이다.\n",
    "- 이러한 장점들을 바탕으로 실제로 가장 많이 사용되는 경사 하강법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mZlr8gbOqpjE"
   },
   "source": [
    "**케라스에서의 미니 배치 경사 하강법의 사용**\n",
    "\n",
    "```python\n",
    "model.fit(X_train, y_train, batch_size=32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_FXN7ZTzqvW7"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.3.4 모멘텀 (Momentum)\n",
    "\n",
    "- **관성**이라는 물리학의 법칙을 응용한 방법\n",
    "- 모멘텀 SGD는 경사 하강법에 관성을 더해 준다.\n",
    "- 모멘텀은 SGD에서 계산된 접선의 기울기에 한 시점(step) 전의 접선의 기울기값을 일정한 비율만큼 반영한다.\n",
    "- 이렇게 하면 마치 언덕에서 공이 내려올 때, 중간에 작은 웅덩이에 빠지더라도 관성의 힘으로 넘어서는 효과를 줄 수 있다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/24987/%EB%A1%9C%EC%BB%AC%EB%AF%B8%EB%8B%88%EB%A9%88.PNG)\n",
    "\n",
    "- 로컬 미니멈에 도달했을 경우\n",
    "  - 기존의 경사 하강법 : 기울기가 0이라서 이를 글로벌 미니멈으로 잘못 인식하여 계산이 끝남\n",
    "  - 모멘텀 SGD : 모멘텀, 즉 관성의 힘들 빌려 값이 조절되면서 로컬 미니멈을 탈출하는 효과를 얻을 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pu1ME4F1rq8K"
   },
   "source": [
    "**케라스에서의 모멘텀 SGD 사용**\n",
    "\n",
    "```python\n",
    "kreas.optimizers.SGD(lr = 0.01, momentum=0.9)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tjikO74WrxkF"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.3.5 아다그라드(Adagrad)\n",
    "\n",
    "- 매개 변수들은 각자 의미하는 바가 다르다.\n",
    "- 그러므로 모든 매개 변수에 동일한 학습률(learning rate)을 적용하는 것은 비효율적이다.\n",
    "- 아다그라드는 **각 매개 변수에 서로 다른 학습률을 적용**시킨다.\n",
    "- 변화가 많은 매개 변수 $\\rightarrow$ 학습률이 작게 설정됨\n",
    "- 변화가 적은 매개 변수 $\\rightarrow$ 학습률이 높게 설정됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zxCIJnbvsLzB"
   },
   "source": [
    "**케라스에서의 아다그라드 사용**\n",
    "\n",
    "```python\n",
    "keras.optimizers.Adagrad(lr=0.01, epsilon=1e-6)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eH6jtzgrsTIm"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.3.6 알엠에스프롭 (RMSprop)\n",
    "\n",
    "- 아다그라드는 학습을 계속 진행한 경우에는, 나중에 가서는 학습률이 지나치게 떨어진다는 단점이 있다.\n",
    "- 이를 다른 수식인 RMSprop로 대체하여 이러한 단점을 개선했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s-ISULHgsgYb"
   },
   "source": [
    "**케라스에서의 RMSprop의 사용**\n",
    "\n",
    "```python\n",
    "kreas.optimizer.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-C6fYiwsn3R"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.3.7 아담 (Adam)\n",
    "\n",
    "- RMSprop와 모멘텀 두 가지를 합친 듯한 방법\n",
    "- 방향과 학습률 두 가지를 모두 잡기 위한 방법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qngxncI5swOw"
   },
   "source": [
    "**케라스에서의 Adam 사용**\n",
    "\n",
    "```python\n",
    "keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VXNK-w2as8VT"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.3.8 케라스의 옵티마이저 사용법\n",
    "\n",
    "- [링크](https://keras.io/optimizers/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J3vNDc3wtCoo"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 3.4 역전파(BackPropagation)\n",
    "\n",
    "- [역전파](https://github.com/sunghan-kim/Introduction-to-NLP-Using-DL/blob/master/Ch08_Deep-Learning/Ch08_v03_04_BackPropagation.ipynb) 페이지 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kxjlfb0ptRbR"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 3.5 에포크, 배치 크기, 이터레이션 (Epochs and Batch size and Iteration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MuZDsUuNt4XQ"
   },
   "source": [
    "- 기계는 실제값과 예측값의 오차로부터 옵티마이저를 통해서 가중치를 업데이트한다.\n",
    "- 머신 러닝에서는 이 과정을 **학습**이라고 한다.\n",
    "- 이를 현실의 학습에 비유\n",
    "  - 사람은 문제지의 문제를 풀고, 정답지의 정답을 보면서 채점을 하면서 부족했던 점을 깨달으며 머릿속의 지식이 업데이트되는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LYSw7OYwMJ6a"
   },
   "source": [
    "- 그런데 사람마다 동일한 문제지와 정답지를 주더라도 공부 방법은 사실 천차만별이다.\n",
    "  - 어떤 사람은 문제지 하나를 다 풀고 나서 정답을 채점\n",
    "  - 어떤 사람은 문제지의 문제를 10개 단위로 끊어서 공부  \n",
    "  (문제 10개를 풀고 채점하고 다시 다음 문제 10개를 풀고 채점하고 반복하는 방식으로 학습)\n",
    "  - 게으른 사람은 문제지를 3번 공부\n",
    "  - 성실한 사람은 문제지의 문제를 달달 외울만큼 문제지를 100번 공부"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MTcJDxmjMbR6"
   },
   "source": [
    "- 기계도 같은 문제지와 정답지를 주더라도 공부 방법을 다르게 설정할 수 있다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/36033/batchandepochiteration.PNG)\n",
    "\n",
    "- 위의 그림은 에포크와 배치 크기와 이터레이션의 차이를 보여준다.\n",
    "- 위의 그림의 예제를 통해 설명한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fwyRAzT_MnbC"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.5.1 에포크(Epoch)\n",
    "\n",
    "- 인공 신경망에서 전체 데이터에 대해서 순전파와 역전파가 끝난 상태  \n",
    "- 전체 데이터를 하나의 문제지에 비유  \n",
    ": 문제지의 모든 문제를 끝까지 다 풀고, 정답지로 채점을 하여 문제지에 대한 공부를 한 번 끝낸 상태\n",
    "- ex) 에포크 = 50 $\\rightarrow$ 전체 데이터 단위로는 총 50번 학습한다.\n",
    "- 문제지에 비유 : 문제지를 50번 푼 셈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RiSd2OnFM5IV"
   },
   "source": [
    "- 이 에포크 횟수가 지나치거나 너무 적으면 앞서 배운 과적합과 과소적합이 발생할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1CTSb32sN9w8"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.5.2 배치 크기(Batch size)\n",
    "\n",
    "- 몇 개의 데이터 단위로 매개 변수를 업데이트 하는 지를 말함\n",
    "- 현실에 비유 : 문제지에서 몇 개씩 문제를 풀고나서 정답지를 확인하느냐의 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3bwjjG2NPxOx"
   },
   "source": [
    "**업데이트 시점**\n",
    "\n",
    "- 사람은 문제를 풀고 정답을 보는 순간 부족했던 점을 깨달으며 지식이 업데이트 된다.\n",
    "- 기계 입장에서는 실제값과 예측값으로부터 오차를 계산하고 옵티마이저가 매개 변수를 업데이트 한다.  \n",
    "(업데이트가 시작되는 시점이 정답지/실제값을 확인하는 시점이다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8YSyOK_jQsqM"
   },
   "source": [
    "- 사람이 2,000 문제가 수록되어 있는 문제지의 문제를 200개 단위로 풀고 채점한다고 하면 이 때 배치 크기는 200이다.\n",
    "- 기계는 배치 크기가 200이면 200개의 샘플 단위로 가중치를 업데이트 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Is442DZJQ32i"
   },
   "source": [
    "**배치 크기 vs 배치의 수**\n",
    "\n",
    "- 전체 데이터가 2,000일 때 배치 크기를 200으로 준다면 **배치의 수**는 10이다.\n",
    "- 이는 에포크에서 배치 크기를 나눠준 값(2,000/200 = 10)이기도 한다.\n",
    "- 이 때 배치의 수를 **이터레이션**이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W-ls72cjREva"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.5.3 이터레이션(Iteration)\n",
    "\n",
    "- 한 번의 에포크를 끝내기 위해서 필요한 배치의 수\n",
    "- 한 번의 에포크 내에서 이루어지는 매개 변수의 업데이트 횟수\n",
    "- 전체 데이터가 2,000일 때 배치 크기를 200으로 한다면 이터레이션의 수는 총 10개이다.\n",
    "- 이는 한 번의 에포크 당 매개 변수 업데이트가 10번 이루어진다는 것을 의미한다.\n",
    "- SGD를 이 개념을 가지고 다시 설명\n",
    "  - SGD는 배치 크기가 1이므로 모든 이터레이션마다 하나의 데이터를 선택하여 경사 하강법을 수행"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ch08_v03_Deep-Learnings-Learning-Method.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
