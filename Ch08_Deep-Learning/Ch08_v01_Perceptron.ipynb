{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZBrieuRcPzts"
   },
   "source": [
    "# Ch08. 딥 러닝(Deep Learning) 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2X25vL9jQDqO"
   },
   "source": [
    "# v01. 퍼셉트론 (Perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MO7qP27YQGGC"
   },
   "source": [
    "- 딥러닝을 이해하기 위해서는 우선 인공 신경망에 대한 이해가 필요하다.\n",
    "- 이번 챕터에서는 초기의 인공 신경망인 **퍼셉트론(Perceptron)**에 대해서 이해한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6yrNUEKPRTVQ"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.1 퍼셉트론 (Perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EHzqj68pRWx3"
   },
   "source": [
    "- 프랑크 로젠블라트(Frank Rosenblatt)가 1957년에 제안한 초기 형태의 인공 신경망\n",
    "- 다수의 입력으로부터 하나의 결과를 내보내는 알고리즘\n",
    "- 실제 뇌를 구성하는 신경 세포 뉴런의 동작과 유사"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P4Rv2wb4RfX_"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.1 신경 세포 뉴런의 그림\n",
    "\n",
    "- 뉴런은 가지돌기에서 신호를 받아들이고, 이 신호가 일정치 이상의 크기를 가지면 축삭돌기를 통해서 신호를 전달한다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/24958/%EB%89%B4%EB%9F%B0.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RkOuxKZ7RoIG"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.2 다수의 입력을 받는 퍼셉트론 그림\n",
    "\n",
    "- 신경 세포 뉴런의 입력 신호와 출력 신호가 퍼셉트론에서 각각 입력값과 출력값에 해당된다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/24958/perceptrin1_final.PNG)\n",
    "\n",
    "- $x$ : 입력값\n",
    "- $W$ : 가중치(Weight)\n",
    "- $y$ : 출력값\n",
    "- 그림 안의 원 : 인공 뉴런"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vvfAzWzHR3Sw"
   },
   "source": [
    "- 실제 신경 세포 뉴런에서의 신호를 전달하는 축삭돌기의 역할을 퍼셉트론에서는 가중치가 대신한다.\n",
    "- 각각의 인공 뉴런에서 보내진 입력값 $x$는 각각의 가중치 $W$와 함께 종착지인 인공 뉴런에 전달되고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TL64uAIkhhnS"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.3 가중치의 의미\n",
    "\n",
    "- 각각의 입력값에는 각각의 가중치가 존재\n",
    "- 이때 가중치의 값이 크면 클수록 해당 입력 값이 중요하다는 것을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3X73-UNGhrMa"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.4 계단 함수 (Step function)\n",
    "\n",
    "- 각 입력값이 가중치와 곱해져서 인공 뉴런에 보내진다.\n",
    "- 각 입력값과 그에 해당되는 가중치의 곱의 전체 합이 \n",
    "  - 임계치(threshold)를 넘으면 종착지에 있는 인공 뉴런은 출력 신호로서 1을 출력\n",
    "  - 그렇지 않을 경우에는 0을 출력\n",
    "- 이러한 함수를 **계단 함수(Step function)**라고 하며, 아래는 그래프는 계단 함수의 하나의 예를 보여준다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/24987/step_function.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iICw0I9JiKkL"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.5 임계치값\n",
    "\n",
    "- 이떄 계단 함수에 사용된 이 임계치값을 수식으로 표현할 때는 보통 세타($\\Theta$)로 표현한다.\n",
    "- 이를 식으로 표현하면 다음과 같다.\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "if \\quad \\sum_i^n w_i x_i \\; \\geq \\; \\theta \\quad \\rightarrow \\quad y = 1\n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "if \\quad \\sum_i^n w_i x_i \\; < \\; \\theta \\quad \\rightarrow \\quad y = 0\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Du116-giikYa"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.6 편향\n",
    "\n",
    "- 단, 위의 식에서 임계치를 좌변으로 넘기고 편향 $b$(bias)로 표현할 수도 있다.\n",
    "- 편향 $b$ 또한 퍼셉트론의 입력으로 사용된다.\n",
    "- 보통 그림으로 표현할 때는 입력값이 1로 고정되고 편향 $b$가 곱해지는 변수로 표현된다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/24958/perceptron2_final.PNG)\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "if \\quad \\sum_i^n w_i x_i + b \\; \\geq \\; 0 \\quad \\rightarrow \\quad y = 1\n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "if \\quad \\sum_i^n w_i x_i + b \\; < \\; 0 \\quad \\rightarrow \\quad y = 0\n",
    "$\n",
    "\n",
    "<br>\n",
    "\n",
    "- 이 책을 포함한 많은 인공 신경망 자료에서 편의상 편향 b가 그림이나 수식에서 생략되서 표현되기도 한다.\n",
    "- 하지만 실제로는 편향 b 또한 딥 러닝이 최적의 값을 찾아야 할 변수 중 하나이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDHdK2Pci-b4"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.7 활성화 함수 (Activation Function)\n",
    "\n",
    "- 이렇게 뉴런에서 출력값을 변경시키는 함수를 활성화 함수(Activation Function)라고 한다.\n",
    "- 초기 인공 신경망 모델인 퍼셉트론은 활성화 함수로 계단 함수를 사용한다.\n",
    "- 그 뒤에 등장한 여러가지 발전된 신경망들은 계단 함수 외에도 여러 다양한 활성화 함수를 사용하기 시작했다.\n",
    "- 앞서 배운 시그모이드 함수나 소프트맥스 함수 또한 활성화 함수 중 하나이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dpr-tNV7jbkG"
   },
   "source": [
    "- 퍼셉트론의 활성화 함수는 계단 함수이지만 여기서 활성화 함수를 시그모이드 함수로 변경하면 방금 배운 퍼셉트론은 곧 이진 분류를 수행하는 로지스틱 회귀와 동일함을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3H1XW8sSjd8O"
   },
   "source": [
    "- 다시 말하면 로지스틱 회귀 모델이 인공 신경망에서는 하나의 인공 뉴런으로 볼 수 있다.\n",
    "- 로지스틱 회귀를 수행하는 인공 뉴런과 위에서 배운 퍼셉트론의 차이는 오직 활성화 함수의 차이이다.\n",
    "  - 인공 뉴런 : 활성화 함수 $f \\left( \\sum_i^n W_i x_i + b \\right)$\n",
    "  - 위의 퍼셉트론(인공 뉴런 중 하나) : 계단 함수 $f \\left( \\sum_i^n W_i x_i + b \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P0o7dYBBjzTN"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.2 단층 퍼셉트론 (Single-Layer Perceptron)\n",
    "\n",
    "- 위에서 배운 퍼셉트론을 단층 퍼셉트론이라고 한다.\n",
    "- 퍼셉트론은 단층 퍼셉트론과 다층 퍼셉트론으로 나누어 진다.\n",
    "- 단층 퍼셉트론은 값을 보내는 단계과 값을 받아서 출력하는 두 단계로만 이루어진다.\n",
    "- 이때 이 각 단계를 보통 층(layer)라고 부른다.\n",
    "- 이 두 개의 층을 입력층(input layer)과 출력층(output layer)이라고 한다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/24958/perceptron3_final.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cy7MlnAAkPs9"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.2.1 단층 퍼셉트론을 이용하여 할 수 있는 일\n",
    "\n",
    "- 단층 퍼셉트론을 이용하면 AND, NAND, OR 게이트를 쉽게 구현할 수 있다.\n",
    "- 게이트 연산에 쓰이는 것은 두 개의 입력값과 하나의 출력값이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFMrP0a6katX"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.2.1.1 AND 게이트\n",
    "\n",
    "- AND 게이트의 경우에는 두 개의 입력 값이 모두 1인 경우에만 출력값이 1이 나오는 구조를 갖고 있다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/24958/andgate.PNG)\n",
    "\n",
    "- 단층 퍼셉트론의 식을 통해 AND 게이트를 만족하는 두 개의 가중치와 편향 값에는 뭐가 있을까?\n",
    "- 각각 $w_1$, $w_2$, $b$라고 한다면 아래와 같은 조합 이외에도 다양한 가중치와 편향의 조합이 나올 수 있다.\n",
    "  - `[0.5, 0.5, -0.7]`\n",
    "  - `[0.5, 0.5, -0.8]`\n",
    "  - `[1.0, 1.0, -1.0]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8yshWznQk1q_"
   },
   "source": [
    "- 이해를 돕기 위해서 AND 게이트를 위한 매개변수 값을 가진 단층 퍼셉트론의 식을 파이썬 코드로 간단하게 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "78gVOl13k7jk"
   },
   "outputs": [],
   "source": [
    "def AND_gate(x1, x2):\n",
    "    w1 = 0.5\n",
    "    w2 = 0.5\n",
    "    b = -0.7\n",
    "\n",
    "    result = x1*w1 + x2*w2 + b\n",
    "\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "99dquSOelDxz"
   },
   "source": [
    "- 위의 함수에 AND 게이트의 입력값을 모두 넣어보면 오직 두 개의 입력값이 1인 경우에만 1을 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "XUwt5fbPlG-j",
    "outputId": "ae5a0aff-92df-4559-cc4a-6c433e220b68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AND_gate(0, 0), AND_gate(0, 1), AND_gate(1, 0), AND_gate(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oUx92cr6lMYL"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.2.1.2 NAND 게이트\n",
    "\n",
    "- NAND 게이트는 두 개의 입력값이 1인 경우에만 출력값이 0이고, 나머지 입력값의 쌍(pair)에 대해서는 모두 출력값이 1이다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/24958/nandgate.PNG)\n",
    "\n",
    "- 앞서 언급했던 AND 게이트를 충족하는 가중치와 편향값인 `[0.5, 0.5, -0.7]`에 -를 붙여서 `[-0.5, -0.5, +0.7]`을 단층 퍼셉트론의 식에 넣어보면 NAND 게이트를 충족한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7_Zp8pY_lqzC"
   },
   "outputs": [],
   "source": [
    "def NAND_gate(x1, x2):\n",
    "    w1 = -0.5\n",
    "    w2 = -0.5\n",
    "    b = 0.7\n",
    "\n",
    "    result = x1*w1 + x2*w2 + b\n",
    "\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vsreK026lvIi",
    "outputId": "556fc482-078d-4afa-bb30-06cf2ea12cbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1, 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAND_gate(0, 0), NAND_gate(0, 1), NAND_gate(1, 0), NAND_gate(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S-ffvF5Glx9T"
   },
   "source": [
    "- `[-0.5, -0.5, -0.7]` 외에도 퍼셉트론이 NAND 게이트의 동작을 하도록 하는 다양한 가중치와 편향의 값들이 있을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L4k__6kxl3nq"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.2.1.3 OR 게이트\n",
    "\n",
    "- 두 개의 입력이 모두 0인 경우에 출력값이 0이고 나머지 경우에는 모두 출력값이 1인 OR 게이트 또한 적절한 가중치 값과 편향 값만 찾으면 단층 퍼셉트론의 식으로 구현할 수 있다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/24958/orgate.PNG)\n",
    "\n",
    "- 예를 들어 각각 가중치와 편향에 대해서 `[0.6, 0.6, -0.5]`를 선택하면 OR 게이트를 충족한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QpkwAEe5l_wK"
   },
   "outputs": [],
   "source": [
    "def OR_gate(x1, x2):\n",
    "    w1=0.6\n",
    "    w2=0.6\n",
    "    b=-0.5\n",
    "    result = x1*w1 + x2*w2 + b\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5kmZyaivmHwq",
    "outputId": "4834e326-4db5-4a86-8f55-b1b31729fe0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 1, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OR_gate(0, 0), OR_gate(0, 1), OR_gate(1, 0), OR_gate(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "18FhOxAYmIzy"
   },
   "source": [
    "- 물론, 이 외에도 이를 충족하는 다양한 가중치와 편향의 값이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7joYDuYQmL4p"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.2.2 단층 퍼셉트론의 한계\n",
    "\n",
    "- 이처럼 단층 퍼셉트론은 AND 게이트, NAND 게이트, OR 게이트 또한 구현할 수 있다.\n",
    "- 하지만 단층 퍼셉트론으로 구현이 불가능한 게이트가 있는데 바로 **XOR 게이트**이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PbWxjoIImYap"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.2.2.1 XOR 게이트\n",
    "\n",
    "- 입력값 두 개가 서로 다른 값을 갖고 있을때에만 출력값이 1이 된다.\n",
    "- 입력값 두 개가 서로 같은 값을 가지면 출력값이 0이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_og8LbipmlRD"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.2.2.2 단층 퍼셉트론으로 XOR 게이트 구현이 불가능한 이유\n",
    "\n",
    "- 위의 파이썬 코드에 아무리 수많은 가중치와 편향을 넣어봐도 XOR 게이트를 구현하는 것은 불가능하다.\n",
    "- 그 이유는 단층 퍼셉트론은 **직선 하나로 두 영역을 나눌 수 있는 문제에 대해서만 구현이 가능하기 때문**이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bcOpSLFvmzBA"
   },
   "source": [
    "- 예를 들어 AND 게이트에 대한 단층 퍼셉트론을 시각화해보면 다음과 같다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/24958/andgraphgate.PNG)\n",
    "\n",
    "- 그림에서는 출력값 0을 하얀색 원, 1을 검은색 원으로 표현했다.\n",
    "- AND 게이트를 충족하려면 하얀색 원과 검은색 원을 직선으로 나누게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FS_zh5HanCZI"
   },
   "source": [
    "- NAND 게이트나 OR 게이트에 대해서도 시각화를 했을 때 직선으로 나누는 것이 가능하다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/24958/oragateandnandgate.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gABZHMHTnG5o"
   },
   "source": [
    "- 그렇다면 XOR 게이트는 어떨까?\n",
    "- XOR 게이트는 입력값 두 개가 서로 다른 값을 갖고 있을때에만 출력값이 1이 되고, 입력값 두 개가 서로 같은 값을 가지면 출력값이 0이 되는 게이트이다.\n",
    "- XOR 게이트를 시각화해보면 다음과 같다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/24958/xorgraphandxorgate.PNG)\n",
    "\n",
    "- 하얀색 원과 검은색 원을 직선 하나로 나누는 것은 불가능하다.\n",
    "- 즉, 단층 퍼셉트론으로는 XOR 게이트를 구현하는 것이 불가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_DFN3bRnW0_"
   },
   "source": [
    "- 이를 단층 퍼셉트론은 **선형 영역에 대해서만 분리가 가능**하다고 말한다.\n",
    "- 다시 말하면 XOR 게이트는 직선이 아닌 곡선. 비선형 영역으로 분리하면 구현이 가능하다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/24958/xorgate_nonlinearity.PNG)\n",
    "\n",
    "- 위의 그림은 곡선을 사용한다면 하얀색 원과 검은색 원을 나눌 수 있음을 보여준다.\n",
    "- 이제 XOR 게이트를 만들 수 있는 다층 퍼셉트론에 대해서 알아보도록 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pe99kJCHngnP"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.3 다층 퍼셉트론 (MultiLayer Perceptron, MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Qbir9rSnqFn"
   },
   "source": [
    "- XOR 게이트는 기존의 AND, NAND, OR 게이트를 조합하면 만들 수 있다.\n",
    "- 퍼셉트론 관점에서 말하면, 층을 더 쌓으면 만들 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iWMg_0lFpNN8"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.1 다층 퍼셉트론과 단층 퍼셉트론의 차이\n",
    "\n",
    "- 단층 퍼셉트론은 입력층과 출력층만 존재한다.\n",
    "- 하지만, 다층 퍼셉트론은 **중간에 층을 더 추가**하였다는 점이 다르다.\n",
    "- 이렇게 입력층과 출력층 사이에 존재하는 층을 **은닉층(hidden layer)**이라고 한다.\n",
    "- 즉, 다층 퍼셉트론은 중간에 은닉층이 존재한다는 점이 단층 퍼셉트론과 다르다.\n",
    "- 다층 퍼셉트론은 줄여서 MLP라고도 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ftVXyOMYprRL"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.2 XOR 게이트를 구현한 다층 퍼셉트론\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/24958/perceptron_4image.jpg)\n",
    "\n",
    "- 위의 그림은 AND, NAND, OR 게이트를 조합하여 XOR 게이트를 구현한 다층 퍼셉트론의 예이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9IYWg9XBp_AK"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.3 은닉층의 개수\n",
    "\n",
    "- XOR 예제에서는 은닉층 1개만으로 문제를 해결할 수 있었지만, 다층 퍼셉트론은 본래 은닉층이 1개 이상인 퍼셉트론을 말한다.\n",
    "- 즉, XOR 문제보다 더욱 복잡한 문제를 해결하기 위해서 다층 퍼셉트론은 중간에 수많은 은닉층을 더 추가할 수 있다.\n",
    "- 은닉층의 개수는 2개일 수도 있고, 수십 개일수도 있고 사용자가 설정하기 나름이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uHEuaPALqJGC"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.4 심층 신경망 (Deep Neural Network, DNN)\n",
    "\n",
    "- 아래는 더 어려운 문제를 풀기 위해서 은닉층이 하나 더 추가되고(이 경우에는 은닉층이 2개), 뉴런의 개수를 늘린 다층 퍼셉트론의 모습을 보여준다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/24958/%EC%9E%85%EC%9D%80%EC%B8%B5.PNG)\n",
    "\n",
    "- 위와 같이 은닉층이 2개 이상인 신경망을 **심층 신경망(Deep Neural Network, DNN)**이라고 한다.\n",
    "- 심층 신경망은 다층 퍼셉트론만 이야기 하는 것이 아니라, 여러 변형된 다양한 신경망들도 은닉층이 2개 이상이 되면 심층 신경망이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pHM2jduhqKW6"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.5 학습(training) 단계 : 가중치 찾기\n",
    "\n",
    "- 지금까지는 OR, AND, XOR 게이트 등. 퍼셉트론이 가야할 정답을 참고로 퍼셉트론이 정답을 출력할 때까지 가중치를 바꿔보면서 맞는 가중치를 찾았다.  \n",
    "(즉, 가중치를 수동으로 찾았다.)\n",
    "- 하지만 이제는 기계가 가중치를 스스로 찾아내도록 자동화시켜야하는데, 이것이 머신 러닝에서 말하는 **학습(training)** 단계에 해당된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HbE1xiMgq2Ti"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.6 학습 단계에서 사용되는 것들\n",
    "\n",
    "- 앞서 선형 회귀와 로지스틱 회귀에서 보았듯이 학습 단계에서는 **손실 함수(Loss function)**와 **옵티마이저(Optimizer)**를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wMa2V8k4q_Ga"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.7 딥 러닝 (Deep Learning)\n",
    "\n",
    "- 만약 학습을 시키는 인공 신경망이 심층 신경망일 경우에는 이를 심층 신경망을 학습시킨다고 하여, **딥 러닝(Deep Learning)**이라고 한다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ch08_v01_Perceptron.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
