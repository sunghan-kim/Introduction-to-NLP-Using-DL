{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r4SdgcPHC6fm"
   },
   "source": [
    "# Ch09. 순환 신경망 (Recurrent Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ogWxpGODAEf"
   },
   "source": [
    "# v05. RNN을 이용한 텍스트 생성 (Text Generation using RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ApV9hwydDDxe"
   },
   "source": [
    "- 이번 챕터에서는 **다 대 일(many-to-one)** 구조의 RNN을 사용하여 문맥을 반영해서 텍스트를 생성하는 모델을 만들어 본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gy14A9KzDMRm"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 5.1 RNN을 이용하여 텍스트 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O9XD9PHNDPxS"
   },
   "source": [
    "- 다음과 같이 3 가지의 문장이 있다고 하자.\n",
    "\n",
    "> \"경마장에 있는 말이 뛰고 있다\"\n",
    "\n",
    "> \"그의 말이 법이다\"\n",
    "\n",
    "> \"가는 말이 고와야 오는 말이 곱다\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2iDsNGXbWDls"
   },
   "source": [
    "- 모델이 문맥을 학습할 수 있도록 전체 문장의 앞의 단어들을 전부 고려하여 학습하도록 데이터를 재구성한다면 아래와 같이 총 11개의 샘플이 구성된다.\n",
    "\n",
    "| samples | $X$                        | $y$    |\n",
    "| :------ | :------------------------- | :----- |\n",
    "| 1       | 경마장에                   | 있는   |\n",
    "| 2       | 경마장에 있는              | 말이   |\n",
    "| 3       | 경마장에 있는 말이         | 뛰고   |\n",
    "| 4       | 경마장에 있는 말이 뛰고    | 있다   |\n",
    "| 5       | 그의                       | 말이   |\n",
    "| 6       | 그의 말이                  | 법이다 |\n",
    "| 7       | 가는                       | 말이   |\n",
    "| 8       | 가는 말이                  | 고와야 |\n",
    "| 9       | 가는 말이 고와야           | 오는   |\n",
    "| 10      | 가는 말이 고와야 오는      | 말이   |\n",
    "| 11      | 가는 말이 고와야 오는 말이 | 곱다   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "40e3D5umWK8b"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 5.1.1 데이터에 대한 이해와 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fhRlCrvab7tw"
   },
   "source": [
    "#### 5.1.1.1 필요 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "p98gLPtWWezW",
    "outputId": "d3e5ff28-3e42-43e1-c9f5-4b46b098b710"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0wAYptLaWhPr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iff-YPJJWv-z"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.1.1.2 학습 데이터\n",
    "\n",
    "- 예제로 언급한 3개의 한국어 문장을 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k1SsG-6gW2aK"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"경마장에 있는 말이 뛰고 있다\n",
    "그의 말이 법이다\n",
    "가는 말이 고와야 오는 말이 곱다\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "c4jt3uGsW39q",
    "outputId": "1f017564-4a12-4003-f44e-9900e87ff9ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'경마장에 있는 말이 뛰고 있다\\n그의 말이 법이다\\n가는 말이 고와야 오는 말이 곱다'"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P27RpBZyW5JK"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.1.1.3 단어 집합 생성\n",
    "\n",
    "- 단어 집합을 생성하고 크기를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IRUNMWTWW9_K",
    "outputId": "910f8d4a-d8f1-4348-c227-9b58538784d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 12\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts([text])\n",
    "\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# 케라스 토크나이저의 정수 인코딩은 인덱스가 1부터 시작하지만,\n",
    "# 케라스의 원-핫 인코딩에서 배열의 인덱스가 0부터 시작하기 때문에\n",
    "# 배열의 크기를 실제 단어 집합의 크기보다 +1로 생성해야 하므로 미리 +1 선언\n",
    "\n",
    "print(\"단어 집합의 크기 : %d\" % vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QVTa4jBRXfxc"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 각 단어와 단어에 부여된 정수 인덱스를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "BPJpoaX5Xavq",
    "outputId": "9ccf3f21-8a25-4824-ae22-763558397816"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'가는': 8,\n",
       " '경마장에': 2,\n",
       " '고와야': 9,\n",
       " '곱다': 11,\n",
       " '그의': 6,\n",
       " '뛰고': 4,\n",
       " '말이': 1,\n",
       " '법이다': 7,\n",
       " '오는': 10,\n",
       " '있는': 3,\n",
       " '있다': 5}"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DCnZhaXHXddR"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.1.1.4 훈련 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OL4sq4tLXnUs",
    "outputId": "02fdf9ca-4638-4e3d-e358-8e69db36845a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습에 사용할 샘플의 개수 : 11\n"
     ]
    }
   ],
   "source": [
    "sequences = list()\n",
    "\n",
    "for line in text.split('\\n'):\n",
    "    encoded = t.texts_to_sequences([line])[0]\n",
    "\n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "\n",
    "print('학습에 사용할 샘플의 개수 : %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dMLGkosRY8oe"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 전체 샘플 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "WW57783VX9kQ",
    "outputId": "6091cf51-7f14-4549-83b8-a40d5efb4975"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3],\n",
       " [2, 3, 1],\n",
       " [2, 3, 1, 4],\n",
       " [2, 3, 1, 4, 5],\n",
       " [6, 1],\n",
       " [6, 1, 7],\n",
       " [8, 1],\n",
       " [8, 1, 9],\n",
       " [8, 1, 9, 10],\n",
       " [8, 1, 9, 10, 1],\n",
       " [8, 1, 9, 10, 1, 11]]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "umIsbGKaY6L4"
   },
   "source": [
    "- 위의 데이터는 아직 레이블로 사용될 단어를 분리하지 않은 훈련 데이터이다.\n",
    "- `[2, 3]` : `[경마장에, 있는]`\n",
    "- `[2, 3, 1]` : `[경마장에, 있는, 말이]`\n",
    "- 전체 훈련 데이터에 대해서 맨 우측에 있는 단어에 대해서만 레이블로 분리해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DH2I6ckDaRuj"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.1.1.5 훈련 데이터 패딩(padding)\n",
    "\n",
    "- 우선 전체 샘플에 대해서 길이를 일치시켜 준다.\n",
    "- 가장 긴 샘플의 길이를 기준으로 한다.\n",
    "- 현재 눈으로 봤을 때, 가장 길이가 긴 샘플은 `[8, 1, 9, 10, 1, 11]`이고 길이는 6이다.\n",
    "- 이를 코드로는 다음과 같이 구할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "cxrpHYp4bKgq",
    "outputId": "1d0248ce-4502-4bcb-f29b-6a6eb609cff5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이 : 6\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(l) for l in sequences)\n",
    "\n",
    "print('샘플의 최대 길이 : {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WPkRw8kbbRs7"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 전체 샘플의 길이를 6으로 패딩한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jX3PqshKbZHy"
   },
   "outputs": [],
   "source": [
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J-tWLi-ybfUx"
   },
   "source": [
    "- `pad_sequences()`는 모든 샘플에 대해서 0을 사용하여 길이를 맞춘다.\n",
    "- `maxlen`의 값으로 6을 주면 모든 샘플의 길이를 6으로 맞춰준다.\n",
    "- `padding`의 인자로 `pre`를 주면 길이가 6보다 짧은 샘플의 앞에 0으로 채운다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5CmH9ezRbsSp"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 전체 훈련 데이터 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "lxb1adBmbv5e",
    "outputId": "e0b66f7a-ffc7-4120-b908-88b4395ff2bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  2  3]\n",
      " [ 0  0  0  2  3  1]\n",
      " [ 0  0  2  3  1  4]\n",
      " [ 0  2  3  1  4  5]\n",
      " [ 0  0  0  0  6  1]\n",
      " [ 0  0  0  6  1  7]\n",
      " [ 0  0  0  0  8  1]\n",
      " [ 0  0  0  8  1  9]\n",
      " [ 0  0  8  1  9 10]\n",
      " [ 0  8  1  9 10  1]\n",
      " [ 8  1  9 10  1 11]]\n"
     ]
    }
   ],
   "source": [
    "print(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9brcMh8WbwtJ"
   },
   "source": [
    "- 길이가 6보다 짧은 모든 샘플에 대해서 앞에 9을 채워서 모든 샘플의 길이를 6으로 바꿨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fiDJS8bEcRLe"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.1.1.6 레이블 분리\n",
    "\n",
    "- 이제 각 샘플의 마지막 단어를 레이블로 분리한다.\n",
    "- 레이블의 분리는 Numpy를 이용해서 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gm7cz5w-b4mB"
   },
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)\n",
    "\n",
    "X = sequences[:, :-1] # 리스트의 마지막 값을 제외하고 저장한 것\n",
    "y = sequences[:, -1] # 리스트의 마지막 값만 저장한 것 (레이블)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w5q7YWglcqX7"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 분리된 X와 y 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "R0tK0lWBcsyD",
    "outputId": "9ca2bd3f-9757-4d85-97f7-c5d334d59255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  2]\n",
      " [ 0  0  0  2  3]\n",
      " [ 0  0  2  3  1]\n",
      " [ 0  2  3  1  4]\n",
      " [ 0  0  0  0  6]\n",
      " [ 0  0  0  6  1]\n",
      " [ 0  0  0  0  8]\n",
      " [ 0  0  0  8  1]\n",
      " [ 0  0  8  1  9]\n",
      " [ 0  8  1  9 10]\n",
      " [ 8  1  9 10  1]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "0dimOKUwctZB",
    "outputId": "2f72a5cd-ed07-4d63-9f51-6a973890b383"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  1  4  5  1  7  1  9 10  1 11]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l9v67NJxcu6w"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.1.1.7 레이블 원-핫 인코딩\n",
    "\n",
    "- 이제 RNN 모델에 훈련 데이터를 훈련 시키기 전에 레이블에 대해서 원-핫 인코딩을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-vi_VChbc5W3"
   },
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "2cUbfNgDc8o3",
    "outputId": "b37d2018-1e29-4ac0-b3a5-d4a6ff15fe19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iQx8_MEhc9fX"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 5.1.2 모델 설계하기\n",
    "\n",
    "- 이제 RNN 모델에 데이터를 훈련시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2tIReloqhMbH"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.1.2.1 필요 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jcKYdTwrdBvM"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P5YnN5pyevEC"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.1.2.2 모델 설계 및 훈련\n",
    "\n",
    "- 각 단어의 임베딩 벡터는 10차원을 가짐\n",
    "- 32의 은닉 상태를 가지는 바닐라 RNN을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fj2r3-rNdLkv"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=max_len-1)) # 레이블을 분리하였으므로 이제 X의 길이는 5\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, epochs=200, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JhXhIlFNd5Eh"
   },
   "source": [
    "```python\n",
    "Train on 11 samples\n",
    "Epoch 1/200\n",
    "11/11 - 1s - loss: 2.4856 - accuracy: 0.0000e+00\n",
    "Epoch 2/200\n",
    "11/11 - 0s - loss: 2.4748 - accuracy: 0.0000e+00\n",
    "Epoch 3/200\n",
    "11/11 - 0s - loss: 2.4640 - accuracy: 0.0000e+00\n",
    "\n",
    "...\n",
    "\n",
    "Epoch 198/200\n",
    "11/11 - 0s - loss: 0.0845 - accuracy: 1.0000\n",
    "Epoch 199/200\n",
    "11/11 - 0s - loss: 0.0831 - accuracy: 1.0000\n",
    "Epoch 200/200\n",
    "11/11 - 0s - loss: 0.0817 - accuracy: 1.0000\n",
    "<tensorflow.python.keras.callbacks.History at 0x7f94903de6a0>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z-RFvACceq2D"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.1.2.3 모델 평가\n",
    "\n",
    "- 모델이 정확하게 예측하고 있는 지 문장을 생성하는 함수를 만들어서 출력해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-aoRsdb_e7SP"
   },
   "outputs": [],
   "source": [
    "def sentence_generation(model, t, current_word, n):\n",
    "    # model : 모델, t : 토크나이저, current_word : 현재 단어, n : 반복할 횟수\n",
    "\n",
    "    init_word = current_word # 처음 들어온 단어도 마지막에 같이 출력하기 위해 저장\n",
    "    sentence = ''\n",
    "\n",
    "    for _ in range(n):\n",
    "\n",
    "        # 현재 단어에 대한 정수 인코딩\n",
    "        encoded = t.texts_to_sequences([current_word])[0]\n",
    "\n",
    "        # 데이터에 대한 패딩\n",
    "        encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n",
    "\n",
    "        # 입력한 X(현재 단어)에 대해서 Y를 예측하고 Y(예측한 단어)를 result에 저장\n",
    "        result = model.predict_classes(encoded, verbose=0)\n",
    "\n",
    "        for word, index in t.word_index.items():\n",
    "            if index == result: # 만약 예측한 단어와 동일한 인덱스와 동일한 단어가 있다면\n",
    "                break\n",
    "\n",
    "        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
    "        current_word = current_word + ' ' + word \n",
    "\n",
    "        # 예측 단어를 문장에 저장\n",
    "        sentence = sentence + ' ' + word\n",
    "\n",
    "    sentence = init_word + sentence\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "A16h6yJXgP6M",
    "outputId": "2e032b65-dc44-4cc4-c40b-9add86f98bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경마장에 있는 말이 뛰고 있다\n"
     ]
    }
   ],
   "source": [
    "# '경마장에' 라는 단어 뒤에는 총 4개의 단어가 있으므로 4번 예측\n",
    "print(sentence_generation(model, t, '경마장에', 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ls-TP5hKgcep",
    "outputId": "5a5abb26-f0b5-41b5-81b7-ca2329230b58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그의 말이 법이다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, t, '그의', 2)) # 2번 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "fTFWAG32g635",
    "outputId": "3c490a52-c51a-499e-ff4e-b8c383002c94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가는 말이 고와야 오는 말이 곱다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, t, '가는', 5)) # 5번 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KE8UG_EZg8TQ"
   },
   "source": [
    "- 이제 앞의 문맥을 기준으로 '말이' 라는 단어 다음에 나올 단어를 기존의 훈련 데이터와 일치하게 예측함을 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fQV9PxRfhJOA"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.1.2.4 모델의 한계\n",
    "\n",
    "- 이 모델은 충분한 훈련 데이터를 갖고 있지 못하므로 위에서 문장의 길이에 맞게 적절하게 예측해야 하는 횟수 4, 2, 5를 각각 인자값으로 주었다.\n",
    "- 이 이상의 숫자를 주면 기계는 '있다', '법이다', '곱다' 다음에 나오는 단어가 무엇인 지 배운 적이 없으므로 임의 예측을 한다.\n",
    "- 이제 더 많은 훈련 데이터를 가지고 실습을 해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9sDdsqIBhqqO"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 5.2 LSTM을 이용하여 텍스트 생성하기\n",
    "\n",
    "- 이번에는 LSTM을 통해 보다 많은 데이터로 텍스트를 생성해보자.\n",
    "- 본질적으로 앞에서 한 것과 동일한 실습이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G8VXbkjMhy3G"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 5.2.1 데이터에 대한 이해와 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SS7_8JWph2fT"
   },
   "source": [
    "#### 5.2.1.1 사용할 데이터\n",
    "\n",
    "- 뉴욕 타임즈 기사의 제목\n",
    "- [해당 링크](https://www.kaggle.com/aashita/nyt-comments)에서 `ArticlesApril2018.csv` 데이터 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cP8DBhQfh_hY"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.2.1.2 필요 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XD9ILEt1iTHI"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ruFuEohPihku"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.2.1.3 훈련 데이터 데이터프레임에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "colab_type": "code",
    "id": "dcpLqq4cilvo",
    "outputId": "1e96b38f-4b98-4672-edb5-107a72936b77"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>byline</th>\n",
       "      <th>documentType</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>printPage</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>webURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781</td>\n",
       "      <td>By JOHN BRANCH</td>\n",
       "      <td>article</td>\n",
       "      <td>Former N.F.L. Cheerleaders’ Settlement Offer: ...</td>\n",
       "      <td>['Workplace Hazards and Violations', 'Football...</td>\n",
       "      <td>68</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:16:49</td>\n",
       "      <td>Pro Football</td>\n",
       "      <td>“I understand that they could meet with us, pa...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/sports/foot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5adf653f068401528a2aa697</td>\n",
       "      <td>656</td>\n",
       "      <td>By LISA FRIEDMAN</td>\n",
       "      <td>article</td>\n",
       "      <td>E.P.A. to Unveil a New Rule. Its Effect: Less ...</td>\n",
       "      <td>['Environmental Protection Agency', 'Pruitt, S...</td>\n",
       "      <td>68</td>\n",
       "      <td>Climate</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:11:21</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>The agency plans to publish a new regulation T...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/climate/epa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5adf4626068401528a2aa628</td>\n",
       "      <td>2427</td>\n",
       "      <td>By PETE WELLS</td>\n",
       "      <td>article</td>\n",
       "      <td>The New Noma, Explained</td>\n",
       "      <td>['Restaurants', 'Noma (Copenhagen, Restaurant)...</td>\n",
       "      <td>66</td>\n",
       "      <td>Dining</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:58:44</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>What’s it like to eat at the second incarnatio...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/dining/noma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5adf40d2068401528a2aa619</td>\n",
       "      <td>626</td>\n",
       "      <td>By JULIE HIRSCHFELD DAVIS and PETER BAKER</td>\n",
       "      <td>article</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>['Macron, Emmanuel (1977- )', 'Trump, Donald J...</td>\n",
       "      <td>68</td>\n",
       "      <td>Washington</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:35:57</td>\n",
       "      <td>Europe</td>\n",
       "      <td>President Trump welcomed President Emmanuel Ma...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/world/europ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5adf3d64068401528a2aa60f</td>\n",
       "      <td>815</td>\n",
       "      <td>By IAN AUSTEN and DAN BILEFSKY</td>\n",
       "      <td>article</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>['Toronto, Ontario, Attack (April, 2018)', 'Mu...</td>\n",
       "      <td>68</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:21:21</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alek Minassian, 25, a resident of Toronto’s Ri...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/world/canad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  articleID  ...                                             webURL\n",
       "0  5adf6684068401528a2aa69b  ...  https://www.nytimes.com/2018/04/24/sports/foot...\n",
       "1  5adf653f068401528a2aa697  ...  https://www.nytimes.com/2018/04/24/climate/epa...\n",
       "2  5adf4626068401528a2aa628  ...  https://www.nytimes.com/2018/04/24/dining/noma...\n",
       "3  5adf40d2068401528a2aa619  ...  https://www.nytimes.com/2018/04/24/world/europ...\n",
       "4  5adf3d64068401528a2aa60f  ...  https://www.nytimes.com/2018/04/24/world/canad...\n",
       "\n",
       "[5 rows x 15 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ArticlesApril2018.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8rPKaiJ7ip08"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.2.1.4 훈련 데이터의 컬럼 확인\n",
    "\n",
    "- 어떤 열이 있고, 열이 총 몇 개가 있는 지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8uLEB3oai1x_",
    "outputId": "8798eff1-449a-4b18-884b-3247b5c45275"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "열의 개수 :  15\n"
     ]
    }
   ],
   "source": [
    "print('열의 개수 : ', len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "IdFuOZNTlN94",
    "outputId": "b9366607-336f-45e1-e9be-3538e1600cf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['articleID', 'articleWordCount', 'byline', 'documentType', 'headline',\n",
      "       'keywords', 'multimedia', 'newDesk', 'printPage', 'pubDate',\n",
      "       'sectionName', 'snippet', 'source', 'typeOfMaterial', 'webURL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FB8CB8MzlPSw"
   },
   "source": [
    "- 총 15개의 열이 존재\n",
    "- 여기서 사용할 열은 제목에 해당되는 `headline`이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VeIeUOIIlXqA"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.2.1.5 결측값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "a5i3FZmKlaOj",
    "outputId": "4532f62c-6833-483a-9f17-4d24ae721f84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['headline'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HSN441HEleRH"
   },
   "source": [
    "- Null 값은 별도로 없는 것 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wT13-NyllhSD"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.2.1.6 노이즈 데이터 확인\n",
    "\n",
    "- `headline` 열에서 모든 신문 기사의 제목을 뽑아서 하나의 리스트로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "JCWOK6q8lpOc",
    "outputId": "1b37bfa6-5dc7-46a5-b3d1-e42360c20b92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
       " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
       " 'The New Noma, Explained',\n",
       " 'Unknown',\n",
       " 'Unknown']"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline = []\n",
    "\n",
    "headline.extend(list(df.headline.values))\n",
    "headline[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yjGg_Zyblv4v"
   },
   "source": [
    "- 4번 째, 5번 째 샘플에 `Unknown` 값이 들어가 있다.\n",
    "- `headline` 전체에 걸쳐서 `Unknown` 값을 가진 샘플이 있을 것으로 추정된다.\n",
    "- 비록 Null 값은 아니지만 지금 하고자 하는 실습에 도움이 되지 않는 노이즈 데이터이므로 제거해 줄 필요가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k5Co7tvvmCI2"
   },
   "source": [
    "- 제거하기 전에 현재 샘플의 개수를 확인해보고 제거 전, 후의 샘플의 개수를 비교해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "uK0hk0c4mJCG",
    "outputId": "d68877dd-87f8-40b7-bf31-05a3ee5366eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 개수 : 1324\n"
     ]
    }
   ],
   "source": [
    "print('총 샘플의 개수 : {}'.format(len(headline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "pu73qLDamMWf",
    "outputId": "b4ac05fa-6b6b-4ff0-8053-c4aaf7fab510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "노이즈값 제거 후 샘플의 개수 : 1214\n"
     ]
    }
   ],
   "source": [
    "headline = [n for n in headline if n != \"Unknown\"]\n",
    "print('노이즈값 제거 후 샘플의 개수 : {}'.format(len(headline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "II2yXR_ZmUFm"
   },
   "source": [
    "- 샘플의 수가 1,324에서 1,214로 110개의 샘플이 제거됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qi4zjrcxmfdp"
   },
   "source": [
    "- 기존에 출력했던 5개의 샘플을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "kiP9LIDmmh15",
    "outputId": "2a81fe4e-a0bb-485a-ad46-9e0244c1b20e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
       " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
       " 'The New Noma, Explained',\n",
       " 'How a Bag of Texas Dirt  Became a Times Tradition',\n",
       " 'Is School a Place for Self-Expression?']"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4AO0shf9mi7u"
   },
   "source": [
    "- 기존에 4번째, 5번째 샘플에서는 Unknown 값이 있었는데 현재는 제거가 된 것을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wAEorPDdmmgF"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.2.1.7 데이터 전처리 수행\n",
    "\n",
    "- 여기서 선택한 전처리\n",
    "  - 구두점 제거\n",
    "  - 단어의 소문자화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z92nJ2f6mszB"
   },
   "source": [
    "- 전처리를 수행하고 다시 샘플 5개를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c21Fquf6mwwA"
   },
   "outputs": [],
   "source": [
    "def repreprocessing(s):\n",
    "    s = s.encode(\"utf8\").decode(\"ascii\", \"ignore\")\n",
    "\n",
    "    return ''.join(c for c in s if c not in punctuation).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "WbXL-A0zm9kl",
    "outputId": "e4c110bb-8575-41d2-acaf-7a702187d960"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['former nfl cheerleaders settlement offer 1 and a meeting with goodell',\n",
       " 'epa to unveil a new rule its effect less science in policymaking',\n",
       " 'the new noma explained',\n",
       " 'how a bag of texas dirt  became a times tradition',\n",
       " 'is school a place for selfexpression']"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [repreprocessing(x) for x in headline]\n",
    "text[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VLE10qyunCdM"
   },
   "source": [
    "- 기존의 출력과 비교\n",
    "  - 모든 단어들이 소문자화됨\n",
    "  - \"N.F.L\"이나 \"Cheerleaders'\" 등과 같이 기존에 구두점이 붙어있던 단어들에서 구두점이 제거됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gCVRngAgoQJn"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.2.1.8 단어 집합(vocabulary) 생성\n",
    "\n",
    "- 단어 집합을 만들고 크기를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "l29_-GYToVWm",
    "outputId": "3f8f21ef-e15b-4406-c7c6-2a7064b9f22b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 3494\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(text)\n",
    "vocab_size = len(t.index_word) + 1\n",
    "\n",
    "print('단어 집합의 크기 : %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cR4aOtrupr54"
   },
   "source": [
    "- 총 3,494개의 단어가 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K_iniLH5pzJP"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.2.1.9 정수 인코딩 및 훈련 데이터 구성\n",
    "\n",
    "- 이제 정수 인코딩과 동시에 하나의 문장을 여러 줄로 분해하여 훈련 데이터를 구성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "Wu3ZQNAsp9Rf",
    "outputId": "e09cd205-16f3-4e90-ed40-bc791c10a503"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[99, 269],\n",
       " [99, 269, 371],\n",
       " [99, 269, 371, 1115],\n",
       " [99, 269, 371, 1115, 582],\n",
       " [99, 269, 371, 1115, 582, 52],\n",
       " [99, 269, 371, 1115, 582, 52, 7],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10, 1116],\n",
       " [100, 3]]"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = list()\n",
    "\n",
    "for line in text: # 1,214개의 샘플에 대해서 샘플을 1개 씩 가져온다.\n",
    "    encoded = t.texts_to_sequences([line])[0] # 각 샘플에 대한 정수 인코딩\n",
    "    \n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "\n",
    "sequences[:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "03XTdMSjcdKG"
   },
   "source": [
    "```\n",
    "[[99, 269], # former nfl\n",
    " [99, 269, 371], # former nfl cheerleaders\n",
    " [99, 269, 371, 1115], # former nfl cheerleaders settlement\n",
    " [99, 269, 371, 1115, 582], # former nfl cheerleaders settlement offer\n",
    " [99, 269, 371, 1115, 582, 52], # 'former nfl cheerleaders settlement offer 1\n",
    " [99, 269, 371, 1115, 582, 52, 7], # former nfl cheerleaders settlement offer 1 and\n",
    " [99, 269, 371, 1115, 582, 52, 7, 2], # ... 이하 생략 ...\n",
    " [99, 269, 371, 1115, 582, 52, 7, 2, 372],\n",
    " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10],\n",
    " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10, 1116], # 모든 단어가 사용된 완전한 첫번째 문장\n",
    " # 바로 위의 줄 : former nfl cheerleaders settlement offer 1 and a meeting with goodell\n",
    " [100, 3]] # epa to에 해당되며 두번째 문장이 시작됨.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F35jStBpcv3S"
   },
   "source": [
    "- 왜 하나의 문장을 저렇게 나눌까?\n",
    "- 예를 들어, 다음과 같은 문장이 있다고 하자.\n",
    "\n",
    "> \"경마장에 있는 말이 뛰고 있다\"\n",
    "\n",
    "- 이 때 최종적으로 원하는 훈련 데이터의 형태는 다음과 같다.\n",
    "\n",
    "| samples | $X$                     | $y$  |\n",
    "| :------ | :---------------------- | :--- |\n",
    "| 1       | 경마장에                | 있는 |\n",
    "| 2       | 경마장에 있는           | 말이 |\n",
    "| 3       | 경마장에 있는 말이      | 뛰고 |\n",
    "| 4       | 경마장에 있는 말이 뛰고 | 있다 |\n",
    "\n",
    "- 하나의 단어를 예측하기 위해 이전에 등장한 단어들을 모두 참고하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n15j_WUYdH2r"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.2.1.10 `index_to_word`\n",
    "\n",
    "- 위의 `sequences`는 모든 문장을 각 단어가 각 시점(time step)마다 하나씩 추가적으로 등장하는 형태로 만들었다.\n",
    "- 하지만 아직 예측할 단어에 해당되는 레이블을 분리하는 작업까지는 수행하지 않은 상태이다.\n",
    "- 어떤 정수가 어떤 단어를 의미하는 지 알아보기 위해 인덱스로부터 단어를 찾는 `index_to_word`를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4oDnpsw5dfil",
    "outputId": "173f38ed-a7d1-44e1-abdc-f098af2dff28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빈도수 상위 582번 단어 : offer\n"
     ]
    }
   ],
   "source": [
    "index_to_word = {}\n",
    "\n",
    "for key, value in t.word_index.items():\n",
    "\n",
    "    index_to_word[value] = key\n",
    "\n",
    "print('빈도수 상위 582번 단어 : {}'.format(index_to_word[582]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lou0IwJrdtmn"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.2.1.11 패딩(padding)\n",
    "\n",
    "- 이제 $y$ 데이터를 분리하기 전에 전체 샘플의 길이를 동일하게 만드는 패딩 작업을 수행한다.\n",
    "- 패딩 작업을 수행하기 전에 가장 긴 샘플의 길이를 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "c40xPc5dd6ZT",
    "outputId": "326edb85-03b4-4475-e131-52efdf94750f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이 : 24\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(l) for l in sequences)\n",
    "print('샘플의 최대 길이 : {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vcpdahQeeEtt"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 가장 긴 샘플의 길이인 24로 모든 샘플의 길이를 패딩한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "sw63VBL_eJcx",
    "outputId": "d7ad1c78-2f2a-4556-e16f-a83a5f187aa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0   99  269]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0   99  269  371]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0   99  269  371 1115]]\n"
     ]
    }
   ],
   "source": [
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
    "print(sequences[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w0Fs9_zZePsf"
   },
   "source": [
    "- `padding='pre'`를 설정하여 샘플의 길이가 24보다 짧은 경우에 앞에 0으로 패딩되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SauohndCedil"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.2.1.12 레이블 분리\n",
    "\n",
    "- 이제 맨 우측 단어만 레이블로 분리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a2ZKwyUsehhp"
   },
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)\n",
    "\n",
    "X = sequences[:, :-1]\n",
    "y = sequences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "nMsOOIR9enQC",
    "outputId": "cd8ebae7-05e4-4eaf-dd22-f26daa71625b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0  99]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0  99 269]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0  99 269 371]]\n"
     ]
    }
   ],
   "source": [
    "print(X[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "oCTE-lqKepxR",
    "outputId": "7aa5c811-b472-4617-d730-e32d0be6dd6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 269  371 1115]\n"
     ]
    }
   ],
   "source": [
    "print(y[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cswt3ugkeuyA"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.2.1.13 레이블 원-핫 인코딩\n",
    "\n",
    "- 레이블 데이터 `y`에 대해서 원-핫 인코딩을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "753sFAZoe3Lw"
   },
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6cDKxIN8e7Bh"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 5.2.2 모델 설계하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sbXZXjiRfBPP"
   },
   "source": [
    "#### 5.2.2.1 필요 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KD4Wb4YbfE9d"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QlNR9AA1fLh7"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.2.2.2 모델 설계 및 훈련\n",
    "\n",
    "- 각 단어의 임베딩 벡터는 10차원을 가진다.\n",
    "- 128개의 은닉 상태 크기를 가지는 LSTM을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_kDKPbxtfOtE"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(vocab_size, 10, input_length=max_len-1)) # y 데이터를 분리하였으므로 이제 X 데이터의 길이는 기존 데이터의 길이 -1\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=200, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ly5h88NCrcZs"
   },
   "source": [
    "```\n",
    "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
    "Instructions for updating:\n",
    "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
    "Train on 7803 samples\n",
    "Epoch 1/200\n",
    "7803/7803 - 14s - loss: 7.6394 - acc: 0.0291\n",
    "Epoch 2/200\n",
    "7803/7803 - 13s - loss: 7.1143 - acc: 0.0327\n",
    "Epoch 3/200\n",
    "7803/7803 - 13s - loss: 6.9751 - acc: 0.0350\n",
    "\n",
    "...\n",
    "\n",
    "Epoch 198/200\n",
    "7803/7803 - 13s - loss: 0.2718 - acc: 0.9166\n",
    "Epoch 199/200\n",
    "7803/7803 - 13s - loss: 0.2712 - acc: 0.9161\n",
    "Epoch 200/200\n",
    "7803/7803 - 13s - loss: 0.2709 - acc: 0.9163\n",
    "<tensorflow.python.keras.callbacks.History at 0x7f6b15952e10>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R_SnAgclfyYj"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.2.2.3 `sentence_generation()` : 문장 생성 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0kO6KPaAf77w"
   },
   "outputs": [],
   "source": [
    "def sentence_generation(model, t, current_word, n):\n",
    "    # model : 모델\n",
    "    # t : 토크나이저\n",
    "    # current_word : 현재 단어\n",
    "    # n : 반복할 횟수\n",
    "\n",
    "    # 처음 들어온 단어도 마지막에 같이 출력하기 위해 저장\n",
    "    init_word = current_word\n",
    "    sentence = ''\n",
    "\n",
    "    for _ in range(n):\n",
    "\n",
    "        # 현재 단어에 대한 정수 인코딩\n",
    "        encoded = t.texts_to_sequences([current_word])[0]\n",
    "\n",
    "        # 데이터에 대한 패딩\n",
    "        encoded = pad_sequences([encoded], maxlen=23, padding='pre')\n",
    "\n",
    "        # 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장\n",
    "        result = model.predict_classes(encoded, verbose=0)\n",
    "\n",
    "        for word, index in t.word_index.items():\n",
    "\n",
    "            if index == result: # 만약 예측한 단어와 인덱스가 동일한 단어가 있다면\n",
    "                break # 해당 단어가 예측 단어이므로 break\n",
    "\n",
    "        current_word = current_word + ' ' + word\n",
    "        sentence = sentence + ' ' + word # 예측 단어를 문장에 저장\n",
    "\n",
    "    sentence = init_word + sentence\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dgICkAhRhE9_"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.2.2.4 문장 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ad79_isshHHd",
    "outputId": "3fc7df76-d0c8-46f8-9894-93463c134986"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i want to be rich and im not sorry in people\n"
     ]
    }
   ],
   "source": [
    "# 임의의 단어 'i'에 대해서 10개의 단어를 추가 생성\n",
    "print(sentence_generation(model, t, 'i', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hzqymq2LhLSG",
    "outputId": "6a64ab51-7ceb-486e-f805-dc5db2818dad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to make facebook more accountable ask live in tied to\n"
     ]
    }
   ],
   "source": [
    "# 임의의 단어 'how'에 대해서 10개의 단어를 추가 생성\n",
    "print(sentence_generation(model, t, 'how', 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCxCyFmJhOGo"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 5.3 참고할만한 자료\n",
    "\n",
    "- [LSTM 코드](http://adventuresinmachinelearning.com/keras-lstm-tutorial/)\n",
    "- [char-level rnn language model](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "- [Teacher Forcing](https://machinelearningmastery.com/teacher-forcing-for-recurrent-neural-networks/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ch09_v05_Text-Generation-using-RNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
