{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wpO3QoCzsO0I"
   },
   "source": [
    "# Ch09. 순환 신경망(Recurrent Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pi49TZY5sdmc"
   },
   "source": [
    "# v01. 순환 신경망(Recurrent Neural Network, RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A4PTR7NSsf8r"
   },
   "source": [
    "- RNN(Recurrent Neural Network)은 **시퀀스(Sequence) 모델**이다.\n",
    "- 입력과 출력을 시퀀스 단위로 처리하는 모델이다.\n",
    "- ex) 번역기\n",
    "  - 입력 : 번역하고자 하는 문장 (단어 시퀀스)\n",
    "  - 출력 : 해당되는 번역된 문장 (단어 시퀀스)\n",
    "- 이러한 시퀀스들을 처리하기 위해 고안된 모델들을 시퀀스 모델이라고 한다.\n",
    "- 그 중에서도 RNN은 딥 러닝에 있어 가장 기본적인 시퀀스 모델이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "da-FQn2wvA6I"
   },
   "source": [
    "- 뒤에서 배우는 LSTM이나 GRU 또한 근본적으로 RNN에 속한다.\n",
    "- RNN을 이해하고 이를 통해 11챕터의 텍스트 분류, 12챕터의 태깅 작업, 13챕터의 기계 번역을 이해한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x7ZXhWSkC8Tt"
   },
   "source": [
    "- cf) 용어는 비슷하지만 순환 신경망과 재귀 신경망(Recursive Neural Network)은 전혀 다른 개념이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n9BFzyKVDDKC"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.1 순환 신경망 (Recurrent Neural Network, RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WWfPRoIDGuHW"
   },
   "source": [
    "### 1.1.1 피드 포워드 신경망\n",
    "\n",
    "- 앞서 배운 신경망들은 전부 은닉층에서 활성화 함수를 지난 값은 오직 출력층 방향으로만 향했다.\n",
    "- 이와 같은 신경망들을 피드 포워드 신경망(Feed Forward Neural Network)이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "00y8LNCOEAVf"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.2 RNN의 특징\n",
    "\n",
    "- 그런데 그렇지 않은 신경망들이 있다.\n",
    "- RNN(Recurrent Neural Network) 또한 그 중 하나이다.\n",
    "- RNN은 은닉층의 노드에서 활성화 함수를 통해 나온 결과를 출력층 방향으로도 보내면서, 다시 은닉층 노드의 다음 계산의 입력으로 보내는 특징을 갖고 있다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/22886/rnn_image1_ver2.PNG)\n",
    "\n",
    "- 이를 그림으로 표현하면 위와 같다.\n",
    "- $x$ : 입력층의 입력 벡터\n",
    "- $y$ : 출력층의 출력 벡터\n",
    "- 실제로는 편향 $b$도 입력으로 존재할 수 있지만 앞으로의 그림에서는 생략한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KccVxwW1FBXP"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.3 셀 (Cell)\n",
    "\n",
    "- RNN에서 **은닉층에서 활성화 함수를 통해 결과를 내보내는 역할을 하는 노드**를 **셀(cell)**이라고 한다.\n",
    "- 이 셀은 이전의 값을 기억하려고 하는 일종의 메모리 역할을 수행하므로 이를 **메모리 셀** 또는 **RNN 셀**이라고 표현한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SjXxgAGyFRM1"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.4 시점 (time step)\n",
    "\n",
    "- 은닉층의 메모리 셀은 각각의 시점(time step)에서 바로 이전 시점에서의 은닉층의 메모리 셀에서 나온 값을 자신의 입력으로 사용하는 재귀적 활동을 하고 있다.\n",
    "- 앞으로는 현재 시점을 변수 t로 표현한다.\n",
    "- 이는 현재 시점 t에서의 메모리 셀이 갖고 있는 값은 과거의 메모리 셀들의 값에 영향을 받은 것임을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E30tpphCI5Ge"
   },
   "source": [
    "- 그렇다면 메모리 셀이 갖고 있는 이 값을 뭐라고 부를까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lG4hP5zNGr21"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.5 은닉 상태 (hidden state)\n",
    "\n",
    "- 메모리 셀이 출력층 방향으로 또는 다음 시점 t+1의 자신에게 보내는 값을 **은닉 상태(hidden state)**라고 한다.\n",
    "- 다시 말해 t 시점의 메모리 셀은 t-1 시점의 메모리 셀이 보낸 은닉 상태값을 t 시점의 은닉 상태 계산을 위한 입력값으로 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_16lyg8cI3U2"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.6 RNN 아키텍처\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/22886/rnn_image2_ver3.PNG)\n",
    "\n",
    "- RNN을 표현할 때는 일반적으로 위의 그림에서 좌측과 같이 화살표로 사이클을 그려서 재귀 형태로 표현하기도 한다.\n",
    "- 또는 우측과 같이 사이클을 그리는 화살표 대신 여러 시점으로 펼쳐서 표현하기도 한다.\n",
    "- 두 그림은 동일한 그림으로 단지 사이클을 그리는 화살표를 사용하여 표현하였느냐, 시점의 흐름에 따라서 표현하였느냐의 차이일 뿐 둘 다 동일한 RNN을 표현하고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MMD4crY6Le2u"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.7 RNN 층의 표현\n",
    "\n",
    "- 피드 포워드 신경망에서는 뉴런이라는 단위를 사용했다.\n",
    "- RNN에서는 뉴런이라는 단위보다는 각각의 층에서 다음과 같은 표현을 주로 사용한다.\n",
    "  - 입력층 : 입력 벡터\n",
    "  - 출력층 : 출력 벡터\n",
    "  - 은닉층 : 은닉 상태\n",
    "- 그래서 사실 위의 그림에서 회색과 초록색으로 표현한 각 네모들은 기본적으로 벡터 단위를 가정하고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yKfh--HJNWJ6"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.8 RNN 뉴런 단위 시각화\n",
    "\n",
    "- 피드 포워드 신경망과의 차이를 비교하기 위해서 RNN을 뉴런 단위로 시각화해보자.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/22886/rnn_image2.5.PNG)\n",
    "\n",
    "- 위의 그림은 각 층의 벡터의 차원(or 은닉 상태)이 아래와 같은 RNN이 시점이 2일 때의 모습을 보여준다.\n",
    "  - 입력층의 입력 벡터의 차원 : 4\n",
    "  - 은닉층의 은닉 상태의 크기 : 2\n",
    "  - 출력층의 출력 벡터의 차원 : 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BVE8E-uRTtDe"
   },
   "source": [
    "- 다시 말해 뉴런 단위로 해석하면 다음과 같다.\n",
    "  - 입력층의 뉴런 수 : 4\n",
    "  - 은닉층의 뉴런 수 : 2\n",
    "  - 출력층의 뉴런 수 : 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-C7PPMdGTwhb"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.9 입력과 출력의 길이에 따른 RNN의 다양한 형태\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/22886/rnn_image3_ver2.PNG)\n",
    "\n",
    "- RNN은 입력과 출력의 길이를 다르게 설계할 수 있으므로 다양한 용도로 사용할 수 있다.\n",
    "- 위 그림은 입력과 출력의 길이에 따라서 달라지는 RNN의 다양한 형태를 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e2I4HzasVzvC"
   },
   "source": [
    "- 위 구조가 자연어 처리에서 어떻게 사용될 수 있는 지 예를 들어보자.\n",
    "- RNN 셀의 각 시점별 입, 출력의 단위는 사용자가 정의하기 나름이지만 가장 보편적인 단위는 **'단어 벡터'**이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CT6JjQ9_WHJ3"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.1.9.1 일대다(one-to-many) 모델\n",
    "\n",
    "- 하나의 입력에 대해서 여러 개의 출력(one-to-many)의 모델\n",
    "- 하나의 이미지 입력에 대해서 사진의 제목을 출력하는 **이미지 캡셔닝(Image Captioning)** 작업에 사용할 수 있다.\n",
    "- 사진의 제목은 단어들의 나열이므로 시퀀스 출력이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZpqPm0iCWgYZ"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.1.9.2 다대일(many-to-one) 모델\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/22886/rnn_image3.5.PNG)\n",
    "\n",
    "- 단어 시퀀스에 대해서 하나의 출력(many-to-one)을 하는 모델\n",
    "- 다음과 같은 경우에 사용 가능\n",
    "  - **감성 분류(sentiment classification)** : 입력 문서가 긍정적인 지 부정적인 지를 판별 \n",
    "  - **스팸 메일 분류(spam detection)** : 메일이 정상 메일인지 스팸 메일인 지 판별\n",
    "- 위 그림은 RNN으로 스팸 메일을 분류할 때의 아키텍쳐를 보여준다.\n",
    "- 이러한 예제들은 **11챕터에서 배우는 텍스트 분류**에서 배운다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_x9uVvFvXaUw"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.1.9.3 다대다(many-to-many) 모델\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/22886/rnn_image3.7.PNG)\n",
    "\n",
    "- 다대다(many-to-many) 모델은 다음과 같은 경우에 사용\n",
    "  - **챗봇** : 입력 문장으로 부터 대답 문장을 출력\n",
    "  - **번역기** : 입력 문장으로부터 번역된 문장을 출력\n",
    "  - **개체명 인식** (12챕터에서 학습)\n",
    "  - **품사 태깅** (12챕터에서 학습)\n",
    "- 위 그림은 개체명 인식을 수행할 때의 RNN 아키텍처를 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z2W6hD-MYHnt"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.10 RNN 수식 정의\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/22886/rnn_image4_ver2.PNG)\n",
    "\n",
    "- $h_t$ : 현재 시점 t에서의 은닉 상태값\n",
    "- 은닉층의 메모리 셀은 $h_t$를 계산하기 위해서 총 두 개의 가중치를 갖게 된다.\n",
    "  1. $W_x$ : 입력층에서 입력값을 위한 가중치\n",
    "  2. $W_h$ : 이전 시점 t-1의 은닉 상태값 $h_{t-1}$을 위한 가중치 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZgVlqoU-ZcmK"
   },
   "source": [
    "- 이를 식으로 표현하면 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LQdzNc72ZfVB"
   },
   "source": [
    "- 은닉층 : \n",
    "$\n",
    "\\quad\n",
    "h_t = tanh \\left( W_x \\; x_t + W_h \\; h_{t-1} + b \\right)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fNb5H3VkZqya"
   },
   "source": [
    "- 출력층 : \n",
    "$\n",
    "\\quad\n",
    "y_t = f \\left( W_y \\; h_t + b \\right)\n",
    "\\quad\n",
    "$\n",
    "$f$ : 비선형 활성화 함수 중 하나"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gln7-If8Z9yn"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.11 RNN의 은닉층 연산\n",
    "\n",
    "- RNN의 은닉층 연산을 벡터와 행렬 연산으로 이해할 수 있다.\n",
    "- 자연어 처리에서 RNN의 입력 $x_t$는 대부분의 경우 단어 벡터로 간주할 수 있다.\n",
    "- $d$와 $D_h$를 다음과 같이 정의했을 때, 각 벡터와 행렬의 크기는 다음과 같다.\n",
    "  - $d$ : 단어 벡터의 차원\n",
    "  - $D_h$ : 은닉 상태의 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4l7D72pnaVT-"
   },
   "source": [
    "- $x_t$ : $\\left( d \\times 1 \\right)$\n",
    "- $W_x$ : $\\left( D_h \\times d \\right)$\n",
    "- $W_h$ : $\\left( D_h \\times D_h \\right)$\n",
    "- $h_{t-1}$ : $\\left( D_h \\times 1 \\right)$\n",
    "- $b$ : $\\left( D_h \\times 1 \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AHjJdbySaxtJ"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 배치 크기가 1이고, $d$와 $D_h$ 두 값 모두를 4로 가정했을 때, RNN의 은닉층 연산을 그림으로 표현하면 아래와 같다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/22886/rnn_images4-5.PNG)\n",
    "\n",
    "- 이 때 $h_t$를 계산하기 위한 활성화 함수로는 주로 **하이퍼볼릭 탄젠트 함수(tanh)**가 사용된다.  \n",
    "(ReLU로 바꿔 사용하는 시도도 있다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RMi1Rg4FbHqV"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.12 가중치의 값\n",
    "\n",
    "- 위의 식에서 각각의 가중치 $W_x$, $W_h$, $W_y$의 값은 모든 시점에서 값을 동일하게 공유한다.\n",
    "- 만약 은닉층이 2개 이상일 경우에는 은닉층 2개의 가중치는 서로 다른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_w9D401ibX5G"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.1.13 출력층 활성화 함수\n",
    "\n",
    "- 출력층은 결과값인 $y_t$를 계산하기 위한 활성화 함수로는 상황에 따라 다르게 사용된다.\n",
    "  - 이진 분류를 해야 하는 경우 : 시그모이드 함수 사용\n",
    "  - 다양한 카테고리 중에서 선택해야 하는 문제 : 소프트맥스 함수 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X-JNcycfbllp"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.2 케라스(Keras)로 RNN 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nmo6VVE9bqtS"
   },
   "source": [
    "### 1.2.1 케라스로 RNN 층 추가\n",
    "\n",
    "```python\n",
    "# RNN 층을 추가하는 코드\n",
    "model.add(SimpleRNN(hidden_size)) # 가장 간단한 형태\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kZPHaTu4bzRb"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.2.2 인자 사용\n",
    "\n",
    "```python\n",
    "# 추가 인자를 사용할 때\n",
    "model.add(SimpleRNN(hidden_size, input_shape=(timesteps, input_dim))\n",
    "\n",
    "# 다른 표기\n",
    "model.add(SimpleRNN(hidden_size, input_length=M, input_dim=N)) # 단, M과 N은 정수\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GpdoaTlDcHSK"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.2.2.1 `hidden_size`\n",
    "\n",
    "- 은닉 상태의 크기를 정의\n",
    "- 메모리 셀이 다음 시점의 메모리 셀과 출력층으로 보내는 값의 크기(`output_dim`)와도 동일\n",
    "- RNN의 용량(capacity)을 늘린다고 보면 된다.\n",
    "- 중소형 모델의 경우 보통 128, 256, 512, 1024 등의 값을 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LEbxWKFMccNy"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.2.2.2 `timesteps`\n",
    "\n",
    "- 입력 시퀀스의 길이(`input_length`)라고 표현하기도 한다.\n",
    "- 시점의 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2EgV1U2cciTP"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.2.2.3 `input_dim`\n",
    "\n",
    "- 입력의 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5sY03jyGclh-"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.2.3 RNN 입력 텐서의 크기\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/22886/rnn_image6between7.PNG)\n",
    "\n",
    "- RNN 층은 `(batch_size, timesteps, input_dim)` 크기의 3D 텐서를 입력으로 받는다.\n",
    "- `batch_size`는 한 번에 학습하는 데이터의 개수를 말한다.\n",
    "- 다만, 이러한 표현은 사람이나 문헌에 따라서, 또는 풀고자 하는 문제에 따라서 종종 다르게 기재된다.\n",
    "- 위의 그림은 문제와 상황에 따라서 다르게 표현되는 입력 3D 텐서의 대표적인 표현들을 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MdX_DjcjsXjW"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.2.4 RNN층에 대한 코드\n",
    "\n",
    "- 헷갈리지 말아야 할 점은 위의 코드는 출력층까지 포함한 하나의 완성된 인공 신경망 코드가 아니라 은닉층, 즉 RNN 층에 대한 코드라는 점이다.\n",
    "- 해당 코드가 리턴하는 결과값은 출력층의 결과가 아니라 하나의 은닉 상태 또는 정의하기에 따라 다수의 은닉 상태이다.\n",
    "- 아래의 그림은 앞서 배운 출력층을 포함한 완성된 인공 신경망 그림과 은닉층까지만 표현한 그림의 차이를 보여준다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/22886/rnn_image7_ver2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wGO8dYCtG0o"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.2.5 RNN 층의 2가지 형태의 은닉 상태 출력 방법\n",
    "\n",
    "- RNN 층은 위에서 설명한 입력 3D 텐서를 입력받아서 어떻게 은닉 상태를 출력할까?\n",
    "- RNN 층은 사용자의 설정에 따라 두 가지 종류의 출력을 내보낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TNFBZYa-t6Rt"
   },
   "source": [
    "1. 메모리 셀의 최종 시점의 은닉 상태만 리턴  \n",
    "$\\rightarrow$ `(batch_size, output_dim)` 크기의 2D 텐서 리턴\n",
    "2. 메모리 셀의 각 시점(time step)의 은닉 상태값들을 모아서 전체 시퀀스를 리턴  \n",
    "$\\rightarrow$ `(batch_size, timesteps, output_dim)` 크기의 3D 텐서 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "etF8bbYet_Ns"
   },
   "source": [
    "- 이는 RNN 층의 `return_sequences` 매개 변수에 `True`를 설정하여 사용이 가능하다.\n",
    "- `output_dim`은 앞서 코드에서 정의한 `hidden_size`의 값으로 설정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZzqycWBt_zD"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.2.6 `return_sequences` 매개 변수 설정 차이\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/22886/rnn_image8_ver2.PNG)\n",
    "\n",
    "- 위의 그림은 `time_steps=3`일 때, `return_sequences=True`를 설정했을 때와 그렇지 않았을 때 어떤 차이가 있는 지를 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kdw5JBFEuN-r"
   },
   "source": [
    "- `return_sequences=True` 선택\n",
    "  - 메모리 셀이 모든 시점(time step)에 대해서 은닉 상태값을 출력\n",
    "  - 모든 시점의 은닉 상태를 전달  \n",
    "  $\\rightarrow$ 다음층이 하나 더 있는 경우  \n",
    "  $\\rightarrow$ many-to-many 문제를 풀 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_DK_w7KcvS-p"
   },
   "source": [
    "- `return_sequences=False` 선택 (또는 별도로 기재 x)\n",
    "  - 메모리 셀은 하나의 은닉 상태값만을 출력한다.\n",
    "  - 그리고 이 하나의 값은 마지막 시점(time step)의 메모리 셀의 은닉 상태 값이다.\n",
    "  - 마지막 은닉 상태만 전달  \n",
    "  $\\rightarrow$ many-to-one 문제를 풀 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21jnr-w3vcAq"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.2.7 RNN 실습\n",
    "\n",
    "- 뒤에서 배우는 LSTM이나 GRU도 내부 메커니즘은 다르지만 `model.add()`를 통해서 층을 추가하는 코드는 사실상 `SimpleRNN` 코드와 같은 형태를 가진다.\n",
    "- 실습을 통해 모델 내부적으로 출력 결과를 어떻게 정의하는 지 보면서 RNN을 이해해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "p31NeZ1Y7-AX",
    "outputId": "3126f538-3d6c-4649-c579-f18c268a9936"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.x selected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dg0ehAU37-70"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "X9dUcSdg8E27",
    "outputId": "ba938de9-ff4f-4bae-a074-0cd68133b4e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, input_shape=(2,10)))\n",
    "# model.add(SimpleRNN(3, input_length=2, input_dim=10)) 와 동일함\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vmVrCHvR9Ecm"
   },
   "source": [
    "- 출력값이 `(batch_size, output_dim)` 크기의 2D 텐서일 때, `output_dim` 은 `hidden_size`의 값인 3이다.\n",
    "- 이 경우 `batch_size`를 현 단계에서는 알 수 없으므로 `(None, 3)`이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9fLVD2GC9v6l"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 이번에는 `batch_size`를 미리 정의해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "Ka5lLL459zHi",
    "outputId": "0c03f81f-120f-4134-97dd-05ef1eb4b85f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (8, 3)                    42        \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, batch_input_shape=(8, 2, 10)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "czct8PIQ97D-"
   },
   "source": [
    "- `batch_size`를 8로 기재하자, 출력의 크기가 `(8, 3)`이 된 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KItPDhoS-Nqt"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 이제 `return_sequences` 매개 변수에 `True`를 기재하여 출력값으로 `(batch_size, timesteps, output_dim)` 크기의 3D 텐서를 리턴하도록 모델을 만들어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "elVMpzjF-Q6L",
    "outputId": "5cb8ba92-7062-4842-9158-2b4727d5321f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (8, 2, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, batch_input_shape=(8,2,10), return_sequences=True))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9zM17yjm-b61"
   },
   "source": [
    "- 출력의 크기가 `(8,2,3)`이 된 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FmzKKUt9-yWU"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.3 파이썬으로 RNN 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K7tCHQH2-03W"
   },
   "source": [
    "- 직접 Numpy로 RNN 층을 구현해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M5DkoD9z-9Ii"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.1 메모리 셀에서 은닉 상태를 계산하는 식\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "h_t = tanh \\left( W_x \\, X_t + W_h \\, h_{t-1} + b \\right)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8YOucKGD_Kmk"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.2 의사 코드(pseudocode) 작성\n",
    "\n",
    "- 실제 구현에 앞서 간단한 의사 코드(pseudocode)를 작성해보자.\n",
    "\n",
    "```python\n",
    "# 아래의 코드는 의사 코드(pseudocode)로 실제 동작하는 코드가 아님\n",
    "\n",
    "hidden_state_t = 0 # 초기 은닉 상태를 0(벡터)로 초기화\n",
    "\n",
    "for input_t in input_length: # 각 시점마다 입력을 받는다.\n",
    "    output_t = tanh(input_t, hidden_state_t) # 각 시점에 대해서 입력과 은닉 상태를 가지고 연산\n",
    "    hidden_state_t = output_t # 계산 결과는 현재 시점의 은닉 상태가 된다.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wKJoK2j0_z1e"
   },
   "source": [
    "- t 시점의 은닉 상태를 `hidden_state_t`라는 변수로 선언\n",
    "- 입력 데이터의 길이를 `input_length`로 선언\n",
    "- 이 경우, 입력 데이터의 길이는 곧 총 시점의 수(timesteps)가 된다.\n",
    "- 그리고 t 시점의 입력값을 `input_t`로 선언했다.\n",
    "- 각 메모리 셀은 각 시점마다 `input_t`와 `hidden_state_t`(이전 상태의 은닉 상태)를 입력으로 활성화 함수인 하이퍼볼릭 탄젠트 함수를 통해 현 시점의 `hidden_state_t`를 계산한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AZ-mZBVdCv4W"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.3 실제 동작되는 코드 구현\n",
    "\n",
    "- 이제 RNN 층을 실제 동작되는 코드로 구현해보자.\n",
    "- 아래의 코드는 이해를 돕기 위해 `(timesteps, input_dim)` 크기의 2D 텐서를 입력으로 받았다고 가정했다.\n",
    "- 실제로 케라스에서는 `(batch_size, timesteps, input_dim)`의 크기의 3D 텐서를 입력으로 받는 것을 기억하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "3qxOwILiC-mF",
    "outputId": "0695b2e6-94cc-4d99-d71c-4be4c67fc0f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.27410811 0.23168261 0.89706688 0.96980511]\n",
      " [0.8498765  0.14192757 0.08394766 0.23022738]\n",
      " [0.12040118 0.00659085 0.06738881 0.96971094]\n",
      " [0.45171124 0.91111798 0.87302842 0.54659368]\n",
      " [0.08480234 0.60586855 0.06234439 0.98092726]\n",
      " [0.48516947 0.59274946 0.11001324 0.46833665]\n",
      " [0.77368785 0.21096529 0.12335165 0.98600379]\n",
      " [0.42395517 0.06529579 0.2411971  0.19366944]\n",
      " [0.49189486 0.73918781 0.74156095 0.7817914 ]\n",
      " [0.4287297  0.56022891 0.28081864 0.91088417]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "timesteps = 10 # 시점의 수. NLP에서는 보통 문장의 길이가 된다.\n",
    "input_dim = 4 # 입력의 차원. NLP에서는 보통 단어 벡터의 차원이 된다.\n",
    "hidden_size = 8 # 은닉 상태의 크기. 메모리 셀의 용량이다.\n",
    "\n",
    "inputs = np.random.random((timesteps, input_dim)) # 입력에 해당되는 2D 텐서\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4fXrW1ShECOO",
    "outputId": "296bc430-0e71-450a-f10d-8240933d64a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "hidden_state_t = np.zeros((hidden_size,)) # 초기 은닉 상태는 0(벡터)로 초기화\n",
    "# 은닉 상태의 크기 hidden_size로 은닉 상태를 만듬\n",
    "print(hidden_state_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D15UP3D9EQyF"
   },
   "source": [
    "- 우선 시점(`timesteps`), 입력의 차원(`input_dim`), 은닉 상태의 크기(`hidden_size`), 그리고 초기 은닉 상태(`hidden_state_t`)를 정의했다.\n",
    "- 현재 초기 은닉 상태는 0의 값을 가지는 벡터로 초기화가 된 상태이다.\n",
    "- 은닉 상태의 크기를 8로 정의하였으므로 8의 차원을 가지는 0의 값으로 구성된 벡터가 출력된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e17TfnK8EZKt"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 이제 가중치와 편향을 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aB8QDMBOE4g8"
   },
   "outputs": [],
   "source": [
    "Wx = np.random.random((hidden_size, input_dim)) # (8, 4) 크기의 2D 텐서 생성. 입력에 대한 가중치\n",
    "Wh = np.random.random((hidden_size, hidden_size)) # (8, 8) 크기의 2D 텐서 생성. 은닉 상태에 대한 가중치\n",
    "b = np.random.random((hidden_size,)) # (8, ) 크기의 1D 텐서 생성. 편향(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "cUy6mk5CFO3U",
    "outputId": "e6307218-8949-42ea-c0a3-dd3006d095dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wx shape :  (8, 4) \n",
      "\n",
      "[[0.99712588 0.43968544 0.74486555 0.11088646]\n",
      " [0.71530296 0.04137311 0.99678117 0.72065782]\n",
      " [0.5518279  0.99905794 0.27283928 0.31356806]\n",
      " [0.58487428 0.90917774 0.03119305 0.37729114]\n",
      " [0.32505609 0.37604724 0.43370984 0.88758978]\n",
      " [0.58207985 0.97946863 0.9344981  0.61230238]\n",
      " [0.73843427 0.38304147 0.49623324 0.26818938]\n",
      " [0.5741706  0.22667425 0.45151019 0.15159209]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Wx shape : \", Wx.shape, \"\\n\")\n",
    "print(Wx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "id": "QpJ7l5YiFRmT",
    "outputId": "baae2c3b-d926-490e-878f-e69d1d7fd850"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wh shape :  (8, 8) \n",
      "\n",
      "[[0.50610563 0.91401507 0.86771642 0.19027208 0.48112934 0.57640491\n",
      "  0.20612381 0.87107571]\n",
      " [0.18435513 0.00244849 0.40668458 0.18687994 0.43673658 0.6598322\n",
      "  0.49524616 0.48444975]\n",
      " [0.94664994 0.8538738  0.91781661 0.19600919 0.80306865 0.62923315\n",
      "  0.86651394 0.57240604]\n",
      " [0.53382121 0.6737277  0.14482861 0.34479468 0.64350756 0.59214472\n",
      "  0.17105043 0.32989381]\n",
      " [0.41833602 0.36595313 0.3966871  0.31101892 0.2631747  0.06214995\n",
      "  0.64464894 0.19689287]\n",
      " [0.79778519 0.13651699 0.24126831 0.25468391 0.98366363 0.88315444\n",
      "  0.27880753 0.82028179]\n",
      " [0.4229681  0.61499518 0.83320555 0.42818037 0.4127449  0.33905948\n",
      "  0.37771843 0.06762895]\n",
      " [0.71050902 0.22882297 0.42808319 0.69809513 0.02332427 0.21906487\n",
      "  0.24608204 0.8325457 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Wh shape : \", Wh.shape, \"\\n\")\n",
    "print(Wh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "_4k2yd5IFbN1",
    "outputId": "c3a2a3f6-4a34-487e-c94b-b7cdfafebd21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b shape :  (8,) \n",
      "\n",
      "[0.96625293 0.97774822 0.96614058 0.40362872 0.94565634 0.09739178\n",
      " 0.22314905 0.35709019]\n"
     ]
    }
   ],
   "source": [
    "print(\"b shape : \", b.shape, \"\\n\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8v7fyegJFx3D"
   },
   "source": [
    "- 각 가중치와 편향의 크기는 위와 같다.\n",
    "- `Wx`는 `(은닉 상태의 크기 x 입력의 차원)`, `Wh`는 `(은닉 상태의 크기 x 은닉 상태의 크기)`, `b`는 `(은닉 상태의 크기)`를 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o9mC34adGBOl"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 이제 모든 시점의 은닉 상태를 출력한다고 가정하고, RNN 층을 동작시켜보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "colab_type": "code",
    "id": "7UXb1NTBGNgA",
    "outputId": "edfd85e4-a5e9-4d76-fd38-1a9c5d6e67e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8)\n",
      "(2, 8)\n",
      "(3, 8)\n",
      "(4, 8)\n",
      "(5, 8)\n",
      "(6, 8)\n",
      "(7, 8)\n",
      "(8, 8)\n",
      "(9, 8)\n",
      "(10, 8)\n",
      "[[0.97143533 0.99227801 0.95604188 0.82378085 0.98273366 0.95758577\n",
      "  0.83952131 0.80723513]\n",
      " [0.99999255 0.99971799 0.99999852 0.99965889 0.99924276 0.99991101\n",
      "  0.99961754 0.9992778 ]\n",
      " [0.99998369 0.99982979 0.99999876 0.99961731 0.99977001 0.99994212\n",
      "  0.99945492 0.99931661]\n",
      " [0.99999874 0.99996371 0.99999988 0.99993442 0.99990106 0.99999751\n",
      "  0.99990576 0.9998297 ]\n",
      " [0.99998963 0.99983088 0.99999961 0.99986715 0.99985253 0.99998148\n",
      "  0.99963785 0.99945769]\n",
      " [0.99999507 0.99981811 0.99999966 0.99987489 0.99972619 0.99997955\n",
      "  0.99974557 0.99961417]\n",
      " [0.99999661 0.99994263 0.99999961 0.99987915 0.99988073 0.99998402\n",
      "  0.99983357 0.99972192]\n",
      " [0.99999226 0.9997629  0.99999883 0.99957231 0.99938472 0.99993244\n",
      "  0.99957581 0.99949277]\n",
      " [0.99999844 0.99996781 0.99999985 0.99992775 0.99991901 0.99999681\n",
      "  0.99989822 0.99981571]\n",
      " [0.99999601 0.99992572 0.99999973 0.9998996  0.99988565 0.99999017\n",
      "  0.99981135 0.99968716]]\n"
     ]
    }
   ],
   "source": [
    "total_hidden_states = []\n",
    "\n",
    "# 메모리 셀 동작\n",
    "for input_t in inputs: # 각 시점에 따라서 입력값이 입력됨\n",
    "    output_t = np.tanh(np.dot(Wx, input_t) + np.dot(Wh, hidden_state_t) + b) # Wx * Xt + Wh * Ht-1 + b(bias)\n",
    "    total_hidden_states.append(list(output_t)) # 각 시점의 은닉 상태의 값을 계속해서 축적\n",
    "    print(np.shape(total_hidden_states)) # 각 시점 t 별 메모리 셀의 출력의 크기는 (timesteps, output_dim)\n",
    "    hidden_state_t = output_t\n",
    "\n",
    "total_hidden_states = np.stack(total_hidden_states, axis=0) # 출력 시 값을 깔끔하게 해 준다.\n",
    "\n",
    "print(total_hidden_states) # (timesteps, output_dim)의 크기. 이 경우 (10, 8)의 크기를 가지는 메모리 셀의 2D 텐서 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U7oJcD4bHYiW"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.4 BPTT (Backpropagation through time, BPTT)\n",
    "\n",
    "- RNN도 다른 인공 신경망과 마찬가지로 역전파를 통해서 학습을 진행한다.\n",
    "- 피드 포워드 신경망의 역전파와 다른 점\n",
    "  - RNN은 전체 시점에 대해서 네트워크를 펼친 다음에 역전파를 사용\n",
    "  - 모든 시점에 대해서 가중치를 공유함\n",
    "- RNN의 이러한 역전파 과정을 **BPTT(BackPropagation Through Time)**이라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YatAsiQ6ImsC"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.5 깊은 순환 신경망 (Deep Recurrent Neural Network)\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/22886/rnn_image4.5_finalPNG.PNG)\n",
    "\n",
    "- 앞서 RNN도 다수의 은닉층을 가질 수 있다고 언급한 바 있다.\n",
    "- 위의 그림은 순환 신경망에서 은닉층이 1개 더 추가되어 은닉층이 2개인 깊은(deep) 순환 신경망의 모습을 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Q59P7wBI6Ym"
   },
   "source": [
    "- 은닉층을 2개 추가하는 경우 코드는 아래와 같다.\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(SimpRNN(hidden_size, return_sequences=True)\n",
    "model.add(SimpRNN(hidden_size, return_sequences=True)\n",
    "```\n",
    "\n",
    "- 위의 코드는 첫 번째 은닉층은 다음 은닉층이 존재하므로 `return_sequences=True`를 설정하여 모든 시점에 대해서 은닉 상태 값을 다음 은닉층으로 보내주고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fhCzBLFRI94r"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.6 양방향 순환 신경망 (Bidirectional Recurrent Nerual Network)\n",
    "\n",
    "- 양방향 순환 신경망은 시점 t에서의 출력값을 예측할 때 이전 시점의 데이터뿐만 아니라, 이후 데이터로도 예측할 수 있다는 아이디어에 기반한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "comjaj-JJdx-"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.6.1 영어 빈간 채우기 문제에 비유\n",
    "\n",
    "> Exercise **is** very effective at [$\\qquad \\qquad$] belly fat.\n",
    "\n",
    "> 1) reducing  \n",
    "2) increasing  \n",
    "3) multiplying\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8mdEgnN1KDCL"
   },
   "source": [
    "- '운동은 복부 지방을 [] 효과적이다'라는 영어 문장\n",
    "- 정답은 reducing(줄이는 것)이다.\n",
    "- 그런데 위의 영어 빈 칸 채우기 문제를 잘 생각해보면 정답을 찾기 위해서는 이전에 나온 단어들만으로는 부족하다.\n",
    "- 목적어인 belly fat(복부 지방)를 모르는 상태라면 정답을 결정하기가 어렵다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y11AJImYKbA7"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.6.2 양방향 RNN의 아이디어\n",
    "\n",
    "- RNN이 과거 시점(time step)의 데이터들을 참고해서, 찾고자하는 정답을 예측한다.\n",
    "- 하지만 실제 문제에서는 과거 시점의 데이터만 고려하는 것이 아니라 향후 시점의 데이터에 힌트가 있는 경우도 많다.\n",
    "- 그래서 이전 시점의 데이터뿐만 아니라, 이후 시점의 데이터도 힌트로 활용하기 위해서 고안된 것이 양방향 RNN이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x7F0tVgeKz22"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.6.3 양방향 RNN의 메모리 셀\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/22886/rnn_image5_ver2.PNG)\n",
    "\n",
    "- 양방향 RNN은 하나의 출력값을 예측하기 위해 기본적으로 **두 개의 메모리 셀을 사용**한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i9YCDrlMLFeG"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.3.1 첫 번째 메모리 셀\n",
    "\n",
    "- 첫 번째 메모리 셀은 앞서 배운 것처럼 **앞 시점의 은닉 상태(Forward States)**를 전달받아 현재의 은닉 상태를 계산한다.\n",
    "- 위의 그림에서는 <font color='orange'>주황색 메모리 셀</font>에 해당된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PMXXNANCLcSW"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.3.2 두 번째 메모리 셀\n",
    "\n",
    "- 두 번째 메모리 셀은 앞에서 배운 것과는 다르다.\n",
    "- 앞 시점의 은닉 상태가 아니라 **뒤 시점의 은닉 상태(Backward States)**를 전달 받아 현재의 은닉 상태를 계산한다.\n",
    "- 위의 그림에서는 <font color='green'>초록색 메모리 셀</font>에 해당된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fxK_1i5sLufk"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.6.4 양방향 RNN의 출력층\n",
    "\n",
    "- 그리고 이 두 개의 값 모두가 출력층에서 출력값을 예측하기 위해 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lR_c03MAL7ne"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.6.5 케라스에서의 양방향 RNN 사용\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences=True), input_shape=(timesteps, input_dim)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sm-fvYl_MACe"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.6.6 다수의 은닉층을 가진 양방향 RNN\n",
    "\n",
    "- 물론, 양방향 RNN도 다수의 은닉층을 가질 수 있다.\n",
    "- 아래의 그림은 양방향 순환 신경망에서 은닉층이 1개 더 추가되어 은닉층이 2개인 깊은(deep) 양방향 순환 신경망의 모습을 보여준다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/22886/rnn_image6_ver3.PNG)\n",
    "\n",
    "- 다른 인공 신경망 모델들도 마찬가지이지만, 은닉층을 무조건 추가한다고 해서 모델의 성능이 좋아지는 것은 아니다.\n",
    "- 은닉층을 추가하면, 학습할 수 있는 양이 많아지지만, 또한 반대로 훈련 데이터 또한 그만큼 많이 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4sM-kfDwMsZf"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 아래의 코드는 은닉층이 4개인 경우를 보여준다.\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences=True), input_shape=(timesteps, input_dim)))\n",
    "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences=True)))\n",
    "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences=True)))\n",
    "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences=True)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OSqpN8yqNDbt"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 양방향 RNN은 **태깅 작업 챕터**의 실습에서 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JNPm6ni8NHq7"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.7 RNN 관련 참고 포스트\n",
    "\n",
    "- [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "- [Recurrent Neural Networks (RNNs) for Language Modeling](https://gluon.mxnet.io/chapter05_recurrent-neural-networks/simple-rnn.html)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ch09_v01_Recurrent-Neural-Network-RNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
