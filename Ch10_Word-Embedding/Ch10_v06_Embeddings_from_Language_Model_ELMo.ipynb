{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9nFuVhN15Cs-"
   },
   "source": [
    "# Ch10. 워드 임베딩 (Word Embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ADs5Qml5MEC"
   },
   "source": [
    "# v06. 엘모 (Embeddings from Language Model, ELMo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7P2nP6Iw5QGK"
   },
   "source": [
    "$\\quad$ ![](https://wikidocs.net/images/page/33930/elmo_DSHQjZD.png)\n",
    "\n",
    "- [논문링크](https://aclweb.org/anthology/N18-1202)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JyYP8YV7xknF"
   },
   "source": [
    "- ELMo(Embeddings from Language Model)는 2018년에 제안된 새로운 워드 임베딩 방법론이다.\n",
    "- ELMo라는 이름은 \"세서미 스트리트\"라는 미국 인형극의 캐릭터 이름이기도 하다.\n",
    "- 뒤에서 배우게 되는 BERT나 최근 마이크로소프트가 사용한 Big Bird라는 NLP 모델 또한 ELMo에 이어 \"세서미 스트리트\"의 케릭터의 이름을 사용했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9WKlCoDx60o"
   },
   "source": [
    "- ELMo는 Embeddings from Language Model의 약자이다.\n",
    "- 해석하면 \"언어 모델로 하는 임베딩\"이다.\n",
    "- ELMo의 가장 큰 특징은 **사전 훈련된 언어 모델(Pre-trained language model)**을 사용한다는 점이다.\n",
    "- 이는 ELMo의 이름에 LM이 들어간 이유이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iSdySShQyOPl"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 6.1 ELMo (Embeddings from Language Model)\n",
    "\n",
    "- \"Bank\"라는 단어를 생각해보자.\n",
    "- \"Bank Account(은행 계좌)\"와 \"River Bank(강둑)\"에서의 \"Bank\"는 전혀 다른 의미를 가진다.\n",
    "- 하지만 Word2Vec이나 GloVe 등으로 표현된 임베딩 벡터들은 이를 제대로 반영하지 못한다는 단점이 있다.\n",
    "  - 예를 들어서 Word2Vec이나 GloVe 등의 임베딩 방법론으로 \"Bank\"란 단어를 `[0.2 0.8 -1.2]`라는 임베딩 벡터로 임베딩하였다고 하자.\n",
    "  - 이 단어는 \"Bank Account(은행 계좌)\"와 \"River Bank(강둑)\"에서의 \"Bank\"는 전혀 다른 의미임에도 불구하고 두 가지 상황 모두에서 `[0.2 0.8 -1.2]`의 벡터가 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ozNXmntHy5G3"
   },
   "source": [
    "- 그렇다면 같은 표기의 단어라도 문맥에 따라서 다르게 워드 임베딩을 할 수 있으면 자연어 처리의 성능이 더 올라가지 않을까?\n",
    "- 단어를 임베딩하기 전에 전체 문장을 고려해서 임베딩을 하겠다는 것이다.\n",
    "- 그래서 탄생한 것이 **문맥을 반영한 워드 임베딩(Contextualized Word Embedding)**이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tslzHfuEzJIc"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 6.2 biLM (Bidirectional Language Model)의 사전 훈련\n",
    "\n",
    "- 우선 다음 단어를 예측하는 작업인 언어 모델링을 상기해보자.\n",
    "- 아래의 그림은 은닉층이 2개인 일반적인 단방향 RNN 언어 모델의 언어 모델링을 보여준다.\n",
    "\n",
    "$\\qquad$ ![](https://wikidocs.net/images/page/33930/deepbilm.PNG)\n",
    "\n",
    "- RNN 언어 모델은 문장으로부터 단어 단위로 입력을 받는다.\n",
    "- RNN 내부의 은닉 상태 $h_t$는 시점(time-step)이 지날수록 점점 업데이트되어 간다.\n",
    "- 이는 결과적으로 $h_t$의 값이 문장의 문맥 정보를 점차적으로 반영한다고 말할 수 있다.\n",
    "- 지금 설명하는 내용은 새로운 개념이 아니라 RNN의 기본 개념이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RfpYdQ2Ez22o"
   },
   "source": [
    "- 그런데 ELMo는 위의 그림의 순방향 RNN 뿐만 아니라, 위의 그림과는 반대 방향으로 문장을 스캔하는 역방향 RNN 또한 활용한다.\n",
    "- ELMo는 양쪽 방향의 언어 모델을 둘 다 활용한다고하여 이 언어 모델을 **biLM(Bidirectional Language Model)**이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "COBNSq6e0BxF"
   },
   "source": [
    "- ELMo에서 말하는 biLM은 기본적으로 다층 구조(Multi-layer)를 전제로 한다.\n",
    "- 은닉층이 최소 2개 이상이라는 의미이다.\n",
    "- 아래의 그림은 은닉층이 2개인 순방향 언어 모델과 역방향 언어 모델의 모습을 보여준다.\n",
    "\n",
    "$\\qquad$ ![](https://wikidocs.net/images/page/33930/forwardbackwordlm2.PNG)\n",
    "\n",
    "- 이 때 biLM의 입력이 되는 워드 임베딩 방법으로는 이 책에서는 다루지 않은 char CNN이라는 방법을 사용한다.\n",
    "- 이 임베딩 방법은 글자(character) 단위로 계산되는 데, 이렇게 하면 마치 서브단어(subword)의 정보를 참고하는 것처럼 문맥과 상관없이 dog란 단어와 doggy란 단어의 연관성을 찾아낼 수 있다.\n",
    "- 또한 이 방법은 OOV에도 견고한다는 장점이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lRueu_VJ0hE3"
   },
   "source": [
    "- 주의할 점은 앞서 RNN 챕터에서 설명한 **양방향 RNN**과 ELMo에서의 **biLM**은 다소 다르다.  \n",
    "  \n",
    "\n",
    "- 양방향 RNN\n",
    "  - 순방향 RNN의 은닉 상태와 역방향의 RNN의 은닉 상태를 다음 층의 입력으로 보내기 전에 연결(concatenate)시킨다.  \n",
    "\n",
    "  \n",
    "- biLM\n",
    "  - 순방향 언어 모델과 역방향 언어 모델이 각각의 은닉 상태만을 다음 은닉층으로 보낸다.\n",
    "  - 훈련시킨 후에 ELMo 표현으로 사용하기 위해서 은닉 상태를 연결(concatenate)시키는 것과는 다르다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rQvdktFh1BhI"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 6.3 biLM의 활용\n",
    "\n",
    "- biLM이 훈련되었다면, 이제 ELMo가 사전 훈련된 biLM을 통해 입력 문장으로부터 단어를 임베딩하기 위한 과정을 살펴보자.\n",
    "\n",
    "$\\qquad$ ![](https://wikidocs.net/images/page/33930/playwordvector.PNG)\n",
    "\n",
    "- 이 예제에서는 play란 단어가 임베딩이 되고 있다는 가정 하에 ELMo를 설명한다.\n",
    "- play라는 단어를 임베딩 하기 위해서 ELMo는 위의 점선의 사각형 내부의 각 층의 결과값을 재료로 사용한다.\n",
    "- 다시 말해 해당 시점(time-step)의 biLM의 각 층의 출력값을 가져온다.\n",
    "- 그리고 순방향 언어 모델과 역방향 언어 모델의 각 층의 출력값을 연결(concatenate)하고 추가 작업을 진행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oj1KSvGD1MFX"
   },
   "source": [
    "- 여기서 **각 층의 출력값**이란 첫 번째 임베딩 층을 말한다.\n",
    "- 나머지 층은 각 층의 은닉 상태를 말한다.\n",
    "- ELMo의 직관적인 아이디어는 각 층의 출력값이 가진 정보는 전부 서로 다른 정류의 정보를 갖고 있을 것이므로, 이들을 모두 활용한다는 점에 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Lst9fXijS6i"
   },
   "source": [
    "- 아래는 ELMo가 임베딩 벡터를 얻는 과정을 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "49vNOeMt5HtD"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 6.3.1 각 층의 출력값을 연결(concatenate)한다.\n",
    "\n",
    "$\\qquad$ ![](https://wikidocs.net/images/page/33930/concatenate.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z1WFk-GN5SKq"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 6.3.2 각 층의 출력값 별로 가중치를 준다.\n",
    "\n",
    "$\\qquad$ ![](https://wikidocs.net/images/page/33930/weight.PNG)\n",
    "\n",
    "- 이 가중치를 여기서는 $s_1$, $s_2$, $s_3$ 라고 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m9INtZC75dRq"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 6.3.3 각 층의 출력값을 모두 더한다.\n",
    "\n",
    "$\\qquad$ ![](https://wikidocs.net/images/page/33930/weightedsum.PNG)\n",
    "\n",
    "- 6.3.2과 6.3.3의 단계를 오약하여 **가중합(Weighted Sum)**을 한다고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W5i-61fdFY5v"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 6.3.4 벡터의 크기르 결정하는 스칼라 매개변수를 곱한다.\n",
    "\n",
    "$\\qquad$ ![](https://wikidocs.net/images/page/33930/scalarparameter.PNG)\n",
    "\n",
    "- 이 스칼라 매개변수를 여기서는 $\\gamma$ 라고 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDhVVCfbFywd"
   },
   "source": [
    "- 이렇게 완성된 벡터를 ELMo 표현(representation)이라고 한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MLWnrhWbHUU-"
   },
   "source": [
    "- 지금까지는 ELMo 표현을 얻기 위한 과정이였다.\n",
    "- 이제 ELMo를 입력으로 사용하고 수행하고 싶은 텍스트 분류, 질의 응답 시스템 등의 자연어 처리 작업이 있을 것이다.\n",
    "- 예를 들어 텍스트 분류 작업을 하고 싶다고 가정하자.\n",
    "- 그렇다면 ELMo 표현을 어떻게 텍스트 분류 작업에 사용할 수 있을까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o7LLRPtcHXGj"
   },
   "source": [
    "- ELMo 표현은 기존의 임베딩 벡터와 함께 사용할 수 있다.\n",
    "- 우선 텍스트 분류 작업을 위해서 GloVe와 같은 기존의 방법론을 사용한 임베딩 벡터를 준비했다고 하자.\n",
    "- 이 때, GloVe를 사용한 임베딩 벡터만 텍스트 분류 작업에 사용하는 것이 아니라 이렇게 준비된 ELMo 표현을 GloVe 임베딩 벡터와 연결(concatenate)해서 입력으로 사용할 수 있다.\n",
    "- 그리고 이 때, ELMo 표현을 만드는 데 사용되는 사전 훈련된 언어 모델의 가중치는 고정시킨다.\n",
    "- 그리고 대신 위에서 사용한 $s_1$, $s_2$, $s_3$와 $\\gamma$는 훈련 과정에서 학습된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eSCMdTDqH09j"
   },
   "source": [
    "$\\qquad$ ![](https://wikidocs.net/images/page/33930/elmorepresentation.PNG)\n",
    "\n",
    "- 위의 그림은 ELMo 표현이 기존의 GloVe 등과 같은 임베딩 벡터와 함께 NLP 태스크의 입력이 되는 것을 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yc5YstZnH_ah"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 6.4 ELMo 표현을 사용해서 스팸 메일 분류하기\n",
    "\n",
    "- 텐서플로우 허브로부터 다양한 사전 훈련된 모델(Pre-trained Model)들을 사용할 수 있다.\n",
    "- 여기서는 사전 훈련된 모델로부터 ELMo 표현을 사용해보는 정도로 예제를 진행해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GTodKWcmMYMK"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 6.4.1 텐서플로우 허브 인스톨\n",
    "\n",
    "- 시작 전에 텐서플로우 허브를 인스톨해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "riI65yElMfBQ",
    "outputId": "632fd4b7-dbd9-43ea-e66b-d7e76083a0cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (3.10.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.18.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub) (46.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y5hPnGPIMgn3"
   },
   "source": [
    "- 설치가 끝났다면 이제 텐서플로우 허브를 임포트할 수 있다.\n",
    "- 이제 ELMo를 사용해서 스팸 메일 분류를 진행해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yt3B4AFeMop_"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 6.4.2 필요 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "TyvpVzgFNRJj",
    "outputId": "9927bd47-dc3d-42a3-e216-61b35ccb84a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.15.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%tensorflow_version 1.x\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aOX9MtjiMtCa"
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "sess = tf.Session()\n",
    "K.set_session(sess) # 세션 초기화 (텐서플로우 개념)\n",
    "\n",
    "# 텐서플로우 허브로부터 ELMo를 다운로드\n",
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/1\", trainable=True)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.tables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G0l1vPd3NKSx"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 6.4.3 데이터셋 불러오기\n",
    "\n",
    "- [파일 다운로드 링크](https://www.kaggle.com/uciml/sms-spam-collection-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "DiXcSHnoN2fN",
    "outputId": "83b5a145-2361-40b5-8b15-9b6d2bf93181"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1  ... Unnamed: 4\n",
       "0   ham  ...        NaN\n",
       "1   ham  ...        NaN\n",
       "2  spam  ...        NaN\n",
       "3   ham  ...        NaN\n",
       "4   ham  ...        NaN\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"spam.csv\", encoding='latin-1')\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ccuSbfuPOuLj"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 6.4.4 데이터 분리\n",
    "\n",
    "- 여기서 필요한 건 `v1`열과 `v2`열이다.\n",
    "- `v1`열은 숫자 레이블로 바꿔야 할 필요가 있다.\n",
    "- 이를 각각 `X_data`와 `y_data`로 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "68rfUm_QO8iy"
   },
   "outputs": [],
   "source": [
    "data['v1'] = data['v1'].replace(['ham', 'spam'], [0, 1])\n",
    "y_data = list(data['v1'])\n",
    "X_data = list(data['v2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "h2Qwhk4OPHC5",
    "outputId": "f9396bfa-a3ae-4441-a9ad-fb769e1cd2b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
       " 'Ok lar... Joking wif u oni...',\n",
       " \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
       " 'U dun say so early hor... U c already then say...',\n",
       " \"Nah I don't think he goes to usf, he lives around here though\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "S_wEmYtrPIIh",
    "outputId": "1a839742-1121-42fd-9b91-cebcddd7e094"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "32bB26VIPKEZ"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 6.4.5 데이터 분할\n",
    "\n",
    "- 훈련 데이터와 테스트 데이터를 8:2 비율로 분할한다.\n",
    "- 그런데 그 전에 이를 위해 전체 데이터 개수의 80%와 20%는 각각 몇 개인 지 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "44TbbUkePVNh",
    "outputId": "8ccfb57b-d0f5-4f54-a425-c1dd5dd7265e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5572\n"
     ]
    }
   ],
   "source": [
    "print(len(X_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "VoeAPT5GPpIR",
    "outputId": "ddb5f9c8-1028-4891-9016-4a060916c09a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4457\n",
      "1115\n"
     ]
    }
   ],
   "source": [
    "n_of_train = int(len(X_data) * 0.8)\n",
    "n_of_test = int(len(X_data) - n_of_train)\n",
    "print(n_of_train)\n",
    "print(n_of_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hm-Vuyk0PxrS"
   },
   "source": [
    "- 전체 데이터는 5,572개이며 8:2 비율로 분리하면 4,457과 1,115가 된다.\n",
    "- 이를 각각 훈련 데이터와 테스트 데이터의 양으로 하여 데이터를 분할한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5d9i7BRKP8Fw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.asarray(X_data[:n_of_train]) #X_data 데이터 중에서 앞의 4457개의 데이터만 저장\n",
    "y_train = np.asarray(y_data[:n_of_train]) #y_data 데이터 중에서 앞의 4457개의 데이터만 저장\n",
    "X_test = np.asarray(X_data[n_of_train:]) #X_data 데이터 중에서 뒤의 1115개의 데이터만 저장\n",
    "y_test = np.asarray(y_data[n_of_train:]) #y_data 데이터 중에서 뒤의 1115개의 데이터만 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mzO6fP7qP_DY"
   },
   "source": [
    "- 이제 훈련을 위한 데이터 준비는 끝났다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1pK8GVzEQC4o"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 6.4.6 ELMo와 설계한 모델 연결\n",
    "\n",
    "- 이제 ELMo와 설계한 모델을 연결하는 작업을 진행해보자.\n",
    "- ELMo는 텐서플로우 허브로부터 가져온 것이기 때문에 케라스에서 사용하기 위해서는 케라스에서 사용할 수 있도록 변환해주는 작업들이 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eVxtZeUTQQRH"
   },
   "outputs": [],
   "source": [
    "# 데이터의 이동이 케라스 -> 텐서플로우 -> 케라스가 되도록 하는 함수\n",
    "def ELMoEmbedding(x):\n",
    "    return elmo(tf.squeeze(tf.cast(x, tf.string)),\n",
    "                as_dict=True,\n",
    "                signature='default')['default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4IqJMMNFQeni"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 이제 모델을 설계한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QNkT2CknQmwu"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Lambda, Input\n",
    "\n",
    "input_text = Input(shape=(1,), dtype=tf.string)\n",
    "embedding_layer = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
    "hidden_layer = Dense(256, activation='relu')(embedding_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(hidden_layer)\n",
    "model = Model(inputs=[input_text], outputs=output_layer)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CBvignUjRJfA"
   },
   "source": [
    "- 모델은 ELMo를 이용한 임베딩 층을 거쳐서 256개의 뉴런이 있는 은닉층을 거친 후 마지막 1개의 뉴런을 통해 이진 분류를 수행한다.\n",
    "- 이진 분류를 위한 마지막 뉴런의 활성화 함수는 시그모이드 함수이다.\n",
    "- 모델의 손실 함수는 `binary_crossentropy` 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KlELGa1NRZsV"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 6.4.7 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mxj69avHRfM3"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1, batch_size=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GM-cPYTxWNmB"
   },
   "source": [
    "```\n",
    "Epoch 1/1\n",
    "4457/4457 [==============================] - 1137s 255ms/step - loss: 0.1076 - acc: 0.9545\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rRaDL-V8Ri3e"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 6.4.8 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "pVydZlaTVod_",
    "outputId": "089a6a18-03d2-47b1-9f1b-4894a07cbe3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115/1115 [==============================] - 307s 275ms/step\n",
      "\n",
      "[ 테스트 정확도 : 0.9776\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[ 테스트 정확도 : %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i-xM7z4_VxBf"
   },
   "source": [
    "- 1번의 에포크에서 98%의 정확도를 얻어낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fm2UkaKKVzzU"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 6.5 참고 자료\n",
    "\n",
    "- [http://www.realworldnlpbook.com/blog/improving-sentiment-analyzer-using-elmo.html](http://www.realworldnlpbook.com/blog/improving-sentiment-analyzer-using-elmo.html) (ENG)\n",
    "- [https://createmomo.github.io/2018/01/23/Super-Machine-Learning-Revision-Notes/](https://createmomo.github.io/2018/01/23/Super-Machine-Learning-Revision-Notes/) (ENG)\n",
    "- [https://www.analyticsvidhya.com/blog/2019/03/learn-to-use-elmo-to-extract-features-from-text/](https://www.analyticsvidhya.com/blog/2019/03/learn-to-use-elmo-to-extract-features-from-text/) (ENG)\n",
    "- [http://www.davidsbatista.net/blog/2018/12/06/Word_Embeddings/](http://www.davidsbatista.net/blog/2018/12/06/Word_Embeddings/) (ENG)\n",
    "- [https://lilianweng.github.io/lil-log/2019/01/31/generalized-language-models.html#bidirectional-language-model](https://lilianweng.github.io/lil-log/2019/01/31/generalized-language-models.html#bidirectional-language-model) (ENG)\n",
    "- [https://medium.com/saarthi-ai/elmo-for-contextual-word-embedding-for-text-classification-24c9693b0045](https://medium.com/saarthi-ai/elmo-for-contextual-word-embedding-for-text-classification-24c9693b0045) (ENG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QvMQQq4VWH5T"
   },
   "source": [
    "<br>\n",
    "\n",
    "char CNN 참고 자료\n",
    "\n",
    "- [https://www.slideshare.net/JaeminCho6/dl-chatbot-seminar-day-02](https://www.slideshare.net/JaeminCho6/dl-chatbot-seminar-day-02) (ENG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ksjjep31WeVz"
   },
   "source": [
    "<br>\n",
    "\n",
    "한국어에 대한 ELMo\n",
    "\n",
    "- [https://github.com/HIT-SCIR/ELMoForManyLangs](https://github.com/HIT-SCIR/ELMoForManyLangs) (ENG)\n",
    "- [https://ratsgo.github.io/embedding/](https://ratsgo.github.io/embedding/) (KOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2VuTjgIxWj6x"
   },
   "source": [
    "<br>\n",
    "\n",
    "ELMo로 단어 몇 개만 임베딩 벡터 얻어보기\n",
    "\n",
    "- [https://medium.com/@joeyism/embedding-with-tensorflow-hub-in-a-simple-way-using-elmo-d1bfe0ada45c](https://medium.com/@joeyism/embedding-with-tensorflow-hub-in-a-simple-way-using-elmo-d1bfe0ada45c) (ENG)\n",
    "- [https://github.com/strongio/keras-elmo/blob/master/Elmo%20Keras.ipynb](https://github.com/strongio/keras-elmo/blob/master/Elmo%20Keras.ipynb) (ENG)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ch10_v06_Embeddings-from-Language-Model-ELMo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
