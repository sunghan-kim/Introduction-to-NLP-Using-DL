{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RkBcDzpC2B66"
   },
   "source": [
    "# Ch11. 텍스트 분류 (Text Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TQS5txts2C9D"
   },
   "source": [
    "# v05. 나이브 베이즈 분류기 (Naive Bayes Classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vuXOFuY3RwRZ"
   },
   "source": [
    "- 텍스트 분류를 위해 정통적으로 사용되는 분류기로 나이브 베이즈 분류기가 있다.\n",
    "- 나이브 베이즈 분류기는 인공 신경망 알고리즘에는 속하지 않지만, 머신 러닝의 주요 알고리즘으로 분류되어 있어 준수한 성능을 보여주는 것으로 알려져 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z7fL9DaLTHWe"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 5.1 베이즈의 정리(Bayes' theorem)를 이용한 분류 메커니즘\n",
    "\n",
    "- 나이브 베이즈 분류기를 이해하기 위해서는 우선 **베이즈의 정리(Bayes' theorem)**를 이해할 필요가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qikLNe9-TSPe"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 5.1.1 베이즈의 정리 (Bayes' theorem)\n",
    "\n",
    "- 베이즈 정리는 조건부 확률을 계산하는 방법 중 하나이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ivOAqCGJTdkV"
   },
   "source": [
    "- $P(A)$ : A가 일어날 확률\n",
    "- $P(B)$ : B가 일어날 확률\n",
    "- $P(B|A)$ : A가 일어나고 나서 B가 일어날 확률\n",
    "- $P(A|B)$ : B가 일어나고 나서 A가 일어날 확률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BVRAwheaTtrg"
   },
   "source": [
    "- 이 때 $P(B|A)$를 쉽게 구할 수 있는 상황이라면, 아래와 같은 식을 통해 $P(A|B)$를 구할 수 있다.\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "P(A|B) = \\frac{P(B|A) \\, P(A)}{P(B)}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VXZufoyvT6ec"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 5.1.2 베이즈 정리를 이용한 텍스트 분류\n",
    "\n",
    "- 나이브 베이즈 분류기는 이러한 베이즈 정리를 이용하여 텍스트 분류를 수행한다.\n",
    "- 예를 들어서 나이브 베이즈 분류기를 통해서 스팸 메일 필터를 만들어본다고 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tk7ALGQgZufP"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.1.2.1 구해야 하는 확률\n",
    "\n",
    "- 입력 텍스트(메일의 본문)이 주어졌을 때, 입력 텍스트가 정상 메일인 지, 스팸 메일인 지 구분하기 위한 확률을 아래와 같이 표현할 수 있다.\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "P(\\text{정상 메일} | \\text{입력 텍스트}) = \\text{입력 텍스트가 있을 때 정상 메일일 확률}\n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "P(\\text{스팸 메일} | \\text{입력 텍스트}) = \\text{입력 텍스트가 있을 때 스팸 메일일 확률}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e7IhI7KzUc-4"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.1.2.2 베이즈 정리를 이용하여 표현\n",
    "\n",
    "- 이를 베이즈 정리에 따라서 식을 표현하면 아래와 같다.\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "P(\\text{정상 메일} | \\text{입력 텍스트}) =\n",
    "\\left\\{ P(\\text{입력 텍스트} | \\text{정상 메일}) \\times P(\\text{정상 메일}) \\right\\} \\, / \\, P(\\text{입력 텍스트})\n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "P(\\text{스팸 메일} | \\text{입력 텍스트}) =\n",
    "\\left\\{ P(\\text{입력 텍스트} | \\text{스팸 메일}) \\times P(\\text{스팸 메일}) \\right\\} \\, / \\, P(\\text{입력 텍스트})\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zFFjA_q_VO6I"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.1.2.3 정상 메일과 스팸 메일 분류 기준\n",
    "\n",
    "- 입력 텍스트가 주어졌을 때\n",
    "  - $P(\\text{정상 메일} | \\text{입력 텍스트}) \\; > \\; P(\\text{스팸 메일} | \\text{입력 텍스트}) \\; \\Rightarrow \\;$ 정상 메일\n",
    "  - $P(\\text{정상 메일} | \\text{입력 텍스트}) \\; < \\; P(\\text{스팸 메일} | \\text{입력 텍스트}) \\; \\Rightarrow \\;$ 스팸 메일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h256do92XwCt"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 그런데 두 확률 모두 식을 보면 $P(\\text{입력 텍스트})$를 분모로 하고 있다.\n",
    "- 그렇기 때문에 분모를 양쪽에서 제거하고 다음과 같이 식을 간소화할 수 있다.\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "P(\\text{정상 메일} | \\text{입력 텍스트}) =\n",
    "P(\\text{입력 텍스트} | \\text{정상 메일}) \\times P(\\text{정상 메일})\n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "P(\\text{스팸 메일} | \\text{입력 텍스트}) =\n",
    "P(\\text{입력 텍스트} | \\text{스팸 메일}) \\times P(\\text{스팸 메일})\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UOIvvbo0YlIk"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.1.2.4 메일의 본문을 분류기 입력으로 사용\n",
    "\n",
    "- 입력 텍스트는 메일의 본문을 의미한다.\n",
    "- 그런데 메일의 본문을 어떻게 나이브 베이즈 분류기의 입력으로 사용할 수 있을까?\n",
    "- 메일의 본문에 있는 모든 단어를 토큰화 시켜서 이 단어들을 나이브 베이즈 분류기의 입력으로 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_KCcm22bY6Rb"
   },
   "source": [
    "- 만약 메일의 본문에 있는 단어가 3개라고 가정해보자.\n",
    "- 기본적으로 나이브 베이즈 분류기는 **모든 단어가 독립적이라고 가정**한다.\n",
    "- 메일의 본문에 있는 단어 3개를 $w_1$, $w_2$, $w_3$라고 표현하자.\n",
    "- 그러면 결국 나이브 베이즈 분류기의 정상 메일일 확률과 스팸 메일일 확률을 구하는 식은 아래와 같다.\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "P(\\text{정상 메일} | \\text{입력 텍스트}) =\n",
    "P(w_1 | \\text{정상 메일}) \\times \n",
    "P(w_2 | \\text{정상 메일}) \\times\n",
    "P(w_3 | \\text{정상 메일}) \\times\n",
    "P(\\text{정상 메일})\n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "P(\\text{스팸 메일} | \\text{입력 텍스트}) =\n",
    "P(w_1 | \\text{스팸 메일}) \\times \n",
    "P(w_2 | \\text{스팸 메일}) \\times\n",
    "P(w_3 | \\text{스팸 메일}) \\times\n",
    "P(\\text{스팸 메일})\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BTFqk7w5ZiIs"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.1.2.5 나이브 베이즈 분류기의 단어 순서\n",
    "\n",
    "- 나이브 베이즈 분류기에서 토큰화 이전의 단어의 순서는 중요하지 않다.\n",
    "- 즉, BoW와 같이 단어의 순서를 무시하고 오직 빈도수만을 고려한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TFcIl4JYZq66"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 5.2 스팸 메일 분류기 (Spam Detection)\n",
    "\n",
    "- 앞서 배운 나이브 베이즈 분류식을 가지고, 입력 텍스트로부터 해당 텍스트가 정상 메일인지 스팸 메일인지를 구분하는 작업을 해보도록 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "28X_RNkedmh8"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 5.2.1 훈련 데이터\n",
    "\n",
    "- 아래와 같은 훈련 데이터가 있다고 가정하자.\n",
    "\n",
    "| -    | 메일로부터 토큰화 및 정제 된 단어들 | 분류      |\n",
    "| :--- | :---------------------------------- | :-------- |\n",
    "| 1    | me free lottery                     | 스팸 메일 |\n",
    "| 2    | free get free you                   | 스팸 메일 |\n",
    "| 3    | you free scholarship                | 정상 메일 |\n",
    "| 4    | free to contact me                  | 정상 메일 |\n",
    "| 5    | you won award                       | 정상 메일 |\n",
    "| 6    | you ticket lottery                  | 스팸 메일 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EmGZ_8qYvrji"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 5.2.2 정상 메일 or 스팸 메일일 확률\n",
    "\n",
    "- \"you free lottery\"라는 입력 텍스트에 대해서 정상 메일일 확률과 스팸 메일일 확률을 각각 구해보자.\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "P(\\text{정상 메일} | \\text{입력 텍스트}) =\n",
    "P(\\text{you} | \\text{정상 메일}) \\times \n",
    "P(\\text{free} | \\text{정상 메일}) \\times\n",
    "P(\\text{lottery} | \\text{정상 메일}) \\times\n",
    "P(\\text{정상 메일})\n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "P(\\text{스팸 메일} | \\text{입력 텍스트}) =\n",
    "P(\\text{you} | \\text{스팸 메일}) \\times \n",
    "P(\\text{free} | \\text{스팸 메일}) \\times\n",
    "P(\\text{lottery} | \\text{스팸 메일}) \\times\n",
    "P(\\text{스팸 메일})\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X165va2Cv3AJ"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 5.2.3 공통 부분\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "P(\\text{정상 메일}) = P(\\text{스팸 메일}) = \\text{총 메일 6개 중 3개} = 0.5\n",
    "$\n",
    "\n",
    "- 위 예제에서는 $P(\\text{정상 메일})$과 $P(\\text{스팸 메일})$의 값은 같은 값이다.\n",
    "- 그러므로 두 식에서 두 개의 확률은 생략 가능하다.\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "P(\\text{정상 메일} | \\text{입력 텍스트}) =\n",
    "P(\\text{you} | \\text{정상 메일}) \\times \n",
    "P(\\text{free} | \\text{정상 메일}) \\times\n",
    "P(\\text{lottery} | \\text{정상 메일})\n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "P(\\text{스팸 메일} | \\text{입력 텍스트}) =\n",
    "P(\\text{you} | \\text{스팸 메일}) \\times \n",
    "P(\\text{free} | \\text{스팸 메일}) \\times\n",
    "P(\\text{lottery} | \\text{스팸 메일})\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S_jl2cT8yw7D"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 5.2.4 각 단어의 메일 분류별 등장 빈도수\n",
    "\n",
    "|    단어     | 정상 메일 빈도수 | 스팸 메일 빈도수 |\n",
    "| :---------: | :--------------: | :--------------: |\n",
    "|     me      |        1         |        1         |\n",
    "|    free     |        2         |        3         |\n",
    "|   lottery   |        0         |        2         |\n",
    "|     get     |        0         |        1         |\n",
    "|     you     |        2         |        2         |\n",
    "| scholarship |        1         |        0         |\n",
    "|     to      |        1         |        0         |\n",
    "|   contact   |        1         |        0         |\n",
    "|     won     |        1         |        0         |\n",
    "|    award    |        1         |        0         |\n",
    "|   ticket    |        0         |        1         |\n",
    "|  빈도수 합  |        10        |        10        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oTbkY5Tbwq9q"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 5.2.5 각 단어의 조건부 확률\n",
    "\n",
    "- $P(\\text{you} | \\text{정상 메일})$을 구하는 방법\n",
    "  - 분모 : 정상 메일에 등장한 모든 단어의 빈도 수의 총합\n",
    "  - 분자 : 정상 메일에서 you가 총 등장한 빈도 수\n",
    "  - 이 경우에는 2/10 = 0.2가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GG0XIsqdxai_"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 5.2.6 확률식 전개\n",
    "\n",
    "- 위와 같은 원리로 식을 전개하면 다음과 같다.\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "P(\\text{정상 메일} | \\text{입력 텍스트}) = 2/10 \\times 2/10 \\times 0/10 = 0\n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "P(\\text{스팸 메일} | \\text{입력 텍스트}) = 2/10 \\times 3/10 \\times 2/10 = 0.012\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YKrHavy1zv80"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 5.2.7 결과\n",
    "\n",
    "- 결과적으로 $P(\\text{정상 메일} | \\text{입력 텍스트}) < P(\\text{스팸 메일} | \\text{입력 텍스트})$이므로 입력 테스트 \"you free lottery\"는 스팸 메일로 분류된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "myKsjDhaz6oa"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 5.2.8 지나친 일반화를 막기 위한 방법\n",
    "\n",
    "- 그런데 예제를 보니 이상한 점이 보인다.\n",
    "- 물론, 직관적으로 보기에도 you, free, lottery라는 단어가 스팸 메일에서 빈도수가 더 높기때문에 스팸 메일인 확률이 더 높은 것은 확실하다.\n",
    "- 그러나 입력 텍스트에 대해서 단 하나의 단어라도 훈련 텍스트에 없었다면 확률 전체가 0이 되는 것은 지나친 일반화이다.\n",
    "- 이 경우에는 정상 메일에 lottery가 단 한 번도 등장하지 않았고, 그 이유로 정상 메일일 확률 자체가 0%가 되어버렸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tZVRbRzy0Jki"
   },
   "source": [
    "- 이를 방지하기 위해서 나이브 베이즈 분류기에서는 각 단어에 대한 확률의 분모, 분자에 전부 숫자를 더해서 분자가 0이 되는 것을 방지하는 **라플라스 스무딩**을 사용하기도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HEv6xr7m0RRC"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 5.3 뉴스 데이터 분류하기(Classification of 20 News Group with Naive Bayes Classifier)\n",
    "\n",
    "- 사이킷런에서는 Twenty Newsgroups이라고 불리는 20개의 다른 주제를 가진 18,846개의 뉴스 데이터를 제공한다.  (토픽 모델링의 LSA 챕터에서 사용했던 데이터와 동일한 데이터)\n",
    "- 해당 데이터는 이미 훈련 데이터(뉴스 11,314개)와 테스트 데이터(뉴스 7,532개)를 미리 분류해놓았기 때문에 별도로 훈련 데이터와 테스트 데이터를 분류할 필요는 없다.\n",
    "- 훈련 데이터로 훈련을 해서 모델을 만들고, 테스트 데이터를 예측했을 때의 정확도를 확인해보도록 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z2eBTypo0YuJ"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 5.3.1 뉴스 데이터에 대한 이해\n",
    "\n",
    "- 해당 데이터는 총 5개의 속성을 갖고 있다.\n",
    "- 그 중에서 우리가 사용할 것은 다음과 같다.\n",
    "  - 해당 데이터의 본문을 갖고 있는 `data` 속성\n",
    "  - 해당 데이터가 어떤 카테고리에 속하는 지 0부터 19까지의 라벨이 붙어 있는 `target` 속성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DvvEzcGG-p7n"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.3.1.1 훈련 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "DIYSVY6R-vWJ",
    "outputId": "21c0abcd-0dc2-4a8d-af68-6c9a85cef349"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsdata = fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Okz_jCmH-362"
   },
   "source": [
    "- `subset` 속성 값 종류\n",
    "  - `all` : 모든 데이터인 뉴스 18,846개를 다운로드\n",
    "  - `train` : 훈련 데이터 다운로드\n",
    "  - `test` : 테스트 데이터 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9-C7Q4rt_gzh"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.3.1.2 데이터의 속성 구성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "drXSd6_I_aZF",
    "outputId": "0679b52e-14f3-4c68-9d88-7e6bac537ea9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "print(newsdata.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QrUlz_ET_kol"
   },
   "source": [
    "- 해당 데이터는 `data`, `filenames`, `target_names`, `target`, `DESCR` 이라는 5개 속성의 데이터를 갖고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cpSKtVuox2uA"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.3.1.3 훈련용 뉴스의 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qLXcIBPsx6Mj",
    "outputId": "472e2e6a-302c-40a0-e9ef-8eabe348ec31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 11314 20 11314\n"
     ]
    }
   ],
   "source": [
    "print(len(newsdata.data),\n",
    "      len(newsdata.filenames),\n",
    "      len(newsdata.target_names),\n",
    "      len(newsdata.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9N7Tq4mTyB6D"
   },
   "source": [
    "- 훈련용 뉴스는 총 11,314개로 구성되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BCN-LODVyKHq"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.3.1.4 `newsdata.target_names`\n",
    "\n",
    "- `newsdata.target_names`는 이 뉴스 데이터의 20개의 카테고리의 이름을 담고 있다.\n",
    "- 어떤 카테고리들로 구성되어 있는 지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "sGRIA8JSyQrY",
    "outputId": "448de75b-6bbb-4391-bb04-5c6b33479b88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(newsdata.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G6GkWpcHyTZJ"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.3.1.5 `newsdata.target`\n",
    "\n",
    "- `target`에는 총 0부터 19까지의 숫자가 들어가 있다.\n",
    "- 첫 번째 훈련용 뉴스의 경우에는 몇 번 카테고리인 지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_BCKMmCLyk_j",
    "outputId": "b2d3527d-86b6-41a2-ecef-3d1974d0214b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(newsdata.target[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_MbuBGlynhT"
   },
   "source": [
    "- 첫 번째 훈련용 뉴스는 카테고리 7번에 속한다고 라벨이 붙어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "sEVI1L1Qyta6",
    "outputId": "cc1454aa-bc06-447f-a63b-ef158a7cdb87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.autos\n"
     ]
    }
   ],
   "source": [
    "print(newsdata.target_names[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OpkxJ0bqyvX5"
   },
   "source": [
    "- 7번 카테고리의 제목은 `rec.autos`이다.\n",
    "- 즉, 첫 번째 훈련용 뉴스는 `rec.autos` 카테고리에 속한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j4u0Bkugy4A7"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.3.1.6 `newsdata.data`\n",
    "\n",
    "- 첫 번째 훈련용 뉴스가 어떤 내용을 갖고 있는 지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "colab_type": "code",
    "id": "7Jq9VP3Ky-3A",
    "outputId": "209ffad5-0cba-41cc-bf35-d32990f07e99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsdata.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FGFth86mzBZZ"
   },
   "source": [
    "- 메일의 내용을 보니 스포차 카에 대한 글로 보인다.\n",
    "- 즉, 이 스포츠 카에 대한 글은 총 0부터 19까지의 카테고리 중 7번 레이블에 속하는 글이고, 7번은 rec.autos 카테고리를 의미하는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qr7yrY_ozM-e"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 5.3.2 나이브 베이즈 분류\n",
    "\n",
    "- 이제 다운로드 받은 훈련 데이터에 대한 전처리를 진행해보자.\n",
    "- 사용할 데이터는 `newsdata.data`와 그에 대한 카테고리 레이블이 되어 있는 `newsdata.target`이다.\n",
    "- 여기서 전처리를 해야 하는 데이터는 `newsdata.data`이다.\n",
    "- 해당 데이터는 토큰화가 전혀 되어 있지 않다.\n",
    "- 나이브 베이즈 분류를 위해서는 데이터를 BoW로 만들어 줄 필요가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XQUi-ZKgziyj"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.3.2.1 DTM 생성\n",
    "\n",
    "- 여기서는 입력한 텍스트를 자동으로 BoW로 만드는 `CountVectorizer`를 사용한다. (BoW 챕터 및 DTM 챕터 참고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YnxWMIKGz17D"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB # 다항분포 나이브 베이즈 모델\n",
    "from sklearn.metrics import accuracy_score # 정확도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ZfqJpEPB0Ekt",
    "outputId": "ec83889a-01ef-4834-9c5d-92215f1f658f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 130107)\n"
     ]
    }
   ],
   "source": [
    "dtmvector = CountVectorizer()\n",
    "\n",
    "X_train_dtm = dtmvector.fit_transform(newsdata.data)\n",
    "print(X_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u_L4HN7D0Ma9"
   },
   "source": [
    "- 자동으로 DTM이 완성되었다.\n",
    "- 11,314는 훈련용 뉴스의 개수이고 DTM 관점에서는 문서의 수가 된다.\n",
    "- 130,107은 전체 훈련 데이터에 등장한 단어의 수를 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cnffb5ly0feL"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.3.2.2 TF-IDF 행렬 생성\n",
    "\n",
    "- 물론, DTM을 그대로 나이브 베이즈 분류기에 사용할 수도 있겠지만 DTM 행렬 대신 IF-IDF 가중치를 적용한 TF-IDF 행렬을 입력으로 텍스트 분류를 수행하면 성능의 개선을 얻을 수도 있다. (DTM 챕터 참고)\n",
    "- 주의할 점은 TF-IDF 행렬이 항상 DTM으로 수행했을 때 보다 성능이 뛰어나지는 않다.\n",
    "- 사이킷런은 TF-IDF를 자동 계산해주는 `TfidfVectorizer` 클래스를 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "swg2YjKg06Ga",
    "outputId": "1fd270ac-883c-46e4-c565-cbe1809d93ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 130107)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "tfidfv = tfidf_transformer.fit_transform(X_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8LBOQjgp1MOU"
   },
   "source": [
    "- 이제 TF-IDF 행렬이 만들어졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R3VgwcW51T0Y"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.3.2.3 나이브 베이즈 분류 수행\n",
    "\n",
    "- 사이킷런은 나이브 베이즈 모델을 지원한다.\n",
    "- 모델의 입력으로 TF-IDF 행렬과 11,314개의 훈련 데이터에 대한 레이블이 적혀 있는 `newsdata.target`이 들어간다.\n",
    "- 이는 앞서 배운 분류 예제들을 상기해보면, 각각 `X_train`과 `y_train`에 해당되는 데이터들이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yGpPtG_S1YyP",
    "outputId": "7ebfbc9a-5753-4385-f4b9-64a7da60973a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = MultinomialNB()\n",
    "mod.fit(tfidfv, newsdata.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "O6JdGMEc1wQC",
    "outputId": "0b72a523-5957-4895-c650-2d609c0d748d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aqlUK2Zx120R"
   },
   "source": [
    "- 여기서 `alpha=1.0`은 라플라스 스무딩이 적용되었음을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fasTjaAG2ACb"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 5.3.2.4 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "43Ul0Rd417J8"
   },
   "outputs": [],
   "source": [
    "# 테스트 데이터 가져오기\n",
    "newsdata_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "\n",
    "# 테스트 데이터를 DTM으로 변환\n",
    "X_test_dtm = dtmvector.transform(newsdata_test.data)\n",
    "\n",
    "# DTM을 TF-IDF 행렬로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "091lANuE2UZr",
    "outputId": "8401b443-7be0-4f47-da78-09baaa9c2455"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 :  0.7738980350504514\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터에 대한 예측\n",
    "predicted = mod.predict(tfidfv_test)\n",
    "\n",
    "# 예측값과 실제값 비교\n",
    "print(\"정확도 : \", accuracy_score(newsdata_test.target, predicted))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ch11_v05_Naive-Bayes-Classifier.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
