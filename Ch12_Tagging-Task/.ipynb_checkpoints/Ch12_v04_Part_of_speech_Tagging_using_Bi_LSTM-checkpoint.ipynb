{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KRYXNX-Cjm0c"
   },
   "source": [
    "# Ch12. 태깅 작업 (Tagging Task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TUbpbn77ju2H"
   },
   "source": [
    "# v04. 양방향 LSTM을 이용한 품사 태깅 (part-of-speech Tagging using Bi-LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i9dD6nT6qDaE"
   },
   "source": [
    "- 품사 태깅에 대해서는 이미 2챕터의 토큰화 챕터에서 배운 바 있다.\n",
    "- 그 당시에는 NLTK와 KoNLPy를 이용해서 이미 기존에 있는 모델로 품사 태깅을 수행했다.\n",
    "- 여기서는 직접 양방향 LSTM을 이용한 품사 태깅을 수행하는 모델을 만들어본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bHEmZ4yTqQKZ"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 4.1 품사 태깅 데이터에 대한 이해와 전처리\n",
    "\n",
    "- 이번에는 양방향 LSTM을 이용해서 품사 태깅을 하는 모델을 만들어보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3L_TRvQYqS_d"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 4.1.1 필요 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ypmGkmFFqbtH"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NjJwOR3uqtoI"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 4.1.2 토큰화와 품사 태깅 전처리가 수행된 문장 데이터\n",
    "\n",
    "- NLTK를 이용하면 영어 코퍼스에 토큰화와 품사 태깅 전처리를 진행한 문장 데이터를 받아올 수 있다.\n",
    "- 여기서는 해당 데이터를 훈련시켜 품사 태깅을 수행하는 모델을 만들어볼 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jmPacs17rAK3"
   },
   "source": [
    "- 우선 전체 문장 샘플의 개수를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "SlSS1kYhrd-U",
    "outputId": "6cd3611a-2669-460b-df1b-ead673d307b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/treebank.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "uREvs-QurCUn",
    "outputId": "e92d918a-258b-4ba3-f3f3-435f7cbbe510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "품사 태깅이 된 문장 개수 :  3914\n"
     ]
    }
   ],
   "source": [
    "# 토큰화에 품사 태깅이 된 데이터 받아오기\n",
    "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
    "\n",
    "# 문장 샘플의 개수 출력\n",
    "print(\"품사 태깅이 된 문장 개수 : \", len(tagged_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yRWQQ1PxrcFS"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 이 중 첫 번째 샘플만 출력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "1TWfqdRerloO",
    "outputId": "5745cbad-ae30-486e-ee46-01904a53728a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(tagged_sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sr4kdj8Jrm4-"
   },
   "source": [
    "- 품사 태깅 전처리가 수행된 첫 번째 문장이 출력된 것을 볼 수 있다.\n",
    "- 이러한 문장 샘플이 총 3,914개가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ozDqYa0fruZu"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 4.1.3 단어와 품사 태깅 정보 분리\n",
    "\n",
    "- 훈련을 시키려면 훈련 데이터에서 단어에 해당되는 부분과 품사 태깅 정보에 해당되는 부분을 분리시켜야 한다.\n",
    "- 즉, `[('Pierre', 'NNP'), ('Vinken', 'NNP')]`와 같은 문장 샘플이 있다면 `Pierre`과 `Vinken`을 같이 저장하고, `NNP`와 `NNP`를 같이 저장할 필요가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YfV3pV9vr_jl"
   },
   "source": [
    "- 이런 경우 파이썬 함수 중에서 `zip()` 함수가 유용한 역할을 한다.\n",
    "- `zip()` 함수는 동일한 개수를 가지는 시퀀스 자료형에서 각 순서에 등장하는 원소들끼리 묶어주는 역할을 한다.  \n",
    "(2챕터의 데이터의 분리 챕터 참고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fTRWFgBUshwk"
   },
   "outputs": [],
   "source": [
    "sentences, pos_tags = [], []\n",
    "\n",
    "for tagged_sentence in tagged_sentences: # 3,914개의 문장 샘플을 1개씩 불러온다.\n",
    "\n",
    "    # 각 샘플에서 단어들은 sentence에 품사 태깅 정보들은 tag_info에 저장한다.\n",
    "    sentence, tag_info = zip(*tagged_sentence)\n",
    "\n",
    "    # 각 샘플에서 단어 정보만 저장\n",
    "    sentences.append(list(sentence))\n",
    "\n",
    "    # 각 샘플에서 품사 태깅 정보만 저장\n",
    "    pos_tags.append(list(tag_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xHpc_ribtKyQ"
   },
   "source": [
    "- 각 문장에 샘플에 대해서는 단어는 `sentences`에 저장되고 태깅 정보는 `pos_tags`에 저장했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKQSTihFtYlq"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 임의로 첫 번째 문장 샘플을 출력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "itlPj2MQtbry",
    "outputId": "c2d7b9b4-88ba-41a6-8333-5f18d69bb45f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n",
      "['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])\n",
    "print(pos_tags[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "213bs3txthrD"
   },
   "source": [
    "- 첫 번째 샘플에 대해서 단어에 대해서만 `sentences[0]`에, 또한 품사에 대해서만 `pos_tags[0]`에 저장된 것을 볼 수 있다.\n",
    "- `sentences`는 예측을 위한 `X`에 해당된다.\n",
    "- `pos_tags`는 예측 대상인 `y`에 해당된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AZuQvbT9t8tK"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 다른 샘플들에 대해서도 처리가 되었는 지 확인하기 위해 임의로 아홉번 째 샘플에 대해서도 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "bjFp_G2suDdZ",
    "outputId": "fef9093a-c2a1-4bcb-ee60-68dcd4defdf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We', \"'re\", 'talking', 'about', 'years', 'ago', 'before', 'anyone', 'heard', 'of', 'asbestos', 'having', 'any', 'questionable', 'properties', '.']\n",
      "['PRP', 'VBP', 'VBG', 'IN', 'NNS', 'IN', 'IN', 'NN', 'VBD', 'IN', 'NN', 'VBG', 'DT', 'JJ', 'NNS', '.']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[8])\n",
    "print(pos_tags[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1DsmdNP5uGr6"
   },
   "source": [
    "- 단어에 대해서만 `sentences[8]`에, 또한 품사에 대해서만 `pos_tags[8]`에 저장된 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r29nsDhnunBQ"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 4.1.4 데이터의 길이 분포 확인\n",
    "\n",
    "- 첫 번째 샘플과 아홉번 째 샘플의 길이가 다른 것을 볼 수 있다.\n",
    "- 사실 3,914개의 문장 샘플의 길이는 전부 제각각이다.\n",
    "- 전체 데이터의 길이 분포를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "UxbQFZXfvy2g",
    "outputId": "995c86df-977c-404e-d8f8-4cd558f92fb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이 : 271\n",
      "샘플의 평균 길이 : 25.722024\n"
     ]
    }
   ],
   "source": [
    "print('샘플의 최대 길이 : %d' % max(len(l) for l in sentences))\n",
    "print('샘플의 평균 길이 : %f' % (sum(map(len, sentences))/len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "jugILumIv-R-",
    "outputId": "f07e84c3-3b64-4344-fcc0-b88b74ee7b14"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(s) for s in sentences], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "krk7aTotwIeF"
   },
   "source": [
    "- 위의 그래프는 대부분의 샘플의 길이가 150 이내이며, 대부분 0~50의 길이를 가지는 것을 보여준다.\n",
    "- 이제 케라스 토크나이저를 통해서 정수 인코딩을 진행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XOENbrAnwbf8"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 4.1.5 토큰화\n",
    "\n",
    "- 우선 케라스 토크나이저를 다음과 같이 함수로 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tCSiv_liwgRr"
   },
   "outputs": [],
   "source": [
    "def tokenize(samples):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(samples)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ACcClVQwmIs"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 문장 데이터에 대해서는 `src_tokenizer`를, 레이블에 해당되는 품사 태깅 정보에 대해서는 `tar_tokenizer`를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QAniDCGVwtRk"
   },
   "outputs": [],
   "source": [
    "src_tokenizer = tokenize(sentences)\n",
    "tar_tokenizer = tokenize(pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D32-CWDfw2f0"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 단어 집합과 품사 태깅 정보 집합의 크기를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "nn0BkXkQw6vT",
    "outputId": "6a73c14c-d493-494c-941e-04c2087a92e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 11388\n",
      "태깅 정보 집합의 크기 : 47\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(src_tokenizer.word_index) + 1\n",
    "tag_size = len(tar_tokenizer.word_index) + 1\n",
    "\n",
    "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
    "print('태깅 정보 집합의 크기 : {}'.format(tag_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XThIQiThxHJs"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 4.1.6 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yclWWuZDxMCt"
   },
   "outputs": [],
   "source": [
    "X_train = src_tokenizer.texts_to_sequences(sentences)\n",
    "y_train = tar_tokenizer.texts_to_sequences(pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rkb22LxIxWAS"
   },
   "source": [
    "- 문장 데이터에 대해서 정수 인코딩이 수행된 결과는 `X_train`에 저장되었다.\n",
    "- 품사 태깅 데이터에 대해서 정수 인코딩이 수행된 결과는 `y_train`에 저장되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Gs3QgUqxhNS"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 정수 인코딩이 되었는 지 확인을 위해 임의로 세 번째 데이터를 출력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "X3FLn4gnxlYq",
    "outputId": "c716d564-f918-4aa8-f992-8d950bc85b80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5601, 3746, 1, 2024, 86, 331, 1, 46, 2405, 2, 131, 27, 6, 2025, 332, 459, 2026, 3], [31, 3746, 20, 177, 4, 5602, 2915, 1, 2, 2916, 637, 147, 3]]\n",
      "[[3, 3, 8, 10, 6, 7, 8, 21, 13, 4, 1, 2, 4, 7, 1, 3, 10, 9], [3, 3, 17, 1, 2, 3, 3, 8, 4, 3, 19, 1, 9]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:2])\n",
    "print(y_train[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4m4Go0iRxoV7"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 4.1.7 패딩\n",
    "\n",
    "- 앞서 본 그래프에 따르면, 대부분의 샘플은 길이가 150 이내이다.\n",
    "- `X`에 해당되는 데이터 `X_train`의 샘플들과 `y`에 해당되는 데이터 `y_train` 샘플들의 모든 길이를 임의로 150 정도로 맞춰보자.\n",
    "- 이를 위해서 케라스의 `pad_sequences()`를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nDfBMAfQx7Ap"
   },
   "outputs": [],
   "source": [
    "max_len = 150\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\n",
    "y_train = pad_sequences(y_train, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b2Zz7iTayILJ"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 4.1.8 훈련 데이터와 테스트 데이터 분리\n",
    "\n",
    "- 이제 훈련 데이터와 테스트 데이터를 8:2의 비율로 분리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ebeB6QVIyNij"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train,\n",
    "                                                    test_size=.2, random_state=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "weEvrLCgyXxK"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 4.1.9 레이블 데이터 원-핫 인코딩\n",
    "\n",
    "- 레이블에 해당하는 태깅 정보에 대해서 원-핫 인코딩을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LOV9-DPpyduL"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=tag_size)\n",
    "y_test = to_categorical(y_test, num_classes=tag_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0lLQxmjFykkj"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 4.1.10 각 데이터의 크기 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "ZSWvSop0yy9i",
    "outputId": "8a966543-6e64-4642-c6ac-e940431f3ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 문장의 크기 : (3131, 150)\n",
      "훈련 샘플 레이블의 크기 : (3131, 150, 47)\n",
      "테스트 샘플 문장의 크기 : (783, 150)\n",
      "테스트 샘플 레이블의 크기 : (783, 150, 47)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
    "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
    "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
    "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0b3k5dQfy0Gh"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 4.2 양방향 LSTM(Bi-directional LSTM)으로 POS Tagger 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d6YVt_nQy48S"
   },
   "source": [
    "### 4.2.1 필요 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vbCxB1SxC71g"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Bidirectional, LSTM, Embedding, InputLayer, TimeDistributed\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FI7h7PH5DKLW"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 4.2.2 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iwfDJBZzDNSQ"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128, input_length=max_len, mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(tag_size, activation=('softmax'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FJfkKKTaDfug"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 4.2.3 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AhkOTgc8Dhyg"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CvsvyfEaDpXy"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 4.2.4 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "colab_type": "code",
    "id": "0Ekl4C3SDr8P",
    "outputId": "ceadb4a4-7d17-4166-d1ac-f6775b16bcd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "25/25 [==============================] - 3s 138ms/step - loss: 0.5733 - accuracy: 0.0582 - val_loss: 0.4946 - val_accuracy: 0.0344\n",
      "Epoch 2/6\n",
      "25/25 [==============================] - 1s 50ms/step - loss: 0.4912 - accuracy: 0.0392 - val_loss: 0.4491 - val_accuracy: 0.0574\n",
      "Epoch 3/6\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.4060 - accuracy: 0.0739 - val_loss: 0.3184 - val_accuracy: 0.0881\n",
      "Epoch 4/6\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.2575 - accuracy: 0.1051 - val_loss: 0.1885 - val_accuracy: 0.1250\n",
      "Epoch 5/6\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.1356 - accuracy: 0.1411 - val_loss: 0.0992 - val_accuracy: 0.1473\n",
      "Epoch 6/6\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 0.0686 - accuracy: 0.1567 - val_loss: 0.0649 - val_accuracy: 0.1540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6e9462acf8>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=6, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uAA8I5Y0DxyE"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 4.2.5 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "m2c7CXMXD6eP",
    "outputId": "fc17bc96-086e-4ae5-8c8e-7266f7ce98d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0662 - accuracy: 0.1540\n",
      "\n",
      " 테스트 정확도: 0.1540\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OhphUr-SD_00"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 4.2.6 특정 테스트 데이터 출력\n",
    "\n",
    "- 실제로 맞추고 있는 지를 특정 테스트 데이터를 주고 직접 출력해서 확인해보자.\n",
    "- 우선 인덱스로부터 단어와 품사 태깅 정보를 리턴하는 `index_to_word`와 `index_to_tag`를 만들고 이를 이용하여 실제값과 예측값을 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cgT0GMldEaoi"
   },
   "outputs": [],
   "source": [
    "index_to_word = src_tokenizer.index_word\n",
    "index_to_tag = tar_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "colab_type": "code",
    "id": "tPW2nznqEi8C",
    "outputId": "ef29af27-a248-41d4-942f-f9ee4540e4b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어             |실제값  |예측값\n",
      "-----------------------------------\n",
      "in               : IN      IN\n",
      "addition         : NN      NN\n",
      ",                : ,       ,\n",
      "buick            : NNP     NNP\n",
      "is               : VBZ     VBZ\n",
      "a                : DT      DT\n",
      "relatively       : RB      RB\n",
      "respected        : VBN     VBN\n",
      "nameplate        : NN      NN\n",
      "among            : IN      IN\n",
      "american         : NNP     NNP\n",
      "express          : NNP     NNP\n",
      "card             : NN      NN\n",
      "holders          : NNS     NNS\n",
      ",                : ,       ,\n",
      "says             : VBZ     VBZ\n",
      "0                : -NONE-  -NONE-\n",
      "*t*-1            : -NONE-  -NONE-\n",
      "an               : DT      DT\n",
      "american         : NNP     NNP\n",
      "express          : NNP     NNP\n",
      "spokeswoman      : NN      NN\n",
      ".                : .       .\n"
     ]
    }
   ],
   "source": [
    "i = 10 # 확인하고 싶은 테스트용 샘플의 인덱스\n",
    "\n",
    "# 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
    "y_predicted = model.predict(np.array([X_test[i]]))\n",
    "\n",
    "# 원-핫 인코딩을 다시 정수 인코딩으로 변경\n",
    "y_predicted = np.argmax(y_predicted, axis=-1)\n",
    "true = np.argmax(y_test[i], -1)\n",
    "\n",
    "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
    "print(35 * \"-\")\n",
    "\n",
    "for w, t, pred in zip(X_test[i], true, y_predicted[0]):\n",
    "    if w != 0: # PAD값은 제외함.\n",
    "        print(\"{:17}: {:7} {}\".format(index_to_word[w], index_to_tag[t].upper(), index_to_tag[pred].upper()))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Ch12_v04_Part-of-speech-Tagging-using-Bi-LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
