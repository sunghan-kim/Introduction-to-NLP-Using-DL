{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4JZeAc4SNkSa"
   },
   "source": [
    "# Ch12. 태깅 작업 (Tagging Task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOXeXiItOeRF"
   },
   "source": [
    "# v03. 양방향 LSTM을 이용한 개체명 인식 (Named Entity Recognition using Bi-LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xoLBSryYOkjM"
   },
   "source": [
    "- 개체명 인식은 챗봇 등에서 필요로 하는 주요 전처리 작업이지만, 그 자체로도 까다로운 작업이다.\n",
    "- 도메인 또는 목적에 특화되도록 개체명 인식을 정확하게 하는 방법 중 하나는 기존에 공개된 개체명 인식기를 사용하는 것이 아니라, 직접 목적에 맞는 데이터를 준비하여 기계를 훈련시켜 모델을 만드는 방법이다.\n",
    "- 여기서는 양방향 LSTM을 이용해서 개체명 인식기를 만들어보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FQcrtkLsnHkR"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 3.1 BIO 표현\n",
    "\n",
    "- 개체명 인식에서 코퍼스로부터 개체명을 인식하기 위한 방법으로 여러 방법이 있다.\n",
    "- 여기서는 가장 보편적인 방법 중 하나인 **IOB(또는 BIO) 방법**을 소개한다.\n",
    "  - B : Begin의 약자, 개체명이 시작되는 부분\n",
    "  - I : Inside의 약자, 개체명의 내부 부분\n",
    "  - O : Outside의 약자, 개체명이 아닌 부분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R3kmMN91neUR"
   },
   "source": [
    "- 예를 들어, 영화에 대한 코퍼스 중에서 영화 제목에 대한 개체명을 뽑아내고 싶다고 가정하자.\n",
    "\n",
    "```\n",
    "해 B\n",
    "리 I\n",
    "포 I\n",
    "터 I\n",
    "보 O\n",
    "러 O\n",
    "가 O\n",
    "자 O\n",
    "```\n",
    "\n",
    "- 다음과 같이 영화 제목에 대해서만 개체명을 인식한다.\n",
    "- 영화 제목이 시작되는 글자인 '해'에서는 B가 사용되었다.\n",
    "- 그리고 영화 제목이 끝나는 순간까지 I가 사용된다.\n",
    "- 그리고 영화 제목이 아닌 부분에서만 O가 사용된다.\n",
    "- 이처럼 B와 I는 개체명을 위해 사용되고, O는 개체명이 아니라는 의미를 갖게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ek6FXuXNnmO2"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 물론 개체명 인식이라는 것은 보통 한 종류의 개체에 대해서만 언급하는 것이 아니라, 여러 종류의 개체가 있을 수 있다.\n",
    "- 예를 들어 영화에 대한 대화에서는 여화 제목에 대한 개체명과 극장에 대한 개체명이 있을 수 있다.\n",
    "- 그럴 때는 각 개체가 어떤 종류인지도 함께 태깅될 것이다.\n",
    "\n",
    "```\n",
    "해 B-movie\n",
    "리 I-movie\n",
    "포 I-movie\n",
    "터 I-movie\n",
    "보 O\n",
    "러 O\n",
    "메 B-theater\n",
    "가 I-theater\n",
    "박 I-theater\n",
    "스 I-theater\n",
    "가 O\n",
    "자 O\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oChkci9JoGhV"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 3.2 개체명 인식 데이터 이해하기\n",
    "\n",
    "- 이제 실습을 통해 양방향 LSTM을 이용한 개체명 인식에 대해서 더 자세히 알아보도록 하자.\n",
    "- `CONLL2003`은 개체명 인식을 위한 전통적인 영어 데이터 셋이다.\n",
    "- 해당 데이터를 가지고 훈련하여 개체명 인식 모델을 만들어보자.\n",
    "- [다운로드 링크](https://raw.githubusercontent.com/Franck-Dernoncourt/NeuroNER/master/neuroner/data/conll2003/en/train.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E5RE2K35oZCU"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 해당 데이터의 앞 부분을 일부 살펴보자.\n",
    "\n",
    "```\n",
    "EU NNP B-NP B-ORG\n",
    "rejects VBZ B-VP O\n",
    "German JJ B-NP B-MISC\n",
    "call NN I-NP O\n",
    "to TO B-VP O\n",
    "boycott VB I-VP O\n",
    "British JJ B-NP B-MISC\n",
    "lamb NN I-NP O\n",
    ". . O O\n",
    "\n",
    "Peter NNP B-NP B-PER\n",
    "Blackburn NNP I-NP I-PER\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yfhy1qQro6Ju"
   },
   "source": [
    "- 해당 데이터의 양식은 `[단어] [품사 태깅] [청크 태깅] [개체명 태깅]`의 형식으로 되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zkIuT73no_Aj"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.2.1 품사 태깅\n",
    "\n",
    "- 품사 태깅이 의미하는 바는 [해당 링크](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)에서 자세하게 확인할 수 있다.\n",
    "- 예를 들어서 `EU` 옆에 붙어있는 `NNP`는 **고유 명사 단수형**을 의미한다.\n",
    "- `rejects` 옆에 있는 `VBZ`는 **3인칭 단수 동사 현재형**을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQFhqAMpVV1"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.2.2 개체명 태깅\n",
    "\n",
    "- `LOC` : location\n",
    "- `ORG` : organization\n",
    "- `PER` : person\n",
    "- `MISC` : miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AG87q8f7tRg8"
   },
   "source": [
    "- 해당 데이터는 BIO 표현 방법을 사용하고 있기 때문에, 개체명의 시작 부분이면서 Organization을 의미하는 `German`에는 `B-ORG`라는 개체명 태깅이 붙는다.\n",
    "- 다만, `German` 그 자체로 개체명 하나이기 때문에 거기서 개체명 인식은 종료되면서 뒤에 `I`가 별도로 붙는 단어가 나오지는 않았다.\n",
    "- 이에 `German` 뒤에 오는 `call`은 개체명이 아니기 때문에 `O`가 태깅이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LEbm9sUBt1d1"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.2.3 문장의 시작과 종료 구분\n",
    "\n",
    "- 또 하나 기억해두어야 할 것은 9번째 줄인 `.. O O` 다음에 11번째 줄 `Peter`가 나오는 부분 사이에 10번째 줄은 공란으로 되어 있다.\n",
    "- 이는 9번째 줄에서 문장이 끝나고 11번째 줄에서 새로운 문장이 시작됨을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sjfc7WtauLvq"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.2.4 이어진 단어 개체명 태깅\n",
    "\n",
    "- 그 다음 문장이 시작되는 11번째 줄에서는 개체명이 하나의 단어로 끝나지 않았을 때, 어떻게 다음 단어로 개체명 인식이 이어지는 지를 보여준다.\n",
    "- `Peter`는 개체명이 시작되면서 person에 해당되기 때문에 `B-PER`이라는 개체명 태깅이 붙는다.\n",
    "- 그리고 아직 개체명에 대한 인식은 끝나지 않았기 때문에 뒤에 붙는 `Balckburn`에서는 `I`가 나오면서 `I-PER`이 개체명 태깅으로 붙게 된다.\n",
    "- 즉, `Peter Blackburn`이 person에 속하는 하나의 개체명이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9lhT1_Vu1zC"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 3.3 데이터 전처리하기\n",
    "\n",
    "- 이번에는 양방향 LSTM을 이용해서 개체명 인식 태깅을 하는 모델을 만들어보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3laY4YdawDk-"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.3.1 필요 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m5gtD_EPu4R0"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kwgmbdW_vUZs"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.3.2 개체명 인식 데이터 불러오기 및 전처리 수행\n",
    "\n",
    "- 위에서 설명한 개체명 인식 데이터를 읽어 전처리를 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tj_w4MpDvbLQ"
   },
   "outputs": [],
   "source": [
    "f = open('train.txt', 'r')\n",
    "tagged_sentences = []\n",
    "sentence = []\n",
    "\n",
    "for line in f:\n",
    "    if len(line)==0 or line.startswith('-DOCSTART') or line[0]==\"\\n\":\n",
    "        if len(sentence) > 0:\n",
    "            tagged_sentences.append(sentence)\n",
    "            sentence = []\n",
    "        continue\n",
    "    splits = line.split(' ') # 공백을 기준으로 속성을 구분한다.\n",
    "    splits[-1] = re.sub(r'\\n', '', splits[-1]) # 줄바꿈 표시 \\n을 제거한다.\n",
    "    word = splits[0].lower() # 단어들은 소문자로 바꿔서 저장한다.\n",
    "    sentence.append([word, splits[-1]]) # 단어와 개체명 태깅만 기록한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "63LhWEv9v-NU"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.3.3 전체 샘플 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "i3JcjH5MwSJI",
    "outputId": "ad18de8d-da50-4121-a596-58bb330cd311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 개수 :  14041\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플 개수 : ', len(tagged_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lvp7ZDoPwU9Y"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.3.4 첫 번째 샘플 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8GApFWhMwYQp",
    "outputId": "85b107a4-e369-4755-87f6-a11e1598f444"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['eu', 'B-ORG'], ['rejects', 'O'], ['german', 'B-MISC'], ['call', 'O'], ['to', 'O'], ['boycott', 'O'], ['british', 'B-MISC'], ['lamb', 'O'], ['.', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(tagged_sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cDOpwBlHwZ7G"
   },
   "source": [
    "- 전처리가 수행된 첫 번째 샘플이 출력된 것을 볼 수 있다.\n",
    "- 이러한 샘플이 총 14,041개가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FH5vxvE-wqRI"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.3.5 단어와 태깅 정보 분리\n",
    "\n",
    "- 그런데 훈련을 시키려면 훈련 데이터에서 단어에 해당되는 부분과 개체명 태깅 정보에 해당되는 부분을 분리시켜야 한다.\n",
    "- 즉, `[('eu', 'B-ORG'), ('rejects', 'O')]`와 같은 문장 샘플이 있다면 `eu`와 `rejects`는 같이 저장(단어)하고, `B-ORG`와 `O`를 같이 저장(태깅 정보)할 필요가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZacIkv7tw2VG"
   },
   "source": [
    "- 이런 경우 파이썬 함수 중에서 `zip()` 함수가 유용한 역할을 한다.\n",
    "- `zip()` 함수는 동일한 개수를 가지는 시퀀스 자료형에서 각 순서에 등장하는 원소들끼리 묶어주는 역할을 한다.  \n",
    "(2챕터의 데이터의 분리 챕터 참고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kTkjCxdKxBHt"
   },
   "outputs": [],
   "source": [
    "sentences, ner_tags = [], [] \n",
    "for tagged_sentence in tagged_sentences: # 14,041개의 문장 샘플을 1개씩 불러온다.\n",
    "    sentence, tag_info = zip(*tagged_sentence) # 각 샘플에서 단어들은 sentence에 개체명 태깅 정보들은 tag_info에 저장.\n",
    "    sentences.append(list(sentence)) # 각 샘플에서 단어 정보만 저장한다.\n",
    "    ner_tags.append(list(tag_info)) # 각 샘플에서 개체명 태깅 정보만 저장한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "enFXdlM92lSN"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 임의로 첫 번째 문장 샘플을 출력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "4q3BnUO92sCP",
    "outputId": "0a6a358f-39cf-474f-bb42-52b7e3e15faf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n",
      "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])\n",
    "print(ner_tags[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wBayINDz2v5n"
   },
   "source": [
    "- 첫 번째 샘플에 대해서 \n",
    "  - 단어에 대해서만 `sentences[0]`에 저장됨\n",
    "  - 개체명에 대해서만 `ner_tags[0]`에 저장됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mHecBamD27Wh"
   },
   "source": [
    "- `sentences`는 예측을 위한 `X`에 해당된다.\n",
    "- `ner_tags`는 예측 대상인 `y`에 해당된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qw3hYGw13Dxe"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 다른 샘플들에 대해서도 처리가 되었는 지 확인하기 위해 임의로 13번 째 샘플에 대해서도 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "TKB4Elj33Kwl",
    "outputId": "99b8ff11-93a0-43d6-e66d-a2723be082a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['only', 'france', 'and', 'britain', 'backed', 'fischler', \"'s\", 'proposal', '.']\n",
      "['O', 'B-LOC', 'O', 'B-LOC', 'O', 'B-PER', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[12])\n",
    "print(ner_tags[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UN30e6cp3OLu"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.3.6 샘플의 길이 분포 확인\n",
    "\n",
    "- 13번 째 샘플은 첫 번째 샘플과 길이가 다른 것을 볼 수 있다.\n",
    "- 사실 14,041개의 문장 샘플의 길이는 전부 제각각이다.\n",
    "- 전체 데이터의 길이 분포를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "Y3v2U0B13fIF",
    "outputId": "c0f62f1d-9eab-4bbe-b2f1-10d4273cd44f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이 : 113\n",
      "샘플의 평균 길이 : 14.501887\n"
     ]
    }
   ],
   "source": [
    "print('샘플의 최대 길이 : %d' % max(len(l) for l in sentences))\n",
    "print('샘플의 평균 길이 : %f' % (sum(map(len, sentences)) / len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "NcBBugW_3rXN",
    "outputId": "368cea44-0149-4443-fb3a-bdcc4f3ddf84"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(s) for s in sentences], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ww9vJJx13zaF"
   },
   "source": [
    "- 위의 그래프는 샘플들의 길이가 대체적으로 0~40의 길이를 가진다.\n",
    "- 특히 0~20의 길이를 가진 샘플이 상당한 비율을 차지하는 것을 보여준다.\n",
    "- 길이가 가장 긴 샘플의 길이는 113이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3NH80p6j36vs"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.3.7 토큰화\n",
    "\n",
    "- 이제 케라스 토크나이저를 통해서 토큰화와 정수 인코딩을 진행한다.\n",
    "- 이번에는 문장 데이터에 있는 모든 단어를 사용하지 않고 높은 빈도수를 가진 상위 약 4,000개의 단어만을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "deS7Gfh54fYK"
   },
   "source": [
    "- 문장 데이터에 대해서는 `src_tokenizer`를 사용한다.\n",
    "- 레이블에 해당되는 개체명 태깅 정보에 대해서는 `tar_tokenizer`를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2WEc2sT43-wH"
   },
   "outputs": [],
   "source": [
    "max_words = 4000\n",
    "src_tokenizer = Tokenizer(num_words=max_words, oov_token='OOV')\n",
    "src_tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(ner_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "r4JAda9k4XKu",
    "outputId": "d9efb4c1-795b-4954-bafb-a9f6fd7b9b26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 4000\n",
      "개체명 태깅 정보 집합의 크기 : 10\n"
     ]
    }
   ],
   "source": [
    "vocab_size = max_words\n",
    "tag_size = len(tar_tokenizer.word_index) + 1\n",
    "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
    "print('개체명 태깅 정보 집합의 크기 : {}'.format(tag_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UZLV_qKM4tsj"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.3.8 정수 인코딩\n",
    "\n",
    "- 문장 데이터에 대해서 정수 인코딩이 수행된 결과는 `X_train`에 저장한다.\n",
    "- 개체명 태깅 데이터에 대해서 정수 인코딩이 수행된 결과는 `y_train`에 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GxR27B9R5BcS"
   },
   "outputs": [],
   "source": [
    "X_train = src_tokenizer.texts_to_sequences(sentences)\n",
    "y_train = tar_tokenizer.texts_to_sequences(ner_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UZe-teeE5IIT"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 정수 인코딩이 되었는 지 확인을 위해 임의로 첫 번째 데이터를 출력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "7uKmaXTK5OXq",
    "outputId": "7af7a498-63b1-4db7-f8a0-71e45f7a3e57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[989, 1, 205, 629, 7, 3939, 216, 1, 3]\n",
      "[4, 1, 7, 1, 1, 1, 7, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mf-OaHhk5Qa6"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.3.9 디코딩\n",
    "\n",
    "- 현재 문장 데이터에 대해서는 일부 단어가 `'OOV'`로 대체된 상황이다.\n",
    "- 이를 확인하기 위해 다시 디코딩(정수에서 다시 텍스트 데이터로 변환) 작업을 해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q30kL29G5pH5"
   },
   "source": [
    "- 이를 위해 인덱스로부터 단어를 리턴하는 `index_to_word`를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mgEewBvA5f2Z"
   },
   "outputs": [],
   "source": [
    "index_to_word = src_tokenizer.index_word\n",
    "index_to_ner = tar_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oi0SL4j65l-i"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 정수 인코딩 된 첫 번째 문장을 다시 디코딩해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "dSWyETXV5tx5",
    "outputId": "f2769a76-3edc-489f-f9dc-7ea52401a5cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 문장 : ['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n",
      "빈도수가 낮은 단어가 OOV 처리된 문장 : ['eu', 'OOV', 'german', 'call', 'to', 'boycott', 'british', 'OOV', '.']\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for index in X_train[0] : # 첫번째 샘플 안의 인덱스들에 대해서\n",
    "    decoded.append(index_to_word[index]) # 다시 단어로 변환\n",
    "\n",
    "print('기존 문장 : {}'.format(sentences[0]))\n",
    "print('빈도수가 낮은 단어가 OOV 처리된 문장 : {}'.format(decoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XnP6EoUE6CD0"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.3.10 패딩\n",
    "\n",
    "- 앞서 본 그래프에 따르면, 대부분의 샘플은 길이가 70 이내이다.\n",
    "- `X`에 해당되는 데이터 `X_train`의 샘플들과 `y`에 해당되는 데이터 `y_train` 샘플들의 모든 길이를 임의로 70정도로 맞춰본다.\n",
    "- 이를 위해서 케라스의 `pad_sequences()`를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMQRLmZpXMXS"
   },
   "outputs": [],
   "source": [
    "max_len = 70\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\n",
    "# X_train의 모든 샘플들의 길이를 맞출 때 뒤의 공간에 숫자 0으로 채움.\n",
    "y_train = pad_sequences(y_train, padding='post', maxlen=max_len)\n",
    "# y_train의 모든 샘플들의 길이를 맞출 때 뒤의 공간에 숫자0으로 채움."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L0AZ0UDEXQsK"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.3.11 훈련 데이터와 테스트 데이터 분리\n",
    "\n",
    "- 이제 훈련 데이터와 테스트 데이터를 8:2의 비율로 분리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EggKgVRBXWNI"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=.2, random_state=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h7YDjEyNXXNS"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.3.12 레이블 데이터 원-핫 인코딩\n",
    "\n",
    "- 레이블에 해당하는 태깅 정보에 대해서 원-핫 인코딩을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EI2lKAxAXcHp"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=tag_size)\n",
    "y_test = to_categorical(y_test, num_classes=tag_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ykWqftUGXdXy"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.3.13 각 데이터의 크기 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "UdoUAVcRXggE",
    "outputId": "200a20f8-1080-4e25-cbcc-dff506d3fc60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 문장의 크기 : (11232, 70)\n",
      "훈련 샘플 레이블의 크기 : (11232, 70, 10)\n",
      "테스트 샘플 문장의 크기 : (2809, 70)\n",
      "테스트 샘플 레이블의 크기 : (2809, 70, 10)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
    "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
    "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
    "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AawwusxrXiW6"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 3.4 양방향 LSTM(Bi-directional LSTM)으로 개체명 인식기 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vFAB9kKdXqLh"
   },
   "source": [
    "### 3.4.1 필요 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yCw4QkP5XsVU"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xMU-AOqeX6zJ"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.4.2 모델 설계\n",
    "\n",
    "- Many-to-Many 문제이므로 `LSTM()`에 `return_sequences=True`를 설정해준다.\n",
    "- 또한, 이번 실습과 각ㅌ이 각 데이터의 길이가 달라서 패딩을 하느라 숫자 0이 많아질 경우에는 `Embedding()`에 `mask_zero=True`를 설정하여 데이터에서 숫자 0은 패딩을 의미하므로 연산에서 제외시킨다는 옵션을 줄 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_s-NTiuCYPNo"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len, mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(tag_size, activation='softmax')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IAGSU98lYhQ9"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.4.3 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GOErcXAPYmPn"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ShhNiD-Yt3P"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.4.4 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "aJZzlx3NYw4K",
    "outputId": "bdac527f-5e5f-451b-ce42-5025feaeff9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "88/88 [==============================] - 4s 51ms/step - loss: 0.1852 - accuracy: 0.1807 - val_loss: 0.1227 - val_accuracy: 0.1691\n",
      "Epoch 2/8\n",
      "88/88 [==============================] - 2s 27ms/step - loss: 0.0985 - accuracy: 0.1782 - val_loss: 0.0786 - val_accuracy: 0.1801\n",
      "Epoch 3/8\n",
      "88/88 [==============================] - 2s 27ms/step - loss: 0.0669 - accuracy: 0.1881 - val_loss: 0.0544 - val_accuracy: 0.1872\n",
      "Epoch 4/8\n",
      "88/88 [==============================] - 2s 26ms/step - loss: 0.0471 - accuracy: 0.1943 - val_loss: 0.0413 - val_accuracy: 0.1911\n",
      "Epoch 5/8\n",
      "88/88 [==============================] - 2s 27ms/step - loss: 0.0362 - accuracy: 0.1975 - val_loss: 0.0363 - val_accuracy: 0.1926\n",
      "Epoch 6/8\n",
      "88/88 [==============================] - 2s 27ms/step - loss: 0.0306 - accuracy: 0.1991 - val_loss: 0.0337 - val_accuracy: 0.1934\n",
      "Epoch 7/8\n",
      "88/88 [==============================] - 2s 27ms/step - loss: 0.0257 - accuracy: 0.2004 - val_loss: 0.0331 - val_accuracy: 0.1937\n",
      "Epoch 8/8\n",
      "88/88 [==============================] - 2s 27ms/step - loss: 0.0226 - accuracy: 0.2014 - val_loss: 0.0320 - val_accuracy: 0.1942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff7a0117208>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=8,  validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Azr88N6Y22k"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.4.5 정확도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "GOUCyGqSY9AF",
    "outputId": "9d91b524-be55-4103-a4c1-280fc92f9b04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 1s 6ms/step - loss: 0.0320 - accuracy: 0.1942\n",
      "\n",
      " 테스트 정확도 : 0.1942\n"
     ]
    }
   ],
   "source": [
    "print('\\n 테스트 정확도 : %.4f' % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yHq2H-otZEIr"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.4.6 테스트 데이터와 실제값 비교\n",
    "\n",
    "- 실제로 맞추고 있는 지를 테스트 데이터를 주고 직접 실제값과 비교해보도록 하자.\n",
    "- 앞서 만들어둔 인덱스로부터 단어와 개체명 태깅 정보를 리턴하는 `index_to_word`와 `index_to_ner`를 사용하여 테스트 데이터에 대한 예측값과 실제값을 비교 출력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 755
    },
    "colab_type": "code",
    "id": "Pmy1LjUwh2BH",
    "outputId": "a34f07e9-75a4-45e7-b5b0-27d41ee9de93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어             |실제값  |예측값\n",
      "-----------------------------------\n",
      "sarah            : B-PER   B-PER\n",
      "brady            : I-PER   I-PER\n",
      ",                : O       O\n",
      "whose            : O       O\n",
      "republican       : B-MISC  B-MISC\n",
      "husband          : O       O\n",
      "was              : O       O\n",
      "OOV              : O       O\n",
      "OOV              : O       O\n",
      "in               : O       O\n",
      "an               : O       O\n",
      "OOV              : O       O\n",
      "attempt          : O       O\n",
      "on               : O       O\n",
      "president        : O       O\n",
      "ronald           : B-PER   B-PER\n",
      "reagan           : I-PER   I-PER\n",
      ",                : O       O\n",
      "took             : O       O\n",
      "centre           : O       O\n",
      "stage            : O       O\n",
      "at               : O       O\n",
      "the              : O       O\n",
      "democratic       : B-MISC  B-MISC\n",
      "national         : I-MISC  I-MISC\n",
      "convention       : I-MISC  I-MISC\n",
      "on               : O       O\n",
      "monday           : O       O\n",
      "night            : O       O\n",
      "to               : O       O\n",
      "OOV              : O       O\n",
      "president        : O       O\n",
      "bill             : B-PER   B-PER\n",
      "clinton          : I-PER   I-PER\n",
      "'s               : O       O\n",
      "gun              : O       O\n",
      "control          : O       O\n",
      "efforts          : O       O\n",
      ".                : O       O\n"
     ]
    }
   ],
   "source": [
    "i = 10 # 확인하고 싶은 테스트용 샘플의 인덱스\n",
    "y_predicted = model.predict(np.array([X_test[i]])) # 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
    "y_predicted = np.argmax(y_predicted, axis=-1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경\n",
    "true = np.argmax(y_test[i], -1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경\n",
    "\n",
    "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
    "print(35 * \"-\")\n",
    "\n",
    "for w, t, pred in zip(X_test[i], true, y_predicted[0]):\n",
    "    if w != 0:\n",
    "        print(\"{:17}: {:7} {}\".format(index_to_word[w], index_to_ner[t].upper(), index_to_ner[pred].upper()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I_MFRbRLimsH"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 3.5 총평\n",
    "\n",
    "- 정확도를 계산하고, 테스트용 샘플에 대해서 예측한 개체명도 출력해봤다.\n",
    "- 출력 결과는 그럴듯해 보이지만 사실 이번에 사용한 정확도 측정 방법이 그다지 적절하지는 않다.\n",
    "- 대부분의 단어가 개체명이 아니라는 `'O'`가 태깅된 상황에서 예측 정확도가 수많은 `'O'`로 인해 결정되고 있기 때문이다.\n",
    "- 이를 해결하는 방법으로는 여러 가지가 있겠지만, 그 중 한 가지는 **F1-score**를 도입하는 것이다.\n",
    "- 이에 대해서는 양방향 LSTM과 CRF 챕터에서 배운다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tpqUBU9xjQbk"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 3.6 참고 링크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKTxbD_kjTLs"
   },
   "source": [
    "### 3.6.1 F1-score에 대한 설명\n",
    "\n",
    "- [https://foulmouthedcshuman.blogspot.com/2018/02/crf-1-task-bio.html](https://foulmouthedcshuman.blogspot.com/2018/02/crf-1-task-bio.html)\n",
    "- [https://blog.naver.com/sogangori/220986343741](https://blog.naver.com/sogangori/220986343741)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CYn-DM7qjZj1"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.6.2 TimeDistributed\n",
    "\n",
    "- [https://github.com/keras-team/keras/issues/1029](https://github.com/keras-team/keras/issues/1029)\n",
    "- [https://stackoverflow.com/questions/47305618/what-is-the-role-of-timedistributed-layer-in-keras/47309453#47309453](https://stackoverflow.com/questions/47305618/what-is-the-role-of-timedistributed-layer-in-keras/47309453#47309453)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i2exSrrEjgKU"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.6.3 `mask_zero=True`\n",
    "\n",
    "- [https://stackoverflow.com/questions/47485216/how-does-mask-zero-in-keras-embedding-layer-work](https://stackoverflow.com/questions/47485216/how-does-mask-zero-in-keras-embedding-layer-work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hAvDC0MTjlwk"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.6.4 OOV 핸들링 하기\n",
    "\n",
    "- [https://medium.com/kata-engineering/handling-out-of-vocabulary-problem-in-indonesian-named-entity-recognition-b63ab3e23a66](https://medium.com/kata-engineering/handling-out-of-vocabulary-problem-in-indonesian-named-entity-recognition-b63ab3e23a66)\n",
    "- [https://www.aclweb.org/anthology/C16-1030](https://www.aclweb.org/anthology/C16-1030)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Ch12_v03_Named-Entity-Recognition-using-Bi-LSTM.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
