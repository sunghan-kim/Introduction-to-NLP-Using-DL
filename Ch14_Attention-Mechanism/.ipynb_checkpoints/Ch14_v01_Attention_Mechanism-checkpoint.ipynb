{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X-WWUZ_fOZco"
   },
   "source": [
    "# Ch14. 어텐션 메커니즘 (Attention Mechanism)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zva2laflOnB5"
   },
   "source": [
    "# v01. 어텐션 메커니즘 (Attention Mechanism)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_WAr7mTPOodY"
   },
   "source": [
    "- 앞서 배운 seq2seq 모델\n",
    "  - **인코더**에서 입력 시퀀스를 컨텍스트 벡터라는 하나의 고정된 크기의 벡터 표현으로 압축\n",
    "  - **디코더**는 이 컨텍스트 벡터를 통해서 출력 시퀀스를 만들어 냄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_McTZTPO1l7"
   },
   "source": [
    "- 하지만 이러한 RNN에 기반한 seq2seq 모델에는 크게 두 가지 문제가 있다.\n",
    "  1. **하나의 고정된 크기의 벡터에 모든 정보를 압축하려고 하니까 정보 손실이 발생한다.**\n",
    "  2. **RNN의 고질적인 문제인 기울기 소실(Vanishing Gradient) 문제가 존재한다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u07QbscZPG7o"
   },
   "source": [
    "- 즉, 결국 이는 기계 번역 분야에서 입력 문장이 길면 번역 품질이 떨어지는 현상으로 나타났다.\n",
    "- 이를 위한 대안으로 입력 시퀀스가 길어지면 출력 시퀀스의 정확도가 떨어지는 것을 보정해주기 위해 등장한 기법인 **어텐션(attention)**을 소개한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GeLXssElPUA_"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.1 어텐션(Attention)의 아이디어\n",
    "\n",
    "- 어텐션의 기본 아이디어는 디코더에서 출력 단어를 예측하는 매 시점(time step)마다, 인코더에서의 전체 입력 문장을 다시 한 번 참고한다는 점이다.\n",
    "- 단, 전체 입력 문장을 전부 다 동일한 비율로 참고하는 것이 아니라, 해당 시점에서 예측해야 할 단어와 연관이 있는 입력 단어 부분을 좀 더 집중(attention)해서 보게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1c7sTRFOPlcu"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.2 어텐션 함수 (Attention Function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h7b7qbNFPz2W"
   },
   "source": [
    "### 1.2.1 key-value 자료형\n",
    "\n",
    "- 어텐션 메커니즘을 언급하기 전에 컴퓨터공학의 많은 분야에서 사용되는 Key-Value로 구성되는 자료형에 대해서 잠깐 살펴보자.\n",
    "- 가령, 이 책의 주 언어로 사용되는 파이썬에도 Key-Value로 구성되는 자료형인 **딕셔너리(Dict)** 자료형이 존재한다.\n",
    "- 파이썬의 딕셔너리 자료형은 키(Key)와 값(Value)이라는 두 개의 쌍으로 구성된다.\n",
    "- 키를 통해서 맵핑된 값을 찾아낼 수 있다는 특징을 갖고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8TBw9oSyQhE1"
   },
   "outputs": [],
   "source": [
    "# 파이썬의 딕셔너리 자료형을 선언\n",
    "# 키(Key): 값(value)의 형식으로 키와 값의 쌍(Pair)을 선언한다.\n",
    "dict = {\"2017\": \"Transformer\", \"2018\": \"BERT\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "my0vUeheQsR-"
   },
   "source": [
    "- 위의 자료형에서 `2017`은 키에 해당되며, `Transformer`는 `2017`의 키와 맵핑되는 값에 해당된다.\n",
    "- 그와 마찬가지로 `2018`은 키에 해당되며, `BERT`는 `2018`이라는 키와 맵핑되는 값에 해당된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VFGTh63DW3Ca",
    "outputId": "61a15a38-7924-4ac2-b2e8-21aae706499c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer\n"
     ]
    }
   ],
   "source": [
    "print(dict['2017'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "TF7iLHU_W4ks",
    "outputId": "8e06006e-c6b7-4169-dd74-214274305005"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT\n"
     ]
    }
   ],
   "source": [
    "print(dict['2018'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0rhZJKMiW6XL"
   },
   "source": [
    "- Key-Value 자료형에 대한 이해를 가지고, 어텐션 함수에 대해서 설명해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QOge9gQQW_Ur"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.2.2 어텐션 함수\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/22893/%EC%BF%BC%EB%A6%AC.PNG)\n",
    "\n",
    "- 어텐션을 함수로 표현하면 주로 다음과 같이 표현된다.\n",
    "\n",
    "> **Attention(Q, K, V) = Attention Value**\n",
    "\n",
    "- 어텐션 함수는 주어진 '쿼리(Query)'에 대해서 모든 '키(Key)'와의 유사도를 각각 구한다.\n",
    "- 그리고 구해낸 이 유사도를 키와 맵핑되어 있는 각각의 '값(Value)'에 반영해준다.\n",
    "- 그리고 유사도가 반영된 '값(Value)'을 모두 더해서 리턴한다.\n",
    "- 여기서는 이를 어텐션 값(Attention Value)이라고 하겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yN6_N43rXdy7"
   },
   "source": [
    "- 지금부터 배우게 되는 seq2seq + 어텐션 모델에서 Q, K, V에 해당되는 각각의 Query, Keys, Values는 각각 다음과 같다.\n",
    "\n",
    "```\n",
    "Q = Query : t 시점의 디코더 셀에서의 은닉 상태\n",
    "K = Keys : 모든 시점의 인코더 셀의 은닉 상태들\n",
    "V = Values : 모든 시점의 인코더 셀의 은닉 상태들\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNQqMkrWXsbE"
   },
   "source": [
    "- 이제 매우 간소화된 어텐션 예제를 통해 어텐션을 이해해보도록 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oA3bXCt2XyNx"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.3 닷-프로덕트 어텐션 (Dot-Product Attention)\n",
    "\n",
    "- 어텐션은 다양한 종류가 있다.\n",
    "- 그 중에서도 가장 수식적으로 이해하기 쉽게 수식을 적용한 닷-프로덕트 어텐션(Dot-Product Attention)을 통해 어텐션을 이해해보도록 하자.\n",
    "- seq2seq에서 사용되는 어텐션 중에서 닷-프로덕트 어텐션과 다른 어텐션의 차이는 주로 중간 수식의 차이로 메커니즘 자체는 거의 유사하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YOYHSHdDYFg5"
   },
   "source": [
    "<br>\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/22893/dotproductattention1_final.PNG)\n",
    "\n",
    "- 위 그림은 디코더의 세 번째 LSTM 셀에서 출력 단어를 예측할 때, 어텐션 메커니즘을 사용하는 모습을 보여준다.\n",
    "- 디코더의 첫 번째, 두 번째 LSTM 셀은 이미 어텐션 메커니즘을 통해 `je`와 `suis`를 예측하는 과정을 거쳤다고 가정한다.\n",
    "- 어텐션 메커니즘에 대해 상세히 설명하기 전에 위의 그림을 통해 전체적인 감만 우선 잡고 들어가보도록 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S4wJDhszYkZo"
   },
   "source": [
    "- 디코더의 세 번째 LSTM 셀은 출력 단어를 예측하기 위해서 인코더의 모든 입력 단어들의 정보를 다시 한번 참고하고자 한다.\n",
    "- 중간 과정에 대한 설명은 현재는 생략하고 여기서 주목할 것은 **인코더의 소프트맥스 함수**이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EV-z5736Yu_A"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 소프트맥스 함수를 통해 나온 결과값은 `I`, `am`, `a`, `student` 단어 각각이 출력 단어를 예측할 때 얼마나 도움이 되는 지의 정도를 수치화한 값이다.\n",
    "- 위의 그림에서는 빨간 직사각형의 크기로 소프트맥스 함수의 결과값의 크기를 표현했다.\n",
    "- 직사각형의 크기가 클 수록 도움이 되는 정도의 크기가 크다.\n",
    "- 각 입력 단어가 디코더의 예측에 도움이 되는 정도가 수치화하여 측정되면 이를 하나의 정보로 담아서 디코더로 전송된다.\n",
    "- 위의 그림에서는 초록색 삼각형이 이에 해당된다.\n",
    "- 결과적으로, 디코더는 출력 단어를 더 정확하게 예측할 확률이 높아진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxfETUH_Y3gw"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 이제 어텐션 메커니즘에 대한 전체적인 감을 잡았으면 어텐션 메커니즘에 대해 상세히 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cx7-csA_aT_e"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.1 어텐션 스코어(Attention Score)를 구한다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/22893/dotproductattention2_final.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aZtaDnnWaYpd"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.3.1.1 용어 정의\n",
    "\n",
    "- 1, 2, ..., t : 인코더의 시점(time step)\n",
    "- $h_1, h_2, \\dots, h_N$ : 인코더의 은닉 상태(hidden state)\n",
    "- $s_t$ : 디코더의 현재 시점(time step) t에서의 디코더의 은닉 상태(hidden state)\n",
    "- 또한 여기서는 인코더의 은닉 상태와 디코더의 은닉 상태의 차원이 같다고 가정\n",
    "- 위의 그림의 경우에는 인코더의 은닉 상태와 디코더의 은닉 상태가 동일하게 크기가 4이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r0M86B52bCZ0"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.3.1.2 디코더의 필요한 입력값\n",
    "\n",
    "- 어텐션 메커니즘의 첫 걸음인 어텐션 스코어(Attention score)에 대해서 배우기 전에, 이전 챕터에서 배웠던 \"디코더의 현재 시점 t에서 필요한 입력값\"을 다시 상기해보자.\n",
    "- 시점 t에서 출력 단어를 예측하기 위해서 디코더의 셀은 두 개의 입력값을 필요로 한다.\n",
    "  - 이전 시점인 t-1의 은닉 상태\n",
    "  - 이전 시점 t-1에 나온 출력 단어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yw3EGdoYcUa3"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.3.1.3 어텐션 값(Attention Value), $a_t$\n",
    "\n",
    "- 그런데 어텐션 메커니즘에서는 출력 단어 예측에 또 다른 값을 필요로 한다.\n",
    "- 바로 어텐션 값(Attention Value)이라는 새로운 값이다.\n",
    "- t번 째 단어를 예측하기 위한 어텐션 값을 $a_t$라고 정의한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rJ0NkHRLcjI5"
   },
   "source": [
    "- 어텐션 값이라는 새로운 개념이 등장한 만큼, 어텐션 값이 현재 시점 t에서의 출력 예측에 구체적으로 어떤게 반영되는 지는 뒤에서 설명한다.\n",
    "- 지금부터 배우는 모든 과정은 $a_t$를 구하기 위한 여정이다.\n",
    "- 그리고 그 여정의 첫 걸음은 바로 어텐션 스코어(Attention Score)를 구하는 일이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KND5co2odg7h"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.3.1.4 어텐션 스코어 (Attention score)\n",
    "\n",
    "- 어텐션 스코어란 현재 디코더의 시점 t에서 단어를 예측하기 위해, 인코더의 모든 은닉 상태 각각이 디코더의 현 시점의 은닉 상태 $s_t$와 얼마나 유사한 지를 판단하는 스코어 값이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UrnP2VqKdwdf"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.3.1.5 어텐션 스코어 계산\n",
    "\n",
    "- 닷-프로덕트 어텐션에서는 이 스코어 값을 구하기 위해 $s_t$를 전치(transpose)하고 각 은닉 상태와 내적(dot product)을 수행한다.\n",
    "- 즉, 모든 어텐션 스코어 값은 스칼라 값이다.\n",
    "- 예를 들어, $s_t$와 인코더의 `i`번 째 은닉 상태의 어텐션 스코어의 계산 방법은 아래와 같다.\n",
    "\n",
    "$\\qquad$ ![](https://wikidocs.net/images/page/22893/i%EB%B2%88%EC%A7%B8%EC%96%B4%ED%85%90%EC%85%98%EC%8A%A4%EC%BD%94%EC%96%B4_final.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z0cYoMY_eHlZ"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.3.1.6 어텐션 스코어 함수 정의\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "score(s_t, \\; h_i) = s_t^T \\, h_i\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qsRXyLgqeWiW"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.3.1.7 $e^t$ : 어텐션 스코어의 모음값\n",
    "\n",
    "- $s_t$와 인코더의 모든 은닉 상태의 어텐션 스코어의 모음값을 $e^t$라고 정의하겠다.\n",
    "- $e^t$의 수식은 다음과 같다.\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "e^t = \\left[ s_t^T \\, h1, \\dots, s_t^T \\, h_N \\right]\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9GPuyRw2eyOd"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.2 소프트맥스(softmax) 함수를 통해 어텐션 분포(Attention Distribution)를 구한다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/22893/dotproductattention3_final.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dk13_l8KfYo8"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.3.2.1 어텐션 분포(Attention Distribution)와 어텐션 가중치(Attention Weight)\n",
    "\n",
    "- $e^t$에 소프트맥스 함수를 적용하여, 모든 값을 합하면 1이 되는 확률 분포를 얻어낸다.\n",
    "- 이를 어텐션 분포(Attention Distribution)라고 한다.\n",
    "- 이 어텐션 분포의 각각의 값은 어텐션 가중치(Attention Weight)라고 한다.\n",
    "- 예를 들어 소프트맥스 함수를 적용하여 얻은 출력값인 `I`, `am`, `a`, `student`의 어텐션 가중치를 각각 `0.1`, `0.4`, `0.1`, `0.4`라고 하자.\n",
    "- 이들의 합은 1이다.\n",
    "- 위의 그림은 각 인코더의 은닉 상태에서의 어텐션 가중치의 크기를 직사각형의 크기를 통해 시각화하였다.\n",
    "-즉, 어텐션 가중치가 클수록 직사각형이 크다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kk_Lf_wYf8-u"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.3.2.2 어텐션 분포 식 정의\n",
    "\n",
    "- 디코더의 시점 t에서의 어텐션 가중치의 모음값인 어텐션 분포를 $\\alpha^t$이라고 할 때, $\\alpha^t$을 식으로 정의하면 다음과 같다.\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "\\alpha^t = softmax(e^t)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OFyRcm7-gPZ-"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.3 각 인코더의 어텐션 가중치와 은닉 상태를 가중합하여 어텐션 값(Attention Value)을 구한다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/22893/dotproductattention4_final.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h6dL8qdNgliS"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.3.3.1 어텐션 값(Attention Value) 계산\n",
    "\n",
    "- 이제 지금까지 준비해온 정보들을 하나로 합치는 단계이다.\n",
    "- 어텐션의 최종 결과값을 얻기 위해서 각 인코더의 은닉 상태와 어텐션 가중치값들을 곱하고, 최종적으로 모두 더한다.\n",
    "- 요약하면 **가중합(Weighted Sum)**을 한다고 말할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3mFF21_SgpRS"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.3.3.2 어텐션 값(Attention Value) 식 정의\n",
    "\n",
    "- 아래는 어텐션의 최종 결과, 즉 어텐션 함수의 출력값인 어텐션 값(Attention Value) $a_t$에 대한 식을 보여준다.\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "a_t = \\sum_{i=1}^N \\alpha_i^t \\, h_i\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N3bPFwFkgtOg"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.3.3.3 컨텍스트 벡터 (context vector)\n",
    "\n",
    "- 이러한 어텐션 값 $a_t$은 종종 인코더의 문맥을 포함하고 있다고 하여 **컨텍스트 벡터(context vector)**라고도 불린다.\n",
    "- 앞서 배운 가장 기본적인 seq2seq에서는 인코더의 마지막 은닉 상태를 컨텍스트 벡터라고 부르는 것과 대조된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eaubj4rShUjg"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.3.4 어텐션 값과 디코더의 t 시점의 은닉 상태를 연결(Concatenate)한다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/22893/dotproductattention5_final_final.PNG)\n",
    "\n",
    "- 이제 어텐션 함수의 최종값인 어텐션 값 $a_t$을 구했다.\n",
    "- 앞서 어텐션 메커니즘이 들어간 t시점의 은닉 상태를 구하는 방법의 식으로 다음과 같은 식을 소개한 바 있다.\n",
    "- 사실 어텐션 값이 구해지면 어텐션 메커니즘은 $a_t$를 $s_t$와 결합(concatenate)하여 하나의 벡터로 만드는 작업을 수행한다.\n",
    "- 이를 $v_t$라고 정의해보자.\n",
    "- 그리고 이 $v_t$를 $\\hat{y}$ 예측의 연산의 입력으로 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PAFgGi35hxvi"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.4 다양한 종류의 어텐션(Attention)\n",
    "\n",
    "- 앞서 seq2seq + 어텐션(attention) 모델에 쓰일 수 있는 다양한 어텐션 종류가 있지만, 닷-프로덕트 어텐션과 다른 어텐션들의 차이는 **중간 수식의 차이**라고 언급한 바 있다.\n",
    "- 여기서 말하는 중간 수식은 **어텐션 스코어 함수**를 말한다.\n",
    "- 위에서 배운 어텐션이 닷-프로덕트 어텐션인 이유는 어텐션 스코어를 구하는 방법이 내적이였기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r880YpVCiuxQ"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 어텐션 스코어를 구하는 방법은 여러 가지가 제시되어 있다.\n",
    "- 현재 제시된 여러 종류의 어텐션 스코어 함수는 다음과 같다.\n",
    "\n",
    "| 이름            | 스코어 함수                                                  |\n",
    "| :-------------- | :----------------------------------------------------------- |\n",
    "| $dot$           | $score(st, \\, hi) = s_t^T \\, h_i$                            |\n",
    "| $scaled \\; dot$ | $score(st, \\, hi) = \\frac{s_t^T \\, h_i}{\\sqrt{n}}$           |\n",
    "| $general$       | $score(st, \\, hi) = s_t^T \\, W_a \\, h_i$<br /> - 단, $W_a$는 학습 가능한 가중치 행렬 |\n",
    "| $concat$        | $score(st, \\, hi) = W_a^T \\, tanh(W_b \\, \\left[ s_t \\, ; \\, h_i \\right])$ |\n",
    "| $location−base$ | $\\alpha_t = softmax \\left( W_a \\, s_t \\right)$<br />- $\\alpha_t$ 산출 시에 $s_t$만 사용하는 방법 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3L1QPjYA-MYw"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.5 어텐션의 발전\n",
    "\n",
    "- 지금까지 seq2seq에서 성능을 향상시켜주기 위한 기법인 어텐션에 대해서 알아봤다.\n",
    "- 어텐션은 처음에는 RNN 기반의 seq2seq의 성능을 보정하기 위한 목적으로 소개되었다.\n",
    "- 하지만, 현재에 이르러서는 어텐션 스스로가 기존의 seq2seq를 대체하는 방법이 되어가고 있다.\n",
    "- 이에 대해서는 다음 챕터인 **트랜스포머(Transformer)** 챕터에서 더 자세히 배워보도록 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xf588n7Z_8O-"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.6 참고 링크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pAW8cJYtANie"
   },
   "source": [
    "### 1.6.1 어텐션을 소개한 논문\n",
    "\n",
    "- [https://arxiv.org/pdf/1409.0473.pdf](https://arxiv.org/pdf/1409.0473.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YCQR2f57ARa-"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.6.2 추천하는 참고 자료\n",
    "\n",
    "- [http://docs.likejazz.com/attention/](http://docs.likejazz.com/attention/)\n",
    "- [https://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.2015/slides/lec14.neubig.seq_to_seq.pdf](https://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.2015/slides/lec14.neubig.seq_to_seq.pdf)\n",
    "- [https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)\n",
    "- [https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3](https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ch14_v01_Attention-Mechanism.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
