{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5OgcY64BGTZ"
   },
   "source": [
    "# Ch14. 어텐션 메커니즘 (Attention Mechanism)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "viayvURqBOLU"
   },
   "source": [
    "# v02. 텍스트 요약 (Text Summarization with Attention mechanism)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "amUZBu3VBXFs"
   },
   "source": [
    "- 텍스트 요약은 상대적으로 큰 원문을 핵심 내용만 간추려서 상대적으로 작은 요약문으로 변환하는 것을 말한다.\n",
    "- 읽는 사람이 시간을 단축해서 내용을 빠르게 이해할 수 있다는 점에서 글을 많이 쓰는 사람들에게는 꼭 필요한능력 중 하나일 것이다.\n",
    "- 그런데 만약 기계가 이를 자동으로 해줄 수만 있다면 얼마나 좋을까?\n",
    "- 이번 챕터에서는 그 중 한 가지 방법인 seq2seq를 구현해본다.\n",
    "- 그리고 어텐션 메커니즘(attention mechanism)을 적용해보자.\n",
    "\n",
    "> 이번 챕터는 시퀀스-투-시퀀스(Sequence-to-Sequence, seq2seq) 챕터를 선행하는 것이 좋다. (모델을 설계하는 코드가 거의 동일)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_hMKirWrHwWj"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 2.1 텍스트 요약 (Text Summarization)\n",
    "\n",
    "- 텍스트 요약은 크게 다음 2가지로 나뉜다.\n",
    "  1. 추출적 요약 (extractive summarization)\n",
    "  2. 추상적 요약 (abstractive summarization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q1pLhQAAH7K4"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.1.1 추출적 요약 (extractive summarization)\n",
    "\n",
    "- 추출적 요약은 원문에서 중요한 핵심 문장 또는 단어구를 몇 개 뽑아서 이들로 구성된 요약문을 만드는 방법이다.\n",
    "- 그렇기 때문에 추출적 요약의 결과로 나온 요약문의 문장이나 단어구들은 전부 원문에 있는 문장들이다.\n",
    "- 추출적 요약의 대표적인 알고리즘으로 머신 러닝 알고리즘인 **텍스트랭크(TextRank)**가 있다.\n",
    "- [해당 링크](https://summariz3.herokuapp.com/)에서 텍스트랭크로 구현된 세 줄 요약기를 시험해볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0cWcRmEGIi6j"
   },
   "source": [
    "- 위 링크로 이동하여 인터넷 뉴스나 가지고 있는 글들을 복사 + 붙여넣기하여 결과를 확인해보자.\n",
    "- 세 개의 문장은 전부 원문에 존재하던 문장들이다.\n",
    "- 이 방법의 단점이라면, 이미 존재하는 문장이나 단어구로만 구성하므로 모델의 언어 표현 능력이 제한된다는 점이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iNnAXUukJDwH"
   },
   "source": [
    "- 그렇다면 마치 사람처럼 원문에 없던 단어나 문장을 사용하면서 핵심만 간추려서 표현하는 요약 방법은 없을까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5sE5yDMJJJvX"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.1.2 추상적 요약 (abstractive summarization)\n",
    "\n",
    "- 추상적 요약은 원문에 없던 문장이라도 핵심 문맥을 반영한 새로운 문장을 생성해서 원문을 요약하는 방법이다.\n",
    "- 마치 사람이 요약하는 것 같은 방식인데, 당연히 추출적 요약보다는 난이도가 높다.\n",
    "- 이 방법은 주로 인공 신경망을 사용하며 대표적인 모델로 seq2seq가 있다.\n",
    "- 이 방법의 단점이라면 seq2seq와 같은 인공 신경망들은 기본적으로 **지도 학습**이라는 점이다.\n",
    "- 다시 말해 추상적 요약을 인공 신경망으로 훈련하기 위해서는 '원문' 뿐만 아니라 '실제 요약문'이라는 레이블 데이터가 있어야 한다.\n",
    "- 그렇기 때문에 데이터를 구성하는 것 자체가 하나의 부담이다.\n",
    "- 이번 챕터에서는 이미 공개된 데이터를 사용해서 추상적 요약을 실습해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aRbZGooaJcLe"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 2.2 아마존 리뷰 데이터에 대한 이해\n",
    "\n",
    "- 이번 챕터에서 사용할 데이터는 아마존 리뷰 데이터이다.\n",
    "- 아래의 링크에서 데이터를 다운로드 한다.\n",
    "- [https://www.kaggle.com/snap/amazon-fine-food-reviews](https://www.kaggle.com/snap/amazon-fine-food-reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DiHBPnEUJk-u"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.2.1 필요 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bk_5iMfLMsJr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "07i4K_muM8rR"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.2.2 데이터 로드하기\n",
    "\n",
    "- `Reviews.csv` 파일을 불러와 데이터프레임에 저장한다.\n",
    "- 이 데이터는 실제로는 약 56만 개의 샘플을 가지고 있다.\n",
    "- 하지만 여기서는 간단히 10만 개의 샘플만 사용한다.\n",
    "- 이는 `pd.read_csv()`의 `nrows`의 인자로 10만이라는 숫자를 적어주면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "9e_TAmWbRoWL",
    "outputId": "cba13f27-405a-407d-acb4-06ab63865bfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "bEv1JkHuRrea",
    "outputId": "0dfbb964-9350-4017-c422-0fda5017b656"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 리뷰 개수 :  100000\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/datasets/amazon-fine-food-reviews/Reviews.csv\",\n",
    "                   nrows=100000)\n",
    "print(\"전체 리뷰 개수 : \", (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BFRZ454-UFlp"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 5개의 샘플만 출력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "id": "JdPg4tS3ULG9",
    "outputId": "b5f17b33-c14e-4fe4-98f8-2bdcfdd46ef8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  ...                                               Text\n",
       "0   1  ...  I have bought several of the Vitality canned d...\n",
       "1   2  ...  Product arrived labeled as Jumbo Salted Peanut...\n",
       "2   3  ...  This is a confection that has been around a fe...\n",
       "3   4  ...  If you are looking for the secret ingredient i...\n",
       "4   5  ...  Great taffy at a great price.  There was a wid...\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QzxhRjXoULw9"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.2.3 필요한 데이터 분리\n",
    "\n",
    "- 5개의 샘플을 출력해보면 `Id`, `ProductId`, `UserId`, `ProfileName`, `HelpfulnessNumerator`, `HelpfulnessDenominator`, `Score`, `Time`, `Summary`, `Text`이라는 10개의 열이 존재함을 알 수 있다.\n",
    "- 그런데 사실 이 중 필요한 열은 `Text`열과 `Summary`열 뿐이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e7nFOqLfUgBD"
   },
   "source": [
    "- `Text`열과 `Summary`열만을 분리하고, 다른 열들은 데이터에서 제외시켜서 재저장한다.\n",
    "- 그리고 5개의 샘플을 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "9-hCkeWVUyDr",
    "outputId": "d6f3b004-02cc-40b8-d628-8ece88e441ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>Not as Advertised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>Cough Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>Great taffy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Summary\n",
       "0  I have bought several of the Vitality canned d...  Good Quality Dog Food\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...      Not as Advertised\n",
       "2  This is a confection that has been around a fe...  \"Delight\" says it all\n",
       "3  If you are looking for the secret ingredient i...         Cough Medicine\n",
       "4  Great taffy at a great price.  There was a wid...            Great taffy"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['Text', 'Summary']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jT4cook6U0-c"
   },
   "source": [
    "<br>\n",
    "\n",
    "- `Text`열이 원문이고, `Summary`열이 `Text`열에 대한 요약이다.\n",
    "- 다시 말해 모델은 `Text`(원문)으로부터 `Summary`(요약)을 예측하도록 훈련된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ChVMbCYfVBZ7"
   },
   "source": [
    "- 랜덤으로 샘플 몇 가지를 더 출력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "jQI3vBSpVEb7",
    "outputId": "920b92fa-68b3-4506-9712-6507a291a1fe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33041</th>\n",
       "      <td>My kids don't like the taste so i have been dr...</td>\n",
       "      <td>taste bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34545</th>\n",
       "      <td>Perfect food for the Shar-Pei breed ... after ...</td>\n",
       "      <td>Natural Balance Food is great!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13143</th>\n",
       "      <td>I am a coffee lover and quite picky about my c...</td>\n",
       "      <td>Complex, European, flavorful coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49032</th>\n",
       "      <td>Bought for 1 year old Maltese~I like the idea ...</td>\n",
       "      <td>good idea but not for my dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8202</th>\n",
       "      <td>the product was exactly what was described.our...</td>\n",
       "      <td>exactly what i ordered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89778</th>\n",
       "      <td>I have two small dogs who are very picky eater...</td>\n",
       "      <td>Two paws up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38849</th>\n",
       "      <td>I can't say I'd recommend this coffee.  If not...</td>\n",
       "      <td>Vending machine coffee tastes better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46376</th>\n",
       "      <td>I've been eating better for a year and lost 70...</td>\n",
       "      <td>I love this stuff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50832</th>\n",
       "      <td>I'm not a coffee snob but I do enjoy high qual...</td>\n",
       "      <td>Good, but not what I expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21145</th>\n",
       "      <td>I have two dogs and they both love this it. I'...</td>\n",
       "      <td>My pups love it!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text                               Summary\n",
       "33041  My kids don't like the taste so i have been dr...                             taste bad\n",
       "34545  Perfect food for the Shar-Pei breed ... after ...        Natural Balance Food is great!\n",
       "13143  I am a coffee lover and quite picky about my c...   Complex, European, flavorful coffee\n",
       "49032  Bought for 1 year old Maltese~I like the idea ...          good idea but not for my dog\n",
       "8202   the product was exactly what was described.our...                exactly what i ordered\n",
       "89778  I have two small dogs who are very picky eater...                           Two paws up\n",
       "38849  I can't say I'd recommend this coffee.  If not...  Vending machine coffee tastes better\n",
       "46376  I've been eating better for a year and lost 70...                     I love this stuff\n",
       "50832  I'm not a coffee snob but I do enjoy high qual...         Good, but not what I expected\n",
       "21145  I have two dogs and they both love this it. I'...                      My pups love it!"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t_LOnwZMVFdc"
   },
   "source": [
    "- 원문은 꽤 긴 반면에, `Summary`에는 3~4개의 단어만으로 구성된 경우도 많아 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PNrPkX-RVOED"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.2.4 데이터 정제하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kcMFwSBPVYXO"
   },
   "source": [
    "#### 2.2.4.1 중복 데이터 제거\n",
    "\n",
    "- 데이터에 중복 샘플이 있는 지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "dZ-LqQXWVcQy",
    "outputId": "2e910d81-32b7-4e5c-fab3-1d1378f2d65f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 88426\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 72348\n"
     ]
    }
   ],
   "source": [
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['Text'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['Summary'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HYm_7jqHVdfq"
   },
   "source": [
    "- 전체 데이터는 10만개의 샘플이 존재하지만, 실제로는 꽤 많은 원문이 중복되어 중복을 배제한 유일한 원문의 개수는 88,426개이다.\n",
    "- 중복 샘플이 무려 약 1,200개나 있다는 의미이다.\n",
    "- `Summary`는 중복이 더 많지만, 원문은 다르더라도 짧은 문장인 요약은 내용이 겹칠 수 있음을 가정하고 일단 중복 제거를 하지 않는다.\n",
    "- `Summary`의 길이 분포는 뒤에서 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zkv3EPJgVoMK"
   },
   "outputs": [],
   "source": [
    "# Text 열에서 중복인 내용이 있다면 중복 제거\n",
    "data.drop_duplicates(subset=[\"Text\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JwUlMgOMV2RC",
    "outputId": "67bd8b1c-cf8d-4057-a7c5-c926369291ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 :  88426\n"
     ]
    }
   ],
   "source": [
    "print(\"전체 샘플수 : \", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oe4wBFw5WAJS"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2.2.4.2 결측값 제거\n",
    "\n",
    "- 이제 Null 샘플이 존재하는 지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "ohAM9UIBWGER",
    "outputId": "b85f7d58-0158-4874-e38a-d34cf5bc6be9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text       0\n",
      "Summary    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8642a-QMWIEJ"
   },
   "source": [
    "- `Summary`에서 1개의 Null 샘플이 남아 있다.\n",
    "- 이를 제거해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nX1TWYXIWMm5",
    "outputId": "4cb811fe-742e-4336-b7e5-97864d1d579b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 :  88425\n"
     ]
    }
   ],
   "source": [
    "# Null 값을 가진 샘플 제거\n",
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플 수 : ', len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yoZdnOgKWTMp"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2.2.4.3 단어 정규화 사전 생성\n",
    "\n",
    "- 지금까지는 불필요한 샘플의 수를 줄이기 위한 정제 과정이였다.\n",
    "- 이제 샘플 내부를 전처리해야 한다.\n",
    "- 단어 정규화와 불용어 제거를 위해 각각의 참고 자료가 필요하다.\n",
    "- 동일한 의미를 가졌지만 스펠링이 다른 단어들을 정규화하기 위한 사전을 만든다.\n",
    "- 이 사전은 [해당 링크](https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python)를 참고하여 만들어진 사전이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C1Z3cL7HWuzL"
   },
   "outputs": [],
   "source": [
    "# 전처리 함수 내 사용\n",
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \n",
    "                \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\", \n",
    "                \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \n",
    "                \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \n",
    "                \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \n",
    "                \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\n",
    "                \"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \n",
    "                \"i'll\": \"i will\", \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \n",
    "                \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \n",
    "                \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \n",
    "                \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\n",
    "                \"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \n",
    "                \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \n",
    "                \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \n",
    "                \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \n",
    "                \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \n",
    "                \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \n",
    "                \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \n",
    "                \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \n",
    "                \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \n",
    "                \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\n",
    "                \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \n",
    "                \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \n",
    "                \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \n",
    "                \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \n",
    "                \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \n",
    "                \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \n",
    "                \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \n",
    "                \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \n",
    "                \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \n",
    "                \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \n",
    "                \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \n",
    "                \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\", \n",
    "                \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \n",
    "                \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nOjrE-qJXILb"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2.2.4.4 불용어 정의\n",
    "\n",
    "- NLTK의 불용어를 저장하고 개수를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "FQ--vov4XaAu",
    "outputId": "9c45280b-ee14-41fe-99f1-569a9122015c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "wV_hORkMXRDX",
    "outputId": "9c4d7f15-4bb0-4f98-92de-fcf658a9b0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 :  179\n"
     ]
    }
   ],
   "source": [
    "# NLTK의 불용어\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print('불용어 개수 : ', len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "UNk2M3UlXX73",
    "outputId": "95d4ed6f-3a67-4e99-8626-beef15f65a93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'here', \"wouldn't\", 'own', 'we', 'from', 'it', \"shan't\", \"you've\", 'very', 'll', 'couldn', 'doesn', 'will', 'few', 'these', 'is', 'those', \"that'll\", 'their', 'she', 'no', 'ma', \"she's\", 'while', 'between', 'nor', 'off', 'out', 'you', 'a', 'other', 'd', 'weren', \"weren't\", 'm', 'and', 'my', 'he', 'any', 'are', 'down', 'been', 'shouldn', 'which', 'what', 'hers', \"shouldn't\", 'wouldn', 'with', 're', \"won't\", 'on', \"hadn't\", 'hasn', 'they', 'up', 'did', \"you'll\", 'him', 'don', 'his', 'through', 'wasn', \"mightn't\", 'until', 'an', 's', 'the', 'himself', \"you'd\", 'y', 'but', \"it's\", 'at', 'yourselves', 'its', 'theirs', 'ours', 'hadn', 'can', 'some', 'didn', 'that', \"doesn't\", 'me', 'below', 'not', 'isn', 'for', 'against', 'have', 'into', \"isn't\", 'because', 'mightn', \"couldn't\", 'who', 'doing', 'about', \"hasn't\", 'were', 'them', 'should', 'most', 't', 'mustn', 'shan', 'won', \"should've\", \"mustn't\", 'am', 'ain', 'itself', 'during', 'same', 'or', 'under', 'had', 'haven', 'her', 'your', 'by', 'as', 'too', 'just', 'now', 'again', 'so', 'of', \"don't\", 'there', 'has', 'do', 'once', 'aren', 've', 'how', \"needn't\", 'such', 'i', 'all', 'to', 'over', 'be', 'more', 'this', \"didn't\", 'before', 'needn', 'our', 'only', \"haven't\", 'themselves', 'was', 'does', \"you're\", \"wasn't\", 'further', 'myself', 'both', 'in', 'then', 'each', 'than', 'above', 'when', 'herself', 'being', 'yours', 'where', 'having', \"aren't\", 'if', 'yourself', 'o', 'after', 'ourselves', 'whom', 'why'}\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fXqgDV0SXe0n"
   },
   "source": [
    "```\n",
    "{'does', 'himself', 't', 'mightn', 'most', \"mustn't\", 'those', 'couldn', 'any', 'too', \"wouldn't\", 'having', \n",
    "... 중략 ...\n",
    "'themselves', 'do', 'will', 'i', 'didn', 'our', 'or', 'we', 'than', 'for', 'by', 'doesn', 'out', 'off', 've'}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "52aH-_BGXoif"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2.2.4.5 전처리 함수 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LCmb_ICOXuYx"
   },
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords = True):\n",
    "\n",
    "    # 텍스트 소문자화\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text\n",
    "    \n",
    "    # 괄호로 닫힌 문자열  제거 Ex) my husband (and myself) for => my husband for\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence)\n",
    "\n",
    "    # 쌍따옴표 \" 제거\n",
    "    sentence = re.sub('\"','', sentence)\n",
    "\n",
    "    # 약어 정규화\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")])\n",
    "\n",
    "    # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(r\"'s\\b\",\"\",sentence)\n",
    "\n",
    "    # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence)\n",
    "\n",
    "    # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence)\n",
    "\n",
    "    if remove_stopwords: # 불용어 제거 (Text)\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stop_words if len(word) > 1)\n",
    "    else: # 불용어 미제거 (Summary)\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IS29CFOpabke"
   },
   "source": [
    "- 여기서는 `Text` 열에서는 불용어를 제거하고, `Summary` 열에서는 불용어를 제거하지 않기로 결정했다.\n",
    "- `Summary`를 입력으로 할 때는 두번째 인자를 `0`으로 줘서 불용어를 제거하지 않는 버전을 실행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "00QXyGVfdVKd"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 임의의 `Text` 문장과 `Summary` 문장을 만들어 전처리 함수를 통한 전처리 후의 결과를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "13XQt2X0ddSM",
    "outputId": "75713ff5-afc9-4bd2-9771-1a4772e9f856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything bought great infact ordered twice third ordered wasfor mother father\n",
      "great way to start the day\n"
     ]
    }
   ],
   "source": [
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(preprocess_sentence(temp_text))\n",
    "print(preprocess_sentence(temp_summary, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o-gYpKnXdltW"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2.2.4.6 `Text` 열 전처리 수행\n",
    "\n",
    "- 우선 `Text` 열에 대해서 전처리를 수행한다.\n",
    "- 전처리 후에는 5개의 전처리된 샘플을 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "ddVwqIX3eWM6",
    "outputId": "3dae9381-53c6-46fb-c238-baf748f823be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
       " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
       " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
       " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
       " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text 열 전처리\n",
    "clean_text = []\n",
    "\n",
    "for s in data['Text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "\n",
    "clean_text[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "95QZeDUdeed8"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2.2.4.7 `Summary` 열 전처리 수행\n",
    "\n",
    "- 이제 `Summary` 열에 대해서 전처리를 수행한다.\n",
    "- 전처리 후에는 5개의 전처리된 샘플을 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "88vGloiNeo8L",
    "outputId": "e32efc66-d7c5-4ab1-a869-f72e51778c96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"http://www.amazon.com/gp/product/b007i7yygy/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['good quality dog food',\n",
       " 'not as advertised',\n",
       " 'delight says it all',\n",
       " 'cough medicine',\n",
       " 'great taffy']"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary 열 전처리\n",
    "clean_summary = []\n",
    "\n",
    "for s in data['Summary']:\n",
    "    clean_summary.append(preprocess_sentence(s, 0))\n",
    "\n",
    "clean_summary[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SUzQfghwexdU"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2.2.4.8 전처리 후 결과 데이터프레임에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "49YKVYNee5dS"
   },
   "outputs": [],
   "source": [
    "data['Text'] = clean_text\n",
    "data['Summary'] = clean_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BJwYRB1ee9hL"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2.2.4.9 전처리 과정 중 발생한 결측값 제거\n",
    "\n",
    "- 혹시 전처리 과정에서 빈 값이 생겼다면 Null 값으로 변경한 후에 Null 값을 가진 샘플이 생겼는 지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "YCpwQFr9fGJC",
    "outputId": "170d2a4a-413c-4f10-8510-e21b7a82c2bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text        0\n",
      "Summary    70\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 길이가 공백인 샘플을 NULL 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ndNd4o08fNz7"
   },
   "source": [
    "- `Summary` 열에서 70개의 샘플이 Null 값을 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a1SrJCoafSlC"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 이 샘플들을 제거해주고, 전체 샘플 수를 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "r40IkHB2fWA5",
    "outputId": "25f24ea1-26d2-4739-b28c-f1294cde48b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 :  88355\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플 수 : ', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KuLl-DGofbSK"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2.2.4.10 각 열의 데이터 길이 분포 확인\n",
    "\n",
    "- 이제 `Text` 열과 `Summary` 열에 대해서 길이 분포를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "db0vAcOyfkW6",
    "outputId": "d3c4d39c-0839-4d57-cb71-814e0a5785eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 2\n",
      "텍스트의 최대 길이 : 1235\n",
      "텍스트의 평균 길이 : 38.792428272310566\n",
      "========================================\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 28\n",
      "요약의 평균 길이 : 4.010729443721352\n"
     ]
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "text_len = [len(s.split()) for s in data['Text']]\n",
    "summary_len = [len(s.split()) for s in data['Summary']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print(\"=\" * 40)\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "QrfAF010fx8D",
    "outputId": "29cc1ef1-03d2-48b3-a980-32949d8494f7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title(\"Summary\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title(\"Text\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "hYF7ipjCf5vp",
    "outputId": "1d33c3e7-60bf-4697-95b8-b5554b4f7b18"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Summary\")\n",
    "plt.hist(summary_len, bins=40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YW5kldfyhS27"
   },
   "source": [
    "- 요약의 경우 대체적으로 15 이하의 길이를 가진다.\n",
    "- 평균 길이는 4이다.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "UBHM7qRAgWGK",
    "outputId": "86ca9aa7-7c3f-4841-bd7e-20f6d1503167"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Text\")\n",
    "plt.hist(text_len, bins=40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sC-Ev2IxgdY4"
   },
   "source": [
    "- 원문 텍스트는 대체적으로 100 이하의 길이를 가진다.\n",
    "- 또한 평균 길이는 38이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Op0OKkX8hQTv"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2.2.4.11 패딩 길이 결정\n",
    "\n",
    "- 여기서 패딩의 길이를 정한다.\n",
    "- 평균 길이보다는 크게 잡아 각각 `Text`는 50, `Summary`는 8로 결정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m8diLUcahow-"
   },
   "outputs": [],
   "source": [
    "text_max_len = 50\n",
    "summary_max_len = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YpT7td8KhrqX"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 50과 8이라는 이 두 길이가 얼마나 많은 샘플들의 길이보다 큰 지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7vW5PaBfh3Be"
   },
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt = 0\n",
    "    for s in nested_list:\n",
    "        if (len(s.split()) <= max_len):\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    print(\"전체 샘플 중 길이가 %s 이하인 샘플의 비율 : %s\" % (max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YIxQdn9uiG-2"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 우선 `Text` 열에 대해서 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_KVzLgz_iKLN",
    "outputId": "51ec65ff-0e31-4c36-a4ed-7dc782a1d4c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율 : 0.7745119121724859\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TstIOeROiNzd"
   },
   "source": [
    "- `Text` 열은 길이가 50 이하인 비율이 77%이다.\n",
    "- 약 23%의 샘플이 길이 50보다 크다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Im5yrxzFiTjM"
   },
   "source": [
    "<br>\n",
    "\n",
    "- `Summary` 열에 대해서 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "88N0oDCEiWes",
    "outputId": "7c0abd6e-4006-42fe-a371-90f28f914a35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 8 이하인 샘플의 비율 : 0.9424593967517402\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(summary_max_len, data['Summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ur6HfET6iZp8"
   },
   "source": [
    "- `Summary` 열은 길이가 8 이하인 경우가 94%이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YeW6pb6widV1"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2.2.4.12 패딩 길이보다 긴 데이터 제거\n",
    "\n",
    "- 여기서는 정해준 최대 길이보다 큰 샘플들을 제거한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "eA_0A1AEim00",
    "outputId": "c973a249-b2b2-43fe-fa76-89600ef99cd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 :  65818\n"
     ]
    }
   ],
   "source": [
    "data = data[data['Text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['Summary'].apply(lambda x: len(x.split()) <= summary_max_len)]\n",
    "\n",
    "print('전체 샘플 수 : ', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l8TCJbNri0QS"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2.2.4.13 정제 작업이 완료된 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "m0z9yvRYi4p3",
    "outputId": "70a41059-3102-4e80-ff54-78df1123e8b9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>good quality dog food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
       "      <td>not as advertised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>delight says it all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>cough medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>great taffy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Summary\n",
       "0  bought several vitality canned dog food produc...  good quality dog food\n",
       "1  product arrived labeled jumbo salted peanuts p...      not as advertised\n",
       "2  confection around centuries light pillowy citr...    delight says it all\n",
       "3  looking secret ingredient robitussin believe f...         cough medicine\n",
       "4  great taffy great price wide assortment yummy ...            great taffy"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hZrivtbJi5Ws"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2.2.4.14 요약(`Summary`) 데이터 시작 토큰 및 종료 토큰 추가\n",
    "\n",
    "- seq2seq 훈련을 위해서는 디코더의 예측 대상에 시작 토큰과 종료 토큰을 추가할 필요가 있다.\n",
    "- 시작 토큰을 `sostoken`, 종료 토큰은 `eostoken`이라 명명하고 앞, 뒤로 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "qUfZMQxAjO6i",
    "outputId": "9afed184-20e4-47ee-a667-f7af790fd416"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>sostoken good quality dog food eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
       "      <td>sostoken not as advertised eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>sostoken delight says it all eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>sostoken cough medicine eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>sostoken great taffy eostoken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                                  Summary\n",
       "0  bought several vitality canned dog food produc...  sostoken good quality dog food eostoken\n",
       "1  product arrived labeled jumbo salted peanuts p...      sostoken not as advertised eostoken\n",
       "2  confection around centuries light pillowy citr...    sostoken delight says it all eostoken\n",
       "3  looking secret ingredient robitussin believe f...         sostoken cough medicine eostoken\n",
       "4  great taffy great price wide assortment yummy ...            sostoken great taffy eostoken"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰 추가\n",
    "data['Summary'] = data['Summary'].apply(lambda x : \"sostoken \" + x + \" eostoken\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m5qJnCd2jcvL"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2.2.4.15 정제 작업이 완료된 데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QakI9XWUji5L"
   },
   "outputs": [],
   "source": [
    "Text_data = list(data['Text'])\n",
    "Summary_data = list(data['Summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "np2eGAigjpEM"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.2.5 데이터의 분리\n",
    "\n",
    "- 훈련 데이터와 테스트 데이터를 분리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "pkvAKyK0jtvy",
    "outputId": "26cf45a4-055c-4ea3-de0a-4b8299e7b1e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 52654\n",
      "훈련 레이블의 개수 : 52654\n",
      "테스트 데이터의 개수 : 13164\n",
      "테스트 레이블의 개수 : 13164\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Text_data, Summary_data,\n",
    "                                                    test_size=0.2, random_state=0, shuffle=True)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(X_train))\n",
    "print('훈련 레이블의 개수 :',len(y_train))\n",
    "print('테스트 데이터의 개수 :',len(X_test))\n",
    "print('테스트 레이블의 개수 :',len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DcK77fdJj6gL"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.2.6 정수 인코딩\n",
    "\n",
    "- 이제 기계가 텍스트를 숫자로 처리할 수 있도록 훈련 데이터와 테스트 데이터에 정수 인코딩을 수행해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szFOdaoikIdZ"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2.2.6.1 원문(`Text`) 데이터의 단어 집합(vocabulary) 생성\n",
    "\n",
    "- 훈련 데이터에 대해서 단어 집합(vocabulary)을 만들어보자.\n",
    "- 우선, 원문에 해당되는 `X_train`에 대해서 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PwadW1UZkQx5"
   },
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer()\n",
    "src_tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AXHwNnGTkXuR"
   },
   "source": [
    "- 이제 단어 집합이 생성되는 동시에 각 단어에 고유한 정수가 부여되었다.\n",
    "- 이는 `src_tokenizer.word_index`에 저장되어져 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KK4Kj-1fkepp"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2.2.6.2 등장 빈도수가 낮은 단어 배제\n",
    "\n",
    "- 여기서는 빈도수가 낮은 단어들은 자연어 처리에서 배제하고자 한다.\n",
    "- 등장 빈도수가 7회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는 지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8ipbb2Akn8h"
   },
   "outputs": [],
   "source": [
    "threshold = 7\n",
    "\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수 총합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    if (value < threshold): # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "Yti5jIsZlOSO",
    "outputId": "66b8dc3e-be92-47ba-c3de-3f1d44aa0e7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 31940\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 23707\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 8233\n",
      "단어 집합에서 희귀 단어의 비율: 74.22354414527238\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.3949897589412323\n"
     ]
    }
   ],
   "source": [
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGThPzPOlQZ4"
   },
   "source": [
    "- 등장 빈도가 threshold` 값인 7회 미만. 즉, 6회 이하인 단어들은 단어 집합에서 무려 70% 이상을 차지한다.\n",
    "- 하지만, 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 적은 수치인 3.39%밖에 되지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h5FzzfnNlc0A"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 여기서는 등장 빈도가 6회 이하인 단어들은 정수 인코딩 과정에서 배제시키고자 한다.\n",
    "- 위에서 이를 제외한 단어 집합의 크기를 8,233으로 계산했는데, 저자는 깔끔한 값을 선호하여 이와 비슷한 값으로 단어 집합의 크기를 8000으로 제한하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P3nMs5h4ljfg"
   },
   "outputs": [],
   "source": [
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab)\n",
    "src_tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2l_ZoynQlwHg"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2.2.6.3 원문(`Text`) 데이터 정수 시퀀스 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cAibAQk_l-H7"
   },
   "outputs": [],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "X_train = src_tokenizer.texts_to_sequences(X_train)\n",
    "X_test = src_tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "SV_HlH-kmWFx",
    "outputId": "4a05ba14-dc3a-4e37-fbd7-f942d0c63215"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4256, 611, 816, 4477, 528, 1540, 32, 45, 4, 79, 2281, 234, 19, 1157, 2923, 948, 1122, 996, 2, 153, 10, 43], [204, 15, 154, 51, 259, 60, 73, 24, 49, 17, 886, 259, 2, 29, 209, 14, 504, 2081, 420, 13, 86, 64, 22, 2464, 134, 14, 504, 86], [112, 1570, 2, 1771, 185, 39, 505, 112, 283], [296, 105, 496, 834, 69, 103, 334, 5082, 2294, 765, 7, 908, 585, 1489, 351, 5265, 100, 75, 1908, 137, 141, 585, 864, 5083, 89, 830, 564, 1772, 305, 254, 1541, 97, 247, 2, 1600, 2100, 92, 2645], [54, 1247, 806, 5, 497, 479, 46, 236, 1218, 381, 5, 3879, 3880, 172, 479, 46, 1247]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OusO3-IVmYIm"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2.2.6.4 요약(`Summary`) 데이터 단어 집합(vocabulary) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c09bCM42mgfi"
   },
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3b1U-GV2msjO"
   },
   "source": [
    "- 이제 단어 집합이 생성되는 동시에 각 단어에 고유한 정수가 부여되었다.\n",
    "- 이는 `tar_tokenizer.word_index`에 저장되어져 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_abmlguVmxZN"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2.2.6.5 등장 빈도수가 낮은 단어 배제\n",
    "\n",
    "- 등장 빈도수가 6회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Fzdfgy9m2MF"
   },
   "outputs": [],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "waHmOGP4m5Dt",
    "outputId": "60083aa1-2f0d-4795-9688-a4a5bd0f0216"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 10498\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 8126\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 2372\n",
      "단어 집합에서 희귀 단어의 비율: 77.40522004191274\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 4.833194065065198\n"
     ]
    }
   ],
   "source": [
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DXEmRSF6m6M1"
   },
   "source": [
    "- 등장 빈도가 5회 이하인 단어들은 단어 집합에서 약 77%를 차지한다.\n",
    "- 하지만, 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 매우 적은 수치인 4.83%밖에 되지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r9uMkFqTnG01"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 이 단어들은 정수 인코딩 과정에서 배제시키도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oKddgvOjnKOF"
   },
   "outputs": [],
   "source": [
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab)\n",
    "tar_tokenizer.fit_on_texts(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fg6wxKObnWZ9"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2.2.6.6 요약(`Summary`) 데이터 정수 시퀀스 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UBey3P33nb4E"
   },
   "outputs": [],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "y_train = tar_tokenizer.texts_to_sequences(y_train)\n",
    "y_test = tar_tokenizer.texts_to_sequences(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Vo1xkAuanmeM",
    "outputId": "f2b12b74-daba-4ebd-99e9-7c9330289f03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 805, 2], [1, 7, 298, 138, 86, 2], [1, 25, 745, 2], [1, 488, 39, 22, 30, 12, 2], [1, 15, 16, 238, 84, 35, 12, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9xw7Kd1Dnn7M"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.2.7 빈 샘플(empty samples) 제거\n",
    "\n",
    "- 전체 데이터에서 빈도수가 낮은 단어가 삭제되었다는 것은 빈도수가 낮은 단어만으로 구성되었던 샘플들은 이제 빈(empty) 샘플이 되었다는 것을 의미한다.\n",
    "- 이 현상은 길이가 상대적으로 길었던 원문(`Text`)의 경우에는 문제가 별로 없겠지만, 애초에 평균 길이가 4밖에 되지 않았던 요약문(`Summary`)의 경우에는 이 현상이 굉장히 두드러졌을 가능성이 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mybzHeLHoEMD"
   },
   "source": [
    "- 요약문에서 길이가 0이 된 샘플들의 인덱스를 받아오자.\n",
    "- 주의할 점은 요약문에는 `sostoken`과 `eostoken`이 추가된 상태이고, 이 두 토큰은 모든 샘플에서 등장하므로 빈도수가 샘플수와 동일하여 단어 집합 제한에도 삭제 되지 않는다.\n",
    "- 그래서 이제 길이가 `0`이 된 요약문의 실질적 길이는 `2`이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "INVIRNq6oT6b"
   },
   "outputs": [],
   "source": [
    "drop_train = [index for index, sentence in enumerate(y_train) if len(sentence) == 2]\n",
    "drop_test = [index for index, sentence in enumerate(y_test) if len(sentence) == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eK-rozVoogPf"
   },
   "source": [
    "- 훈련 데이터와 테스트 데이터에 대해서 요약문의 길이가 `2`인 경우의 인덱스를 각각 `drop_train`과 `drop_test`에 저장하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FDeFWxQYol1y"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 삭제 전의 훈련 데이터와 테스트 데이터의 개수를 출력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "Uh_a5TtaopE7",
    "outputId": "5b2c9a3d-d7b8-4839-9061-16df1afeba4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 52654\n",
      "훈련 레이블의 개수 : 52654\n",
      "테스트 데이터의 개수 : 13164\n",
      "테스트 레이블의 개수 : 13164\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 개수 :', len(X_train))\n",
    "print('훈련 레이블의 개수 :',len(y_train))\n",
    "print('테스트 데이터의 개수 :',len(X_test))\n",
    "print('테스트 레이블의 개수 :',len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7CJ52UxMoqtz"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 삭제 후의 개수는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "UEsrvsg7ouSK",
    "outputId": "181edda7-c62b-4d49-8a29-afc4c6e22534"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 51404\n",
      "훈련 레이블의 개수 : 51404\n",
      "테스트 데이터의 개수 : 12813\n",
      "테스트 레이블의 개수 : 12813\n"
     ]
    }
   ],
   "source": [
    "X_train = np.delete(X_train, drop_train, axis=0)\n",
    "y_train = np.delete(y_train, drop_train, axis=0)\n",
    "X_test = np.delete(X_test, drop_test, axis=0)\n",
    "y_test = np.delete(y_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(X_train))\n",
    "print('훈련 레이블의 개수 :',len(y_train))\n",
    "print('테스트 데이터의 개수 :',len(X_test))\n",
    "print('테스트 레이블의 개수 :',len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3WSpl6SRo2WK"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.2.8 패딩 하기\n",
    "\n",
    "- 훈련 데이터와 테스트 데이터에 대해서 패딩 작업을 수행한다.\n",
    "- 이미 앞서 정해둔 최대 길이를 넘는 샘플들은 제외했기 때문에 따로 길이 분포를 재확인하지는 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7qbH8LWHpByy"
   },
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=text_max_len, padding='post')\n",
    "X_test = pad_sequences(X_test, maxlen=text_max_len, padding='post')\n",
    "\n",
    "y_train = pad_sequences(y_train, maxlen=summary_max_len, padding='post')\n",
    "y_test = pad_sequences(y_test, maxlen=summary_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X8UlQKuzpTwS"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 2.3 seq2seq + attention으로 요약 모델 설계 및 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I5wssoGtpaT0"
   },
   "source": [
    "### 2.3.1 필요한 도구들 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "brWfgKf7pdrk"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n6maXrmPuCfN"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.3.2 인코더 설계\n",
    "\n",
    "- 인코더는 LSTM 층을 3개 쌓는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "id": "YWYfmmxsuIEh",
    "outputId": "def33771-34fa-4e82-e736-5ec1f7ba4071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-QfT9En9u2wc"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.3.3 디코더 설계 (출력층 제외)\n",
    "\n",
    "- 디코더를 설계한다.\n",
    "- 단, 출력층은 제외하고 설계한다.\n",
    "- 디코더의 설계는 인코더와 사실상 동일하지만 초기 상태(`initial_state`)를 인코더의 상태로 주어야 하는 것에 주의해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "QsQX6FWYvI__",
    "outputId": "ca9dd000-000e-4efd-994a-f293bfbdf209"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "# 디코더\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb = Embedding(tar_vocab, embedding_dim)(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ti_i3l5yvm8J"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.3.4 디코더의 출력층 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nGkqrPscvvSj"
   },
   "outputs": [],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A4KQF_c8v7tO"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.3.5 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "sQ2O-xLGv-bW",
    "outputId": "9a804a26-0977-487e-e01e-b05aeed0cc4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 2000)   514000      lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,633,104\n",
      "Trainable params: 3,633,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4toL3kYwD0G"
   },
   "source": [
    "- 총 3,633,104개의 매개변수를 가진 seq2seq 모델이 설계된다.\n",
    "- 지금까지의 모델 설계는 앞서 seq2seq 챕터에서 배웠던 내용과 동일하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0J2hyzgKwQcW"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.3.6 어텐션 메커니즘이 결합된 출력층 설계\n",
    "\n",
    "- 이번 챕터에서는 어텐션 메커니즘을 사용할 예정이다.\n",
    "- 그러므로 위에서 설계한 출력층을 사용하지 않고, 어텐션 메커니즘이 결합된 새로운 출력층을 설계할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YZ5-VVKCwfc0"
   },
   "source": [
    "- 어텐션 함수를 직접 작성하지 않고 이미 깃허브에 공개된 함수를 사용할 것이다.\n",
    "- 아래의 코드를 통해 `attention.py` 파일을 다운로드하고, `AttentionLayer`를 임포트한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JoK7Ky0lwos1",
    "outputId": "6943b736-0d72-4a57-98cd-ed2965c827a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('attention.py', <http.client.HTTPMessage at 0x7f5b8817dac8>)"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/layers/attention.py\", filename=\"attention.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EgUWXuwtws-N"
   },
   "outputs": [],
   "source": [
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dlZDVCwtwxhM"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 어텐션 메커니즘을 이용해 디코더의 출력층을 새롭게 설계한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FJ4TnP9ew3nM"
   },
   "outputs": [],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IU-0su_qxXMv"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.3.7 어텐션 메터니즘이 결합된 출력층이 적용된 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "CLowSrdRxbt3",
    "outputId": "579579a7-1203-4e5b-c4ee-4e6c413018df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 2000)   1026000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,276,432\n",
      "Trainable params: 4,276,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ke7u1Rr0xkZc"
   },
   "source": [
    "- 총 4,276,432개의 파라미터를 가진 모델이 설계된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A2iPc_BIxpTr"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.3.8 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rMSW21Rpxro-"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZzuhIPfoxwfL"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.3.9 조기 종료 조건 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X5BKtb9fx2Cu"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pjqmZohxx7K6"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.3.10 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 630
    },
    "colab_type": "code",
    "id": "taD6o_Jgx9_d",
    "outputId": "bfdc1f7a-67ac-4ba3-a562-a522022de898"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "201/201 [==============================] - 191s 951ms/step - loss: 3.0338 - val_loss: 2.7245\n",
      "Epoch 2/50\n",
      "201/201 [==============================] - 191s 950ms/step - loss: 2.6700 - val_loss: 2.5566\n",
      "Epoch 3/50\n",
      "201/201 [==============================] - 191s 949ms/step - loss: 2.5055 - val_loss: 2.4284\n",
      "Epoch 4/50\n",
      "201/201 [==============================] - 192s 954ms/step - loss: 2.3663 - val_loss: 2.3327\n",
      "Epoch 5/50\n",
      "201/201 [==============================] - 191s 953ms/step - loss: 2.2644 - val_loss: 2.2548\n",
      "Epoch 6/50\n",
      "201/201 [==============================] - 190s 945ms/step - loss: 2.1909 - val_loss: 2.2142\n",
      "Epoch 7/50\n",
      "201/201 [==============================] - 192s 954ms/step - loss: 2.1348 - val_loss: 2.1906\n",
      "Epoch 8/50\n",
      "163/201 [=======================>......] - ETA: 35s - loss: 2.0887"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-4241facecc7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m                   \u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                   \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    850\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train, y_train[:,:-1]], y_train.reshape(y_train.shape[0], y_train.shape[1], 1)[:,1:] \\\n",
    "                  ,epochs=50, callbacks=[es], batch_size = 256, validation_data=([X_test, y_test[:,:-1]], \\\n",
    "                  y_test.reshape(y_test.shape[0], y_test.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gQUqMYmsykyM"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.3.11 손실 시각화\n",
    "\n",
    "- 학습 과정에서 기록된 훈련 데이터의 손실과 테스트 데이터의 손실 히스토리를 시각화해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6uPwKdS2lYr"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-F_3l6-C2wbO"
   },
   "source": [
    "- 테스트 데이터의 손실이 지속적으로 줄어들다가 어느 순간부터 정체하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pU4k8-bW20aL"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 2.4 seq2seq + attention으로 요약 모델 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2WVdOfSb28NH"
   },
   "source": [
    "### 2.4.1 사전 생성\n",
    "\n",
    "- 테스트를 위해 필요한 3개의 사전을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bKGj-f6n3Bi6"
   },
   "outputs": [],
   "source": [
    "# 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "src_index_to_word = src_tokenizer.index_word\n",
    "\n",
    "# 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index\n",
    "\n",
    "# 요약 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "STpGXgtG3T9m"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.4.2 테스트 단계의 seq2seq 모델 설계\n",
    "\n",
    "- seq2seq는 훈련 단계와 테스트 단계의 동작이 다르다.\n",
    "- 그러므로 테스트 단계의 모델을 별도로 다시 설계해줄 필요가 있다.\n",
    "- 다시 새로운 seq2seq 모델을 만들어보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rcbqxVGF3g6q"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2.4.2.1 테스트 단계의 인코더 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CEaAc7ey3kmt"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs,\n",
    "                      outputs=[encoder_outputs, state_h, state_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzQqNZeC3uOg"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 2.4.2.2 테스트 단계의 디코더 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVA0QluN3wit"
   },
   "outputs": [],
   "source": [
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size, ))\n",
    "decoder_state_input_c = Input(shape=(hidden_size, ))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs) # TODO: dec_emb_layer 수정 필요\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용.\n",
    "# 이는 뒤의 함수 decode_sequence()에 구현\n",
    "\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2,\n",
    "                                                    initial_state=[decoder_state_input_h,\n",
    "                                                                   decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hF2z9LEN4eOu"
   },
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input,\n",
    "                                            decoder_outputs2])\n",
    "\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2,\n",
    "                                                          attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "deocder_outputs2 = decoder_softmax_layer(decoder_inf_concat)\n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
    "                                          decoder_state_input_h,\n",
    "                                          decoder_state_input_c],\n",
    "                      [decoder_outputs2] + [state_h2, state_c2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bt8hhKPj5KiG"
   },
   "source": [
    "- 테스트 단계를 위한 모델이 완성되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vl3hQVpn5OF2"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.4.3 테스트를 위한 함수 설계\n",
    "\n",
    "- 테스트를 위해 사용되는 함수 `decode_sequence`를 설계한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aJ3zH8QG5Wf7"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1, 1, tar_vocab_size)) # TODO: tar_vocab_size 수정 필요\n",
    "    target_seq[0, 0, tar_to_index['\\t']] = 1. # TODO: tar_to_index 수정 필요, \\t -> sostoken으로 수정 필요\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        # 이전 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index] # index_to_tar 수정 필요\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # <EOS>에 도달하거나 최대 길이를 넘으면 중단\n",
    "        if (sampled_char == '\\n' or len(decoded_sentence) > max_tar_len): # \\n -> eostoken 수정 필요, max_tar_len 수정 필요\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # 상태 없데이트\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jSo3D2-V6_2z"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.4.4 정수 시퀀스를 텍스트 시퀀스로 만드는 함수 설계\n",
    "\n",
    "- 테스트 단계에서 원문과 실제 요약문, 예측 요약문을 비교하기 위해 정수 시퀀스를 텍스트 시퀀스로 만드는 함수를 설계한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6lmrgQ87Lba"
   },
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp = ''\n",
    "    for i in input_seq:\n",
    "        if (i != 0):\n",
    "            temp = temp + src_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "USdhaVCj7aSq"
   },
   "outputs": [],
   "source": [
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp = ''\n",
    "    for i in input_seq:\n",
    "        if ( (i != 0 and 1 != target_word_index['sostoken']) and i != target_word_index['eostoken'] ):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BA5avkXK7xdf"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.4.5 테스트 샘플 중 500번부터 1000번까지 테스트 실시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Au7FK64e71pQ"
   },
   "outputs": [],
   "source": [
    "for i in range(500, 1000):\n",
    "    print('원문 : ', seq2text(X_test[i]))\n",
    "    print('실제 요약문 : ', seq2summary(y_test[i]))\n",
    "    print('예측 요약문 : ', decode_sequence(X_test[i].reshape(1, text_max_len)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-vv1YNEZ8Gr0"
   },
   "source": [
    "- 실제 요약문과 완전히 똑같지 않으면서 원문의 맥락을 잘 잡아서 예측된 요약문들이 존재하는 것을 확인할 수 있다."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Ch14_v02_Text-Summarization-with-Attention-mechanism.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
