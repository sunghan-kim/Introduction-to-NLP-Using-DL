{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QYCf8vu0WSmw"
   },
   "source": [
    "# Ch15. 트랜스포머(Transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qMPbFDB6WajT"
   },
   "source": [
    "# v01. 트랜스포머 (Transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m2VMPPklWc2K"
   },
   "source": [
    "- 이번 챕터를 정확히 이해하기 위해서는 어텐션 챕터에 대한 사전 이해가 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cr0m9PosWipK"
   },
   "source": [
    "- 트랜스포머(Transformer)는 2017년 구글이 발표한 논문인 \"Attention is all you need\"에서 나온 모델이다.\n",
    "- 기존의 seq2seq의 구조인 인코더-디코더를 따르면서도, 논문의 이름처럼 어텐션(Attention)만으로 구현한 모델이다.\n",
    "- 이 모델은 RNN은 쓰지 않고 어텐션만을 사용하여 인코더-디코더 구조를 만들어 **학습 속도가 무척 빠르다**는 장점을 갖고 있으며 성능도 RNN보다 우수하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LvaorvGMXLq5"
   },
   "source": [
    "- 이번 챕터의 코드는 텐서플로우 2.0 공식 문서를 참고했다.\n",
    "- 아래의 모든 실습은 아래의 코드가 우선 수행되었다고 가정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "colab_type": "code",
    "id": "607QHLW8XTI5",
    "outputId": "15f8aab9-811b-425b-af22-0e75dda932a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.9.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (19.3.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (2.21.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.3.1.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (4.38.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.12.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.16.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.18.2)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.21.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (3.10.0)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.8)\n",
      "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.51.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow_datasets) (46.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FnYobzKgXVdx"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pjLqO6V3Xm4w"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.1 기존의 seq2seq 모델의 한계\n",
    "\n",
    "- 트랜스포머에 대해서 배우기 전에 기존의 seq2seq를 상기해보자.\n",
    "- 기존의 seq2seq 모델은 인코더-디코더 구조로 구성되어져 있다.\n",
    "  - 인코더 : 입력 시퀀스를 하나의 벡터 표현으로 압축한다.\n",
    "  - 디코더 : 이 벡터 표현을 통해서 출력 시퀀스를 만들어낸다.\n",
    "- 하지만 이러한 구조는 인코더가 입력 시퀀스를 하나의 벡터로 압축하는 과정에서 입력 시퀀스의 정보가 일부 손실된다는 단점이 있다.\n",
    "- 이를 보정하기 위해 어텐션이 사용되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FcUNLCirXqKj"
   },
   "source": [
    "- 그런데 어텐션을 RNN의 보정을 위한 용도가 아니라 아예 어텐션으로 인코더와 디코더를 만들어보면 어떨까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29zMuVZzaXSM"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.2 트랜스포머(Transformer)의 주요 하이퍼 파라미터\n",
    "\n",
    "- 시작에 앞서 트랜스포머의 하이퍼파라미터를 정의하고자 한다.\n",
    "- 각 하이퍼파라미터의 의미에 대해서는 뒤에서 설명한다.\n",
    "- 여기서는 트랜스포머에는 이러한 하이퍼파라미터가 존재한다는 정도로만 이해해보도록 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QDv1aFSKanDT"
   },
   "source": [
    "- 아래에서 정의하는 수치값은 트랜스포머를 제안한 논문에서 사용한 수치값이다.\n",
    "- 하이퍼파라미터는 사용자가 모델 설계시 임의로 변경할 수 있는 값들이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RM_e7t3naw5K"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.2.1 $d_{model}$ = 512\n",
    "\n",
    "- 트랜스포머의 인코더와 디코더에서의 정해진 입력과 출력의 크기를 의미한다.\n",
    "- 즉, 임베딩 벡터의 크기 또한 $d_{model}$이다.\n",
    "- 각 인코더와 디코더가 다음 층의 인코더와 디코더로 값을 보낼 때에도 이 크기를 가진다.\n",
    "- 논문에서는 512의 크기를 가졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uNtHmN6rbD18"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.2.2 $\\text{num_layers}$ = 6\n",
    "\n",
    "- 트랜스포머에서 하나의 인코더와 디코더를 층으로 생각했을 때, 트랜스포머 모델에서 인코더와 디코더가 총 몇 층으로 구성되었는 지를 의미한다.\n",
    "- 논문에서는 인코더와 디코더를 각각 총 6개 쌓았다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "daz65CL9bd9a"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.2.3 $\\text{num_heads}$ = 8\n",
    "\n",
    "- 트랜스포머에서는 어텐션을 사용할 때, 1번 하는 것보다 여러 개로 분할해서 병렬로 어텐션을 수행하고 결과값을 다시 하나로 합치는 방식을 택했다.\n",
    "- 이 때 이 병렬의 개수를 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M0TgCVFab_Mx"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.2.4 $d_{ff}$ = 2048\n",
    "\n",
    "- 트랜스포머 내부에는 피드 포워드 신경망이 존재한다.\n",
    "- 이 때 은닉층의 크기를 의미한다.\n",
    "- 피드 포워드 신경망의 입력층과 출력층의 크기는 $d_{model}$의 크기를 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RdjlrMtQclh4"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.3 트랜스포머 (Transformer)\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/31379/transformer1.PNG)\n",
    "\n",
    "- 트랜스포머는 RNN을 사용하지 않지만 기존의 seq2seq처럼 인코더에서 입력 시퀀스를 입력받고, 디코더에서 출력 시퀀스를 출력하는 인코더-디코더 구조를 유지하고 있다.\n",
    "- 다만 다른 점은 인코더와 디코더라는 단위가 N개 존재할 수 있다는 점이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BuoKUztvc5SP"
   },
   "source": [
    "- 이전 seq2seq 구조에서는 인코더와 디코더에서 각각 하나의 RNN이 t개의 시점(time-step)을 가지는 구조였다.\n",
    "- 하지만 이번에는 인코더와 디코더라는 단위가 N개로 구성되는 구조이다.\n",
    "- 트랜스포머를 제안한 논문에서는 인코더와 디코더의 개수($\\text{num_layers}$)를 각각 6개를 사용했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TwvOZ3CGdH3G"
   },
   "source": [
    "$\\quad$ ![](https://wikidocs.net/images/page/31379/transformer2.PNG)\n",
    "\n",
    "- 위의 그림은 인코더와 디코더가 6개씩 존재하는 트랜스포머의 구조를 보여준다.\n",
    "- 이 책에서는 인코더와 디코더가 각각 여러 개 쌓여있다는 의미를 사용할 때는 알파벳 `s`를 뒤에 붙여 `encoders`, `decoders`라고 표현하겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "csvK-Al8dcY5"
   },
   "source": [
    "$\\quad$ ![](https://wikidocs.net/images/page/31379/transformer4_final_final_final.PNG)\n",
    "\n",
    "- 위의 그림은 인코더로부터 정보를 전달받아 디코더가 출력 결과를 만들어내는 트랜스포머 구조를 보여준다.\n",
    "- 디코더는 마치 기존의 seq2seq 구조처럼 시작 심볼 `<sos>`를 입력으로 받아 종료 심볼 `<eos>`가 나올 때까지 연산을 진행한다.\n",
    "- 이는 RNN은 사용되지 않지만 여전히 인코더-디코더의 구조는 유지되고 있음을 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e19Fmn8Edw-n"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 이제 트랜스포머의 내부 구조를 조금씩 확대해가는 방식으로 트랜스포머를 이해해보자.\n",
    "- 우선 인코더와 디코더의 구조를 이해하기 전에 **트랜스포머의 입력**에 대해서 이해해보겠다.\n",
    "- 트랜스포머의 인코더와 디코더는 단순히 각 단어의 임베딩 벡터들을 입력받는 것이 아니라 **임베딩 벡터에서 조정된 값을 입력 받는다.**\n",
    "- 이에 대해서 알아보기 위해 입력 부분을 확대해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "azvqSiNufOk9"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.4 포지셔널 인코딩 (Positional Encoding)\n",
    "\n",
    "- 트랜스포머의 내부를 이해하기 전에 우선 **트랜스포머의 입력**에 대해서 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T9pxBE6Lf_i6"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.4.1 위치 정보(position information)의 필요성\n",
    "\n",
    "- RNN이 자연어 처리에서 유용했던 이유는 단어의 위치에 따라 단어를 순차적으로 입력 받아서 처리하는 RNN의 특성으로 인해 각 단어의 위치 정보(position information)를 가질 수 있다는 점에 있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WtB_Z0ZlgEoq"
   },
   "source": [
    "- 하지만 트랜스포머는 단어 입력을 순차적으로 받는 방식이 아니므로 단어의 위치 정보를 다른 방식으로 알려줄 필요가 있다.\n",
    "- 트랜스포머는 위치 정보를 얻기 위해서 **각 단어의 임베딩 벡터에 위치 정보들을 더하여 모델의 입력으로 사용**한다.\n",
    "- 이를 **포지셔널 인코딩(positional encoding)**이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zZxHbD8EgX3y"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.4.2 포지셔널 인코딩 과정\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/31379/transformer5_final_final.PNG)\n",
    "\n",
    "- 위의 그림은 입력으로 사용되는 임베딩 벡터들이 트랜스포머의 입력으로 사용되기 전에 포지셔널 인코딩값이 더해지는 것을 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ohFP1HrKg9NJ"
   },
   "source": [
    "- 임베딩 벡터가 인코더의 입력으로 사용되기 전에 포지셔널 인코딩값이 더해지는 과정을 시각화하면 아래와 같다.\n",
    "\n",
    "$\\qquad$ ![](https://wikidocs.net/images/page/31379/transformer6_final.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eNV2g1pShFKY"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.4.3 포지셔널 인코딩값 산출 방법\n",
    "\n",
    "- 포지셔널 인코딩 값들은 어떤 값이기에 위치 정보를 반영해줄 수 있을까?\n",
    "- 트랜스포머는 위치 정보를 가진 값을 만들기 위해서 아래의 두 개의 함수를 사용한다.\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "PE_{(pos, \\, 2i)} = sin \\left( pos \\, / \\, 10000^{2i / d_{model}} \\right)\n",
    "$\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "PE_{(pos, \\, 2i+1)} = cos \\left( pos \\, / \\, 10000^{2i / d_{model}} \\right)\n",
    "$\n",
    "\n",
    "- 사인 함수와 코사인 함수의 그래프를 상기해보면 요동치는 값의 형태를 생각해볼 수 있다.\n",
    "- 트랜스포머는 사인 함수와 코사인 함수의 값을 임베딩 벡터에 더해줌으로서 단어의 순서 정보를 더해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8MRoE8OkiDv0"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.4.4 임베딩 벡터와 포지셔널 인코딩의 덧셈\n",
    "\n",
    "- 그런데 위의 두 함수에는 다음과 같은 생소한 변수들이 있다.\n",
    "  - $pos$\n",
    "  - $i$\n",
    "  - $d_{model}$\n",
    "- 위의 함수를 이해하기 위해서는 위에서 본 임베딩 벡터와 포지셔널 인코딩의 덧셈은 사실 **임베딩 벡터가 모여 만들어진 문장 벡터 행렬과 포지셔널 인코딩 행렬의 덧셈 연산**을 통해 이루어진다는 점을 이해해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13-nsn3JicIY"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.4.5 포지셔널 인코딩값 산출 함수 변수 설명\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/31379/transformer7.PNG)\n",
    "\n",
    "- $pos$는 입력 문장에서의 임베딩 벡터의 위치를 나타낸다.\n",
    "- $i$는 임베딩 벡터 내의 차원의 인덱스를 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BTUd-uiti3Pl"
   },
   "source": [
    "- 위의 식에 따르면 임베딩 벡터 내의 각 차원의 인덱스가 \n",
    "  - 짝수인 경우(= $(pos, \\, 2i)$) $\\rightarrow$ 사인 함수의 값 사용\n",
    "  - 홀수인 경우(= $(pos, \\, 2i+1)$) $\\rightarrow$ 코사인 함수의 값 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9VGzArS6jk6O"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 또한 위의 식에서 $d_{model}$은 트랜스포머의 모든 층의 출력 차원을 의미하는 트랜스포머의 하이퍼파라미터이다.\n",
    "- 앞으로 보게 될 트랜스포머의 각종 구조에서 $d_{model}$의 값이 계속해서 등장하는 이유이다.\n",
    "- 임베딩 벡터 또한 $d_{model}$의 차원을 가진다.\n",
    "- 위의 그림에서는 마치 4로 표현되었지만 실제 논문에서는 512의 값을 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A0m8ldUSj6HO"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.4.6 포지셔널 인코딩의 순서 정보 보존\n",
    "\n",
    "- 위와 같은 포지셔널 인코딩 방법을 사용하면 순서 정보가 보존된다.\n",
    "- 예를 들어 각 임베딩 벡터에 포지셔널 인코딩값을 더하면 같은 단어라고 하더라도 문장 내의 위치에 따라서 트랜스포머의 입력으로 들어가는 임베딩 벡터의 값이 달라진다.\n",
    "- 결국 트랜스포머의 입력은 순서 정보가 고려된 임베딩 벡터라고 보면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-EM6Q20UoItH"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.4.7 포지셔널 인코딩 코드 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dp3m2VeyoYwN"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RPVz1Jwcokxd"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                            np.arange(d_model)[np.newaxis, :],\n",
    "                            d_model)\n",
    "    \n",
    "    # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    \n",
    "    # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    return tf.cast(angle_rads, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xGly6MFxpJUf"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.4.8 포지셔널 인코딩 행렬 시각화\n",
    "\n",
    "- 50 x 128의 크기를 가지는 포지셔널 인코딩 행렬을 시각화하여 어떤 형태를 가지는 지 확인해보자.\n",
    "- 이는 입력 문장의 단어가 50개이면서, 각 단어가 128차원의 임베딩 벡터를 가질 때 사용할 수 있는 행렬이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "wCr1QmcbpX6L",
    "outputId": "f12d3b7c-90c4-45b2-ea62-48c76994e83e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 128)\n"
     ]
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 128)\n",
    "print(pos_encoding.shape) # 크기 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "7pTnaCaapenT",
    "outputId": "1f3927f7-8329-48ce-b9c2-7f9e2a4e2392"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolormesh(pos_encoding, cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 128))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nfFSm_39pmt7"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.5 인코더\n",
    "\n",
    "- 트랜스포머의 입력에 대해서 이해하였으니 이제 인코더의 구조에 대해서 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "52ZpuxlIqW65"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.5.1 인코더의 개수\n",
    "\n",
    "- 트랜스포머는 기본적으로 $n$개의 인코더를 가진다고 가정한다.\n",
    "- 이는 하이퍼파라미터인 $\\text{num_layers}$을 의미한다.\n",
    "- 논문에서는 총 6개의 인코더를 사용하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "chji6VpOqZoh"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.5.2 인코더의 내부 구조\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/31379/transformer9.png)\n",
    "\n",
    "- 인코더를 하나의 층이라는 개념으로 생각한다면, 하나의 인코더 층은 크게 총 2개의 서브층(sublayer)으로 나뉘어진다.\n",
    "  - **셀프 어텐션**\n",
    "  - **피드 포워드 신경망**\n",
    "- 위의 그림에서는 **멀티 헤드 셀프 어텐션**과 **포지션 와이즈 피드 포워드 신경망**이라고 적혀있지만, 결국 이는 각각 어텐션과 피드 포워드 신경망을 여러 번 사용하였을 뿐이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vWUa6Cahq7vR"
   },
   "source": [
    "- 우선 멀티-헤드 어텐션에 대해서 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KfhmSZVLq-Ff"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.6 인코더의 멀티-헤드 어텐션\n",
    "\n",
    "- 트랜스포머에서는 셀프 어텐션이라는 어텐션 기법이 등장한다.\n",
    "- 앞서 배웠던 어텐션 함수에 대해서 복습하고, 셀프 어텐션이 앞서 배웠던 어텐션과 무엇이 다른 지 이해해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Aa7AycNarJ-4"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.6.1 셀프 어텐션의 의미와 이점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8oyd7FBsSZu"
   },
   "source": [
    "#### 1.6.1.1 어텐션\n",
    "\n",
    "- 어텐션 함수는 주어진 '쿼리(Query)'에 대해서 모든 '키(Key)'와의 유사도를 각각 구한다.\n",
    "- 그리고 구해낸 이 유사도를 가중치로 사용하여 키와 맵핑되어있는 각각의 '값(Value)'에 반영해준다.\n",
    "- 그리고 유사도가 반영된 '값(Value)'을 모두 가중합(=어텐션값)하여 리턴한다.\n",
    "\n",
    "$\\qquad$ ![](https://wikidocs.net/images/page/22893/%EC%BF%BC%EB%A6%AC.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y33jpMDispat"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.1.2 셀프 어텐션 (self-attention)\n",
    "\n",
    "- 어텐션 중에서는 셀프 어텐션(self-attention)이라는 것이 있다.\n",
    "- 단지 어텐션을 자기 자신에게 수행한다는 의미이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mNHDED53s1W1"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.1.3 셀프 어텐션을 위한 `Q`, `K`, `V`의 재정의\n",
    "\n",
    "- 앞서 배운 seq2seq에서 어텐션을 사용할 경우의 `Q`, `K`, `V`의 정의를 다시 생각해보자.\n",
    "\n",
    "```\n",
    "Q = Query : t 시점의 디코더 셀에서의 은닉 상태\n",
    "K = Keys : 모든 시점의 인코더 셀의 은닉 상태들\n",
    "V = Values : 모든 시점의 인코더 셀의 은닉 상태들\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zQOaroa6tDLN"
   },
   "source": [
    "- 그런데 사실 t 시점이라는 것은 계속 변화하면서 반복적으로 쿼리를 수행하므로 결국 전체 시점에 대해서 일반화를 할 수도 있다.\n",
    "\n",
    "```\n",
    "Q = Query : 모든 시점의 디코더 셀에서의 은닉 상태\n",
    "K = Keys : 모든 시점의 인코더 셀의 은닉 상태들\n",
    "V = Values : 모든 시점의 인코더 셀의 은닉 상태들\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WDEBmngJ5F2b"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 이처럼 기존에는 디코더 셀의 은닉 상태가 `Q`이고, 인코더 셀의 은닉 상태가 `K`라는 점에서 `Q`와 `K`가 서로 다른 값을 가지고 있었다.\n",
    "- 그런데 셀프 어텐션에서는 `Q`, `K`, `V`가 전부 동일하다.\n",
    "- 트랜스포머의 셀프 어텐션에서의 `Q`, `K`, `V`는 아래와 같다.\n",
    "\n",
    "```\n",
    "Q : 입력 문장의 모든 단어 벡터들\n",
    "K : 입력 문장의 모든 단어 벡터들\n",
    "V : 입력 문장의 모든 단어 벡터들\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qonSV-Pb5hW4"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.1.4 셀프 어텐션을 통해 얻을 수 있는 효과\n",
    "\n",
    "- 셀프 어텐션에 대한 구체적인 사항을 배우기 전에 셀프 어텐션을 통해 얻을 수 있는 효과에 대해서 먼저 이해해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V-SsFXSh54av"
   },
   "source": [
    "$\\quad$ ![](https://wikidocs.net/images/page/31379/transformer10.png)\n",
    "\n",
    "- 위의 그림은 트랜스포머에 대한 구글 AI 블로그 포스트에서 가져왔다.\n",
    "- 위의 예시 문장을 번역하면 아래와 같은 의미가 된다.\n",
    "\n",
    "> '그 동물은 길을 건너지 않았다. 왜냐하면 그것은 너무 피곤하였기 때문이다.'\n",
    "\n",
    "- 그런데 여기서 그것(`it`)에 해당하는 것은 과연 길(`street`)일까? 동물(`animal`)일까?\n",
    "- 우리는 피곤한 주체가 동물이라는 것을 아주 쉽게 알 수 있지만 기계는 그렇지 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JD059WPq6Yiw"
   },
   "source": [
    "- 하지만 셀프 어텐션은 입력 문장 내의 단어들끼리 유사도를 구하므로서 그것(`it`)이 동물(`animal`)과 연관되었을 확률이 높다는 것을 찾아낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kbEte0i26geO"
   },
   "source": [
    "- 기존의 seq2seq에서의 어텐션에서는 인코더 측의 문장과 디코더 측의 문장이라는 서로 다른 문장들의 단어들을 가지고 연관성을 찾아냈다.\n",
    "- 그렇기 때문에 위 정보는 기존의 seq2seq의 어텐션 구조로는 찾을 수 없던 정보이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "STdNN2rT6tR9"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 이제 셀프 어텐션의 개념을 알아보았으니, 트랜스포머에서의 셀프 어텐션의 메커니즘을 차근차근 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5mU6O9Kk608F"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.6.2 `Q`, `K`, `V` 벡터 얻기\n",
    "\n",
    "- 앞서 셀프 어텐션은 입력 문장의 단어 벡터들을 가지고 수행한다고 했다.\n",
    "- 사실 셀프 어텐션은 인코더의 초기 입력인 $d_{model}$의 차원을 가지는 단어 벡터들을 사용하여 셀프 어텐션을 수행하는 것이 아니다.\n",
    "- 우선 각 단어 벡터들로부터 `Q`벡터, `K`벡터, `V`벡터를 얻는 작업을 거친다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SsoLX8WZ7Sf3"
   },
   "source": [
    "- 이때 이 `Q`벡터, `K`벡터, `V`벡터들은 초기 입력인 $d_{model}$의 차원을 가지는 단어 벡터들보다 더 작은 차원을 가진다.\n",
    "- 논문에서는 $d_{model}$ = 512의 차원을 가졌던 각 단어 벡터들을 64의 차원을 가지는 `Q`벡터, `K`벡터, `V`벡터로 변환하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vgygL1el7p0U"
   },
   "source": [
    "- 64라는 값은 트랜스포머의 또 다른 하이퍼파라미터인 $\\text{num_heads}$로 인해 결정된다.\n",
    "- 트랜스포머는 $d_{model}$을 $\\text{num_heads}$로 나눈 값을 각 `Q`벡터, `K`벡터, `V`벡터의 차원으로 결정한다.\n",
    "- 논문에서는 $\\text{num_heads}$를 8로 하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nUPwiIB_8CVr"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 이제 그림을 통해 이해해보자.\n",
    "- 예를 들어 여기서 사용하고 있는 예문 중 `student`라는 단어 벡터를 `Q`, `K`, `V`의 벡터로 변환하는 과정을 보겠다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/31379/transformer11.PNG)\n",
    "\n",
    "- 기존의 벡터로부터 더 작은 벡터는 가중치 행렬을 곱하므로서 완성된다.\n",
    "- 각 가중치 행렬은 $d_{model} \\times \\left( d_{model} / \\text{num_heads} \\right)$의 크기를 가진다.\n",
    "- 이 가중치 행렬은 훈련 과정에서 학습된다.\n",
    "- 즉, 논문과 같이 $d_{model}$ = 512이고, $\\text{num_heads}$ = 8 이라면, 각 벡터에 3개의 서로 다른 가중치 행렬을 곱하고 64의 크기를 가지는 `Q`, `K`, `V` 벡터를 얻어낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uOJpGtwi8c1N"
   },
   "source": [
    "- 위의 그림은 단어 벡터 중 `student` 벡터로부터 `Q`, `K`, `V` 벡터를 얻어내는 모습을 보여준다.\n",
    "- 모든 단어 벡터에 위와 같은 과정을 거치면 `I`, `am`, `a`, `student`는 각각의 `Q`, `K`, `V` 벡터를 얻는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XJBFbNC9B24R"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.6.3 스케일드 닷-프로덕트 어텐션(Scaled dot-product Attention)\n",
    "\n",
    "- `Q`, `K`, `V` 벡터를 얻었다면 지금부터는 기존에 배운 어텐션 메커니즘과 동일하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bTw1b1KFB82k"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.3.1 메커니즘\n",
    "\n",
    "1. 각 `Q` 벡터는 모든 `K` 벡터에 대해서 어텐션 스코어를 구한다.\n",
    "2. 어텐션 분포를 구한 뒤에 이를 이용하여 모든 `V` 벡터를 가중합하여 어텐션 값 또는 컨텍스트 벡터를 구한다.\n",
    "3. 이를 모든 `Q` 벡터에 대해서 반복한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vDrglJZdCcFJ"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.3.2 다양한 종류의 어텐션 함수\n",
    "\n",
    "- 앞서 어텐션 챕터에서 어텐션 함수의 종류는 다양하다고 언급했다.\n",
    "  - $score(q, k) = q \\cdot k$  \n",
    "  : 내적만을 사용하는 어텐션 함수 (어텐션 챕터에서 사용)\n",
    "  - $score(q, k) = q \\cdot k / \\sqrt{n}$  \n",
    "  : 내적한 값을 특정값으로 나눠준 어텐션 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0VLUMGrpiHXq"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.3.3 스케일드 닷-프로덕트 어텐션 (Scaled dot-product Attention)\n",
    "\n",
    "- 트랜스포머에서는 어텐션 함수로 $score(q, k) = q \\cdot k / \\sqrt{n}$를 사용한다.\n",
    "- 이러한 함수를 사용하는 어텐션을 어텐션 챕터에서 배운 닷-프로덕트 어텐션(dot-product attention)에서 값을 스케일링하는 것을 추가하였다고 하여 **스케일드 닷-프로덕트 어텐션 (Scaled dot-product Attention)**라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y5vhhpRjifs6"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.3.4 어텐션 스코어 계산\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/31379/transformer13.PNG)\n",
    "\n",
    "- 우선 단어 `I`에 대한 `Q`벡터($Q_{\\text{I}}$)를 기준으로 살펴보자.\n",
    "- 지금부터 설명하는 과정은 다음 각각의 `Q`벡터들에 대해서도 모두 동일한 과정을 거친다.\n",
    "  - `am`에 대한 `Q`벡터 ($Q_{\\text{am}}$)\n",
    "  - `a`에 대한 `Q`벡터 ($Q_{\\text{a}}$)\n",
    "  - `student`에 대한 `Q`벡터 ($Q_{\\text{student}}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q6Pd_i6rpsRG"
   },
   "source": [
    "- 위의 그림은 단어 `I`에 대한 `Q` 벡터가 모든 `K` 벡터에 대해서 어텐션 스코어를 구하는 것을 보여준다.\n",
    "- 위의 128과 32는 저자가 임의로 가정한 수치이므로 신경쓰지 않아도 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZwCpBeHyuSp-"
   },
   "source": [
    "- 위의 그림에서 어텐션 스코어는 각각 단어 `I`가 단어 `I`, `am`, `a`, `student`와 얼마나 연관되어 있는 지를 보여주는 수치이다.\n",
    "- 트랜스포머에서는 두 벡터의 내적값을 스케일링 하는 값으로 `K` 벡터의 차원을 나타내는 $d_k$에 루트를 씌운 $\\sqrt{d_k}$를 사용하는 것을 택했다.\n",
    "- 앞서 언급하였듯이 논문에서 $d_k$는 $d_{model} / \\text{num_heads}$ 라는 식에 따라서 64의 값을 가진다.\n",
    "- 따라서 $\\sqrt{d_k}$는 8의 값을 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5B02IcWbu1DU"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.3.5 어텐션 분포 및 어텐션 값 계산\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/31379/transformer14_final.PNG)\n",
    "\n",
    "- 이제 어텐션 스코어에 소프트맥스 함수를 사용하여 어텐션 분포(Attention Distribution)을 구한다.\n",
    "- 그런 다음 각 $V$ 벡터와 가중합하여 어텐션 값(Attention Value)을 구한다.\n",
    "- 이를 단어 `I`에 대한 어텐션 값 또는 단어 `I`에 대한 컨텍스트 벡터(context vector)라고도 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EpUUkDlQvWxG"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.3.6 모든 `Q` 벡터에 대해 반복\n",
    "\n",
    "- 이제 `am`에 대한 `Q` 벡터, `a`에 대한 `Q` 벡터, `student`에 대한 `Q` 벡터에 대해서도 모두 동일한 과정을 반복하여 각각에 대한 어텐션 값을 구한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zLXnavvGvodB"
   },
   "source": [
    "- 그런데 한 가지 의문이 생긴다.\n",
    "- 굳이 이렇게 각 `Q` 벡터마다 일일히 따로 연산할 필요가 있을까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jLhZqK4MvuV5"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.6.4 행렬 연산으로 일괄 처리하기\n",
    "\n",
    "- 사실 각 단어에 대한 `Q`, `K`, `V` 벡터를 구하고 스케일드 닷-프로덕트 어텐션을 수행하였던 위의 과정들은 벡터 연산이 아니라 **행렬 연산**을 사용하면 일괄 계산이 가능하다.\n",
    "- 지금까지 벡터 연산으로 설명하였던 이유는 이해를 돕기 위한 과정이고, 실제로는 행렬 연산으로 구현된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r2ryCL6fwCeC"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.4.1 행렬 연산을 통해 `Q`, `K`, `V` 행렬 얻기\n",
    "\n",
    "- 위의 과정을 벡터가 아닌 행렬 연산으로 이해해보자.\n",
    "- 우선, 각 단어 벡터마다 일일히 가중치 행렬을 곱해주는 것이 아니라 문장 행렬에 가중치 행렬을 곱하여 `Q` 행렬, `K` 행렬, `V` 행렬을 구한다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/31379/transformer12.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2cb1FZGdwUqw"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.4.2 행렬 연산을 통해 어텐션 스코어 행렬 구하기\n",
    "\n",
    "- 이제 행렬 연산을 통해 어텐션 스코어는 어떻게 구할 수 있을까?\n",
    "- 여기서 `Q` 행렬을 `K` 행렬을 전치한 행렬과 곱해준다고 해보자.\n",
    "- 이렇게 되면 각각의 단어의 `Q` 벡터와 `K` 벡터의 내적이 각 행렬의 원소가 되는 행렬이 결과로 나온다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/31379/transformer15.PNG)\n",
    "\n",
    "- 다시 말해 위의 그림의 결과 행렬의 값에 전체적으로 $\\sqrt{d_k}$를 나누어주면 이는 각 행과 열이 어텐션 스코어값을 가지는 행렬이 된다.\n",
    "  - 예를 들어 `I` 행과 `student` 열의 값은 `I`의 `Q` 벡터와 `student`의 `K` 벡터의 어텐션 스코어와 동일한 행렬이 된다.\n",
    "- 즉, 어텐션 스코어 행렬이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CY8wab8-1kPJ"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.4.3 어텐션 분포와 어텐션 값 행렬 구하기\n",
    "\n",
    "- 어텐션 스코어 행렬을 구하였다면 남은 것은 어텐션 분포를 구하고, 이를 사용하여 모든 단어에 대한 어텐션 값을 구하는 일이다.\n",
    "- 이는 간단하게 어텐션 스코어 행렬에 소프트맥스 함수를 사용하고, `V` 행렬을 곱하는 것으로 해결된다.\n",
    "- 이렇게 되면 각 단어의 어텐션 값을 모두 가지는 어텐션 값 행렬이 결과로 나온다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/31379/transformer16.PNG)\n",
    "\n",
    "- 위의 그림은 행렬 연산을 통해 모든 값이 일괄 계산되는 과정을 식으로 보여준다.\n",
    "- 해당 식은 실제 트랜스포머 논문에 기재된 아래의 수식과 정확하게 일치하는 식이다.\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "Attention(Q, \\, K, \\, V) = softmax \\left( \\frac{Q K^T}{\\sqrt{d_k}} \\right) \\, V\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G6dkOkes3e-X"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.4.4 행렬 연산에 사용된 행렬의 크기 정리\n",
    "\n",
    "- 위의 행렬 연산에 사용된 행렬의 크기를 모두 정리해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8VEK3TLc3qFE"
   },
   "source": [
    "<br>\n",
    "\n",
    "**1) 문장 행렬의 크기**\n",
    "\n",
    "- 우선 입력 문장의 길이를 `seq_len`이라고 해보자.\n",
    "- 그렇다면 문장 행렬의 크기는 다음과 같다.\n",
    "  - 문장 행렬의 크기 : $(\\text{seq_len}, \\, d_{model})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VXpC-IOTL-5Z"
   },
   "source": [
    "- 여기에 3개의 가중치 행렬을 곱해서 `Q`, `K`, `V` 행렬을 만들어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yb6ziCES4C-U"
   },
   "source": [
    "<br>\n",
    "\n",
    "**2) `Q`, `K`, `V` 행렬의 크기**\n",
    "\n",
    "- 우선 행렬의 크기를 정의하기 위해 행렬의 각 행에 해당되는 `Q`, `K`, `V` 벡터의 크기를 다음과 같다고 하자.\n",
    "  - `Q` 벡터의 크기 : $d_k$\n",
    "  - `K` 벡터의 크기 : $d_k$\n",
    "  - `V` 벡터의 크기 : $d_v$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m08CHDnw4g-t"
   },
   "source": [
    "- 그렇다면 `Q`, `K`, `V` 행렬의 크기는 다음과 같아야 한다.\n",
    "  - `Q` 행렬의 크기 : $(\\text{seq_len}, d_k)$\n",
    "  - `K` 행렬의 크기 : $(\\text{seq_len}, d_k)$\n",
    "  - `V` 행렬의 크기 : $(\\text{seq_len}, d_v)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sGUB21qHL0ti"
   },
   "source": [
    "<br>\n",
    "\n",
    "**3) 가중치 행렬의 크기**\n",
    "\n",
    "- 그렇다면 문장 행렬과 `Q`, `K`, `V` 행렬의 크기로부터 가중치 행렬의 크기 추정이 가능하다.\n",
    "  - $W^Q$의 크기 : $(d_{model}, d_k)$\n",
    "  - $W^K$의 크기 : $(d_{model}, d_k)$\n",
    "  - $W^V$의 크기 : $(d_{model}, d_v)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WZ50gQy9NaPa"
   },
   "source": [
    "<br>\n",
    "\n",
    "**4) $d_k$, $d_v$의 크기**\n",
    "\n",
    "- 단, 논문에서는 $d_k$와 $d_v$의 크기는 다음과 같이 동일하다.\n",
    "  - $d_k$의 크기 = $d_v$의 크기 = $d_{model}/\\text{num_heads}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1oMGFcPLN9mB"
   },
   "source": [
    "<br>\n",
    "\n",
    "**5) 어텐션 값 행렬 $a$의 크기**\n",
    "\n",
    "- 결과적으로 $softmax \\left( \\frac{Q K^T}{\\sqrt{d_k}} \\right) \\, V$ 식을 적용하여 나오는 어텐션 값 행렬 $a$의 크기는 다음과 같다.\n",
    "  - 어텐션 값 행렬 $a$의 크기 : $(\\text{seq_len}, d_v)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MNSI1eC4OTD2"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.6.5 스케일드 닷-프로덕트 어텐션 구현하기\n",
    "\n",
    "- 위 내용을 코드로 작성하면 아래와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7wHZ_ZniPwa9"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.5.1 `scaled_dot_product_attention()` 구현\n",
    "\n",
    "- `Q` 행렬과 `K` 행렬을 전치한 행렬을 곱하고, 소프트맥스 함수를 사용하여 어텐션 분포 행렬을 얻은 뒤에 `V` 행렬과 곱한다.\n",
    "- 코드에서 `mask`가 사용되는 if문은 아직 배우지 않은 내용으로 지금은 무시하고 넘어간다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nqBuv96qOaSe"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask): # Q 행렬, K 행렬, V 행렬, 마스크 수행 여부\n",
    "\n",
    "    # Q 행렬과 K 행렬을 곱한다. 즉, 어텐션 스코어 행렬을 얻는다.\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b = True)\n",
    "\n",
    "    # 스케일링\n",
    "    dk = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # 필요하다면 마스크를 수행한다.\n",
    "    # 해당 조건문이 어떤 의미인 지는 뒤에서 설명한다. (현재는 무시)\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # 소프트맥스 함수를 사용하여 어텐션 가중치들, 즉 어텐션 분포를 얻는다.\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # 어텐션 분포 행렬과 V 행렬을 곱하여 최종 결과를 얻는다.\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    # 최종 결과와 어텐션 분포 리턴\n",
    "    # 어텐션 분포 또한 리턴하는 이유는 아래에서 값을 출력해보며 함수 테스트를 위함\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t6Au5vKbPp8H"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.5.2 `scaled_dot_product_attention()` 테스트\n",
    "\n",
    "- `scaled_dot_product_attention()` 함수가 정상 작동하는 지 테스트를 해보도록 한다.\n",
    "- 우선 `temp_q`, `temp_k`, `temp_v`라는 임의의 `Query`, `Key`, `Value` 행렬을 만든다.\n",
    "- 이를 `scaled_dot_product_attention` 함수에 입력으로 넣어 함수가 리턴하는 값을 출력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0Z0uCLKQH7Q"
   },
   "outputs": [],
   "source": [
    "# 임의의 Query, Key, Value인 Q, K, V 행렬 생성\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Key : (4, 3)\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)\n",
    "\n",
    "# Value : (4, 2)\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)\n",
    "\n",
    "# Query : (1, 3)\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X4LkMz8UuanW"
   },
   "source": [
    "- 여기서 주목할 점은 `Query`에 해당하는 `temp_q`의 값 `[0, 10, 0]`은 `Key`에 해당하는 `temp_k`의 두 번째 값 `[0, 10, 0]`과 일치한다는 점이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RQbmjGCXxAj-"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 그렇다면 어텐션 분포와 어텐션 값은 어떤 값이 나올까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "UF4au2E2xEkn",
    "outputId": "ff30c5ca-e6b5-40d2-c017-fbce0ba2b2b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 함수 실행\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tEGHrxTpxRXZ"
   },
   "source": [
    "- `Query`는 4개의 `Key`값 중 두 번째 값과 일치하므로 어텐션 분포는 `[0, 1, 0, 0]`의 값을 가진다.\n",
    "- 결과적으로 `Value`의 두 번째 값인 `[10, 0]`이 출력되는 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mxkXITlNxqrW"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 이번에는 `Query`의 값만 다른 값으로 바꿔보고 함수를 실행해보자.\n",
    "- 이번에 사용할 `Query` 값 `[0, 0, 10]`은 `Key`의 세 번째 값과 네 번째 값 두 개의 값 모두와 일치하는 값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "qlVFgfph4TTd",
    "outputId": "803ba23a-516e-4bed-f664-47913269a6a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)\n",
    "\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "srEcSylN4fU7"
   },
   "source": [
    "- `Query`의 값은 `Key`의 세 번째 값과 네 번째 값 두 개의 값과 모두 유사하다는 의미에서 어텐션 분포는 `[0, 0, 0.5, 0.5]`의 값을 가진다.\n",
    "- 결과적으로 나오는 값 `[550, 5.5]`는 `Value`의 세 번째 값 `[100, 5]`에 `0.5`를 곱한 값과 네 번째 값 `[1000, 6]`에 `0.5`를 곱한 값의 원소별 합이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Exj3gBwUDl1"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 이번에는 하나가 아닌 3개의 `Query`의 값을 함수의 입력으로 사용해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "id": "gIvYxcXVUKbE",
    "outputId": "13391dd1-67da-419c-e02b-ae87ef7dc6f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Query : (3, 3)\n",
    "temp_q = tf.constant([[0,   0, 10],\n",
    "                      [0,  10,  0],\n",
    "                      [10, 10,  0]], dtype=tf.float32)\n",
    "\n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "\n",
    "print(temp_attn) # 어텐션 분포(어텐션 가중치의 나열)\n",
    "print(temp_out) # 어텐션 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AbIxapQEUixf"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.6.6 멀티 헤드 어텐션 (Multi-head Attention)\n",
    "\n",
    "- 앞서 배운 어텐션에서는 $d_{model}$의 차원을 가진 단어 벡터를 $\\text{num_heads}$로 나눈 차원을 가지는 `Q`, `K`, `V` 벡터로 바꾸고 어텐션을 수행했다.\n",
    "- 논문 기준으로는 512의 차원의 각 단어 벡터를 8로 나누어 64차원의 `Q`, `K`, `V` 벡터로 바꾸어서 어텐션을 수행한 셈이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ra1jQ9czki-a"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.6.1 차원을 축소시킨 벡터로 어텐션 수행한 이유\n",
    "\n",
    "- 이제 $\\text{num_heads}$의 의미와 왜 $d_{model}$의 차원을 가진 단어 벡터를 가지고 어텐션을 하지 않고 차원을 축소시킨 벡터로 어텐션을 수행했는 지 이해해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "elGGwLK2k70s"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.6.2 병렬 어텐션 수행\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/31379/transformer17.PNG)\n",
    "\n",
    "- 트랜스포머 연구진은 한 번의 어텐션을 하는 것보다 여러 번의 어텐션을 병렬로 사용하는 것이 더 효과적이라고 판단했다.\n",
    "- 그래서 $d_{model}$의 차원을 $\\text{num_heads}$개로 나누어 $d_{model} / \\text{num_heads}$의 차원을 가지는 `Q`, `K`, `V`에 대해서 $\\text{num_heads}$개의 병렬 어텐션을 수행한다.\n",
    "- 논문에서는 하이퍼파라미터인 $\\text{num_heads}$의 값을 8로 지정하였고, 8개의 병렬 어텐션이 이루어지게 된다.\n",
    "- 다시 말해 위에서 설명한 어텐션이 8개로 병렬로 이루어진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bb31czmmqHoi"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.6.3 어텐션 헤드\n",
    "\n",
    "- 이 때 각각의 어텐션 값 행렬을 **어텐션 헤드**라고 부른다.\n",
    "- 이 때 가중치 행렬 $W^Q$, $W^Q$, $W^Q$의 값은 8개의 어텐션 헤드마다 전부 다르다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JOi-5H8eqMYo"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.6.4 병렬 어텐션으로 얻을 수 있는 효과\n",
    "\n",
    "- 그리스 로마 신화에는 머리가 여러 개인 괴물 히드라나 케로베로스가 나온다.\n",
    "- 이 괴물들의 특징은 머리가 여러 개이기 때문에 여러 시점에서 상대방을 볼 수 있다는 것이다.\n",
    "- 이렇게 되면 시각에서 놓치는 게 별로 없을테니 이런 괴물들에게 기습을 하는 것이 굉장히 힘이 들 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zs5k1e84qk54"
   },
   "source": [
    "- 멀티 헤드 어텐션도 똑같다.\n",
    "- 어텐션을 병렬로 수행하여 다른 시각으로 정보들을 수집하겠다는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZtG7pvgHqoRV"
   },
   "source": [
    "- 예를 들어, 아래의 예문을 상기해보자.\n",
    "\n",
    "> \"그 동물은 길을 건너지 않았다. 왜냐하면 그것은 너무 피곤하였기 때문이다.\"\n",
    "\n",
    "- 단어 그것(`it`)이 쿼리였다고 해보자.\n",
    "- 즉, `it`에 대한 `Q` 벡터로부터 다른 단어와의 연관도를 구하였을 때\n",
    "  - 첫 번째 어텐션 헤드는 '그것(`it`)'과 '동물(`animal`)'의 연관도를 높게 봄\n",
    "  - 두 번째 어텐션 헤드는 '그것(`it`)'과 '피곤하였기 때문이다(`tired`)'의 연관도를 높게 봄\n",
    "- 이는 각 어텐션 헤드는 전부 다른 시각에서 보고있기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oZMo8rgArQvw"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.6.5 어텐션 헤드 연결(concatenate)\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/31379/transformer18_final.PNG)\n",
    "\n",
    "- 병렬 어텐션을 모두 수행했다면 모든 어텐션 헤드를 연결(concatenate)한다.\n",
    "- 모두 연결된 어텐션 헤드 행렬의 크기는 $(\\text{seq_len}, d_model)$가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bp4zYWRIw-E-"
   },
   "source": [
    "- 지금까지 그림에서는 책의 지면상의 한계로 4차원을 $d_{model}$ = 512($2^9$)로 표현하고, 2차원을 $d_v$ = 64($2^6$)로 표현해왔다.\n",
    "- 그렇기 때문에 위의 그림의 행렬의 크기에 혼동이 올 수 있다.\n",
    "- 8개의 어텐션 헤드의 연결(concatenate) 과정의 이해를 위해 이번 행렬만 예외로 위와 같이 $d_{model}$의 크기를 $d_v$의 8배인 16차원으로 표현하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-88xuo7oxMQU"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.6.6 멀티-헤드 어텐션의 최종 결과물\n",
    "\n",
    "- 아래의 그림에서는 다시 $d_{model}$를 4차원으로 표현한다.\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/31379/transformer19.PNG)\n",
    "\n",
    "- 어텐션 헤드를 모두 연결한 행렬은 또 다른 가중치 행렬 $W^o$을 곱한다.\n",
    "- 이렇게 나온 결과 행렬이 멀티-헤드 어텐션의 최종 결과물이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n7git19ryZH1"
   },
   "source": [
    "- 위의 그림은 어텐션 헤드를 모두 연결한 행렬이 가중치 행렬 $W^o$과 곱해지는 과정을 보여준다.\n",
    "- 이 때 결과물인 멀티-헤드 어텐션 행렬은 인코더의 입력이었던 문장 행렬의 $(\\text{seq_len}, d_{model})$ 크기와 동일하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sOPuY_pGyq1L"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.6.7 행렬의 크기 유지\n",
    "\n",
    "- 다시 말해 인코더의 첫 번째 서브층인 멀티-헤드 어텐션 단계를 끝마쳤을 때, 인코더의 입력으로 들어왔던 행렬의 크기가 아직 유지되고 있음을 기억해두자.\n",
    "- 첫 번째 서브층인 멀티-헤드 어텐션과 두 번째 서브층인 포지션 와이즈 피드 포워드 신경망을 지나면서 인코더의 입력으로 들어올 때의 행렬의 크기는 계속 유지되어야 한다.\n",
    "- 트랜스포머는 다수의 인코더를 쌓은 형태(논문에서는 인코더가 6개)이다.\n",
    "- 인코더에서의 입력의 크기가 출력에서도 동일 크기로 계속 유지되어야만 다음 인코더에서도 다시 입력이 될 수 있기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pcjnz7irzP8r"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.6.7 멀티 헤드 어텐션(Multi-head Attention) 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PG5UjzPYDKk4"
   },
   "source": [
    "#### 1.6.7.1 가중치 행렬의 2가지 종류\n",
    "\n",
    "- 멀티 헤드 어텐션에서는 크게 두 종류의 가중치 행렬이 나왔다.\n",
    "  1. `WQ`, `WK`, `WV` : `Q`, `K`, `V` 행렬을 만들기 위한 가중치 행렬\n",
    "  2. `WO` : 어텐션 헤드들을 연결(concatenate) 후에 곱해주는 가중치 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jqnOKB_8DOQe"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.7.2 가중치 행렬 연산 구현\n",
    "\n",
    "- 가중치 행렬을 곱하는 것을 구현 상에서는 입력을 밀집층(Dense layer)을 지나게 하므로서 구현한다.\n",
    "- 케라스 코드 상으로 지금까지 사용해온 `Dense()`에 해당된다.\n",
    "\n",
    "```python\n",
    "Dense(units)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LHrSPob5DbWk"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.7.3 멀티 헤드 어텐션 구현 5가지 파트\n",
    "\n",
    "1. `WQ`, `WK`, `WV`에 해당하는 밀집층을 지나게한다.\n",
    "2. 지정된 헤드 수(`num_heads`)만큼 나눈다. (`split`)\n",
    "3. 스케일드 닷 프로덕트 어텐션\n",
    "4. 나눠졌던 헤드들을 연결(`concatenate`)한다.\n",
    "5. `WO`에 해당하는 밀집층을 지나게 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hC_jyqM2D0ge"
   },
   "source": [
    "<br>\n",
    "\n",
    "#### 1.6.7.4 멀티 헤드 어텐션 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i4sZDQPPD3_v"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        \n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads # 8\n",
    "        self.d_model = d_model # 512\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model) # WQ\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model) # WK\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model) # WV\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model) # WO\n",
    "\n",
    "    # 아래의 call 함수에서 헤드를 나누기 위해서 호출\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "\n",
    "        inputs = tf.reshape(inputs,\n",
    "                            shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        \n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], input['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # 1. WQ, WK, WV에 해당하는 밀집층 나누기\n",
    "        query = self.query_dense(query) # (batch_size, seq_len, d_model)\n",
    "        key = self.key_dense(key) # (batch_size, seq_len, d_model)\n",
    "        value = self.value_dense(value) # (batch_size, seq_len, d_model)\n",
    "\n",
    "        # 2. 헤드 나누기\n",
    "        query = self.split_heads(query, batch_size) # (batch_size, num_heads, seq_len, d_model/num_heads)\n",
    "        key = self.split_heads(key, batch_size) # (batch_size, num_heads, seq_len, d_model/num_heads)\n",
    "        value = self.split_heads(value, batch_size) # (batch_size, num_heads, seq_len, d_model/num_heads)\n",
    "\n",
    "        # 3. 스케일드 닷 프로덕트 어텐션 (앞서 구현한 함수 사용)\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 4. 헤드 연결(concatenate)하기\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "        \n",
    "        # 5. WO에 해당하는 밀집층 지나기\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs # 최종 결과 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TmtcjLmnJXVP"
   },
   "source": [
    "<br>\n",
    "\n",
    "- 이제 첫 번째 서브층인 멀티 헤드 어텐션을 구현해보았다.\n",
    "- 앞서 인코더는 두 개의 서브층(sublayer)으로 나눠진다고 했다.\n",
    "- 이제 두 번째 서브층인 포지션-와이즈 피드 포워드 신경망에 대해서 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RxWh--CdJsN7"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.7 포지션-와이즈 피드 포워드 신경망 (Position-wise FFNN)\n",
    "\n",
    "- 지금은 인코더를 설명하고 있지만, 포지션 와이즈 FFNN은 인코더와 디코더에서 공통적으로 가지고 있는 서브층이다.\n",
    "- 포지션-와이즈 FFNN은 쉽게 말하면 **완전 연결 FFNN(Fully-connected FFNN)**이라고 해석할 수 있다.\n",
    "- 앞서 인공 신경망은 결국 벡터와 행렬 연산으로 표현될 수 있음을 배웠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "utIxwx1QJ_oS"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.7.1 포지션-와이즈 FFNN 수식\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "FFNN(x) = MAX \\left( 0, x W_1 + b_1 \\right) W_2 + b_2\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5RIdvMAdKTwE"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.7.2 포지션-와이즈 FFNN 수식 그림 표현\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/31379/positionwiseffnn.PNG)\n",
    "\n",
    "- $x$\n",
    "  - 앞서 멀티 헤드 어텐션의 결과로 나온 $(\\text{seq_len}, d_{model})$의 크기를 가지는 행렬\n",
    "- $W_1$\n",
    "  - 가중치 행렬\n",
    "  - $(d_{model}, d_{ff})$의 크기를 가짐\n",
    "- $W_2$\n",
    "  - 가중치 행렬\n",
    "  - $(d_{ff}, d_{model})$의 크기를 가짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dqCHn7DaK32T"
   },
   "source": [
    "- 논문에서 은닉층의 크기인 $d_{ff}$는 앞서 하이퍼파라미터를 정의할 때 언급했듯이 2,048의 크기를 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l2cmNoJPLeFv"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.7.3 인코더 내,외부에서의 매개변수 사용\n",
    "\n",
    "- 여기서 매개변수 $W_1$, $b_1$, $W_2$, $b_2$는 하나의 인코더 층 내에서는 다른 문장, 다른 단어들마다 정확하게 동일하게 사용된다.\n",
    "- 하지만 인코더 층마다는 다른 값을 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3g0yLIeuM5hP"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.7.4 인코더 내부 연산 수행 과정\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/31379/transformer20.PNG)\n",
    "\n",
    "- 위의 그림에서 좌측은 인코더의 입력을 벡터 단위로 봤을 때, 각 벡터들이 멀티 헤드 어텐션 층이라는 인코더 내 첫 번째 서브층을 지나 FFNN을 통과하는 것을 보여준다.\n",
    "- 여기서 FFNN은 두 번째 서브층인 Position-wise FFNN을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hGFbgeeuNyGn"
   },
   "source": [
    "- 물론, 실제로는 그림의 우측과 같이 행렬로 연산된다.\n",
    "- 두 번째 서브층을 지난 인코더의 최종 출력은 여전히 인코더의 입력의 크기였던 $(\\text{seq_len}, d_{model})$의 크기가 보존된다.\n",
    "- 하나의 인코더 층을 지난 이 행렬은 다음 인코더의 층으로 전달된다.\n",
    "- 다음 층에서도 동일한 인코더 연산이 반복된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kiWFyRfvOHNt"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.7.5 포지션-와이즈 FFNN 함수 형태 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ABSCOekOO29"
   },
   "outputs": [],
   "source": [
    "def position_wise_feed_forward_network(d_model, dff):\n",
    "\n",
    "    return tf.keras.Sequential([tf.keras.layers.Dense(dff, activation='relu'), # (batch_size, seq_len, dff)\n",
    "                                # 활성화 함수 relu는 첫 번째 층에만 배치한다.\n",
    "                                tf.keras.layers.Dense(d_model) # (batch_size, seq_len, d_model)\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PdFVyE4EO6cF"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 1.8 잔차 연결(Residual connection)과 층 정규화(Layer Normalization)\n",
    "\n",
    "$\\quad$ ![](https://wikidocs.net/images/page/31379/transformer21.PNG)\n",
    "\n",
    "- 인코더의 두 개의 서브층에 대해서 이해했다면, 인코더에 대한 설명은 거의 다왔다.\n",
    "- 트랜스포머에서는 이러한 두 개의 서브층을 가진 인코더에 추가적으로 사용하는 기법이 있다.\n",
    "- 바로 **Add & Norm**이다.\n",
    "- 더 정확히는 **잔차 연결(residual connection)**과 **층 정규화(layer normalization)**를 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JDVp6bM9P3Sb"
   },
   "source": [
    "- 위의 그림은 앞서 Position-wise FFNN를 설명할 때 사용한 앞선 그림에서 화살표와 Add & Norm(잔차 연결과 정규화 과정)을 추가한 그림이다.\n",
    "- 추가된 화살표들은 서브층 이전의 입력에서 시작되어 서브층의 출력 부분을 향하고 있는 것에 주목하자.\n",
    "- 추가된 화살표가 어떤 의미를 갖고 있는 지는 잔차 연결과 층 정규화를 배우고 나면 이해할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T-FUnHCbSRXf"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.8.1 잔차 연결 (Residual connection)\n",
    "\n",
    "- 잔차 연결(residual connection)의 의미를 이해하기 위해서 어떤 함수 $H(x)$에 대한 이야기를 해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BuAWR7IDScUr"
   },
   "source": [
    "$\n",
    "\\qquad\n",
    "H(x) = x + F(x)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vb36iWA6SlNs"
   },
   "source": [
    "$\\qquad$ ![](https://wikidocs.net/images/page/31379/transformer22.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3bpBAEPrSnbM"
   },
   "source": [
    "- 위의 그림은 입력 $x$와 $x$에 대한 어떤 함수 $F(x)$의 값을 더한 함수 $H(x)$의 구조를 보여준다.\n",
    "- 어떤 함수 $F(x)$가 트랜스포머에서는 서브층에 해당된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8QxMUDAZS048"
   },
   "source": [
    "- 다시 말해 잔차 연결은 **서브층의 입력과 출력을 더하는 것**을 말한다.\n",
    "- 앞서 언급했듯이 트랜스포머에서 서브층의 입력과 출력은 동일한 차원을 갖고 있다.\n",
    "- 그러므로 서브층의 입력과 서브층의 출력은 덧셈 연산을 할 수 있다.\n",
    "- 이것이 바로 위의 인코더 그림에서 각 화살표가 서브층의 입력에서 출력으로 향하도록 그려졌던 이유이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GRHbtX7gTF_L"
   },
   "source": [
    "- 잔차 연결은 컴퓨터 비전 분야에서 주로 사용되는 모델의 학습을 돕는 기법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DomfbaC4TKZL"
   },
   "source": [
    "- 이를 식으로 표현하면 $x + Sublayer(x)$라고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hnGsi8i-TSJz"
   },
   "source": [
    "- 관련 논문 : [https://arxiv.org/pdf/1512.03385.pdf](https://arxiv.org/pdf/1512.03385.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FecjPyT2TWXi"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.8.2 층 정규화 (Layer Normalization)\n",
    "\n",
    "$\n",
    "\\qquad\n",
    "LayerNorm(x + Sublayer(x))\n",
    "$\n",
    "\n",
    "- 관련 논문 : [https://arxiv.org/pdf/1607.06450.pdf](https://arxiv.org/pdf/1607.06450.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zKC3_XHxTiO7"
   },
   "source": [
    "<br>\n",
    "\n",
    ".. 내용 작성중..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QicR1bkGToCi"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 참고 링크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "87EchwGiTriK"
   },
   "source": [
    "### 파이토치 코드로 작성된 자료\n",
    "\n",
    "- [https://www.aclweb.org/anthology/W18-2509](https://www.aclweb.org/anthology/W18-2509)\n",
    "- [http://nlp.seas.harvard.edu/2018/04/03/attention.html](http://nlp.seas.harvard.edu/2018/04/03/attention.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xb_QzmYATyJq"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 시각화가 잘 된 자료\n",
    "\n",
    "- [http://jalammar.github.io/illustrated-transformer/](http://jalammar.github.io/illustrated-transformer/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ETNx9ncT2Pg"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 동영상 강의\n",
    "\n",
    "- [https://www.youtube.com/watch?v=xhY7m8QVKjo](https://www.youtube.com/watch?v=xhY7m8QVKjo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TuU3CyGrT7vp"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 기타 참고 링크\n",
    "\n",
    "- [http://homepage.huangyhq.com/2018/08/25/Attention-is-All-You-Need-Comprehend-Transformer/](http://homepage.huangyhq.com/2018/08/25/Attention-is-All-You-Need-Comprehend-Transformer/)\n",
    "- [https://rubikscode.net/2019/08/05/transformer-with-python-and-tensorflow-2-0-attention-layers/](https://rubikscode.net/2019/08/05/transformer-with-python-and-tensorflow-2-0-attention-layers/)\n",
    "- [https://medium.com/@adriensieg/from-pre-trained-word-embeddings-to-pre-trained-language-models-focus-on-bert-343815627598](https://medium.com/@adriensieg/from-pre-trained-word-embeddings-to-pre-trained-language-models-focus-on-bert-343815627598)\n",
    "- [http://www.programmersought.com/article/2641874742/](http://www.programmersought.com/article/2641874742/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7VAfpQf-UHKR"
   },
   "source": [
    "- [https://leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html](https://leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html)\n",
    "- [https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1184/lectures/lecture12.pdf](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1184/lectures/lecture12.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQoOiXKOULu4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ch15_v01_Transformer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
